{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Class Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import ipywidgets\n",
    "from ipywidgets import interact, interactive, interact_manual\n",
    "import IPython\n",
    "import pylab\n",
    "pylab.rcParams['figure.figsize'] = (16, 8)\n",
    "\n",
    "from utilities import plot_helpers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.multiclass import OneVsOneClassifier, OneVsRestClassifier\n",
    "from sklearn import datasets\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_confusion_matrix(pred_label, true_label, num_classes=2):\n",
    "    \"\"\"This works for predictions in {0, 1, ..., Num Classes}.\"\"\"\n",
    "    confusion_matrix = np.zeros((num_classes, num_classes))\n",
    "    for row in range(num_classes):\n",
    "        for col in range(num_classes):\n",
    "            confusion_matrix[row, col] = np.sum(np.bitwise_and(pred_label == row, true_label == col))\n",
    "    return confusion_matrix\n",
    "\n",
    "def accuracy(confusion_matrix):\n",
    "    return np.sum(np.diag(confusion_matrix)) / np.sum(confusion_matrix)\n",
    "\n",
    "def precision(confusion_matrix):\n",
    "    correct = np.diag(confusion_matrix)\n",
    "    pred = np.sum(confusion_matrix, axis=1)\n",
    "    pred[pred == 0] = 1  # to avoid nan.\n",
    "    \n",
    "    return np.min(correct / pred)\n",
    "\n",
    "def recall(confusion_matrix):\n",
    "    correct = np.diag(confusion_matrix)\n",
    "    pred = np.sum(confusion_matrix, axis=0)\n",
    "    pred[pred == 0] = 1  # to avoid nan.\n",
    "\n",
    "    return np.min(correct / pred)\n",
    "\n",
    "def f1_score(confusion_matrix):\n",
    "    correct = np.diag(confusion_matrix)\n",
    "    rec_dem = np.sum(confusion_matrix, axis=0)\n",
    "    prec_dem = np.sum(confusion_matrix, axis=1)\n",
    "        \n",
    "    if np.any(correct == 0):\n",
    "        return 0   # to avoid nan.\n",
    "    else:\n",
    "        return np.min(2 * correct / (rec_dem +  prec_dem))\n",
    "\n",
    "def print_metrics(x, y, classifier):\n",
    "    cm = build_confusion_matrix(classifier.predict(x), y, num_classes=len(np.unique(y)))\n",
    "    acc = accuracy(cm)\n",
    "    prec = precision(cm)\n",
    "    rec = recall(cm)\n",
    "    f1 = f1_score(cm)\n",
    "    \n",
    "    print('Accuracy: {:.2f}. (Min-class) Precision: {:.2f}. (Min-class) Recall: {:.2f}. (Min-class) F1-Score: {:.2f}. '.format(acc, prec, rec, f1))\n",
    "    print('Confusion Matrix: \\n', cm)\n",
    "\n",
    "\n",
    "    \n",
    "def multiclass(strategy, classifier, noise):\n",
    "    np.random.seed(1)\n",
    "    X, y = datasets.make_classification(n_samples=100, n_features=2, n_informative=2, n_redundant=0, n_repeated=0, \n",
    "                                        n_classes=3, n_clusters_per_class=1,\n",
    "                                        class_sep=2, random_state=0)\n",
    "    X += noise * np.random.randn(100, 2)\n",
    "    \n",
    "    if classifier == 'perceptron':\n",
    "        base_classifier = SGDClassifier(loss='perceptron', alpha=0.001, random_state=0)\n",
    "    elif classifier == 'svm':\n",
    "        base_classifier = LinearSVC(random_state=0, loss='hinge')\n",
    "    \n",
    "    if strategy == 'OvO':\n",
    "        classifier =  OneVsOneClassifier(base_classifier)\n",
    "        colors = ['r', 'g', 'b']\n",
    "    elif strategy == 'OvR' or strategy == 'OvA':\n",
    "        classifier =  OneVsRestClassifier(base_classifier)\n",
    "        colors = ['b', 'g', 'r']\n",
    "    elif strategy == 'multi-class':\n",
    "        classifier = base_classifier\n",
    "        colors = ['b', 'g', 'r']\n",
    "\n",
    "        \n",
    "    \n",
    "    classifier.fit(X, y)\n",
    "    X0, X1 = X[:, 0], X[:, 1]\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    h = .02\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))\n",
    "\n",
    "    fig = plt.subplot(111)\n",
    "    plot_helpers.plot_contours(fig, classifier, xx, yy, cmap=plt.cm.jet, alpha=0.3)\n",
    "    \n",
    "    opt = {'marker': 'bs', 'label': '0', 'x_label': '$x$', 'y_label': '$y$', 'size': 8}\n",
    "    plot_helpers.plot_data(X[np.where(y == 0)[0], 0], X[np.where(y == 0)[0], 1], fig=fig, options=opt)\n",
    "    opt = {'marker': 'g*', 'label': '1', 'size': 8}\n",
    "    plot_helpers.plot_data(X[np.where(y == 1)[0], 0], X[np.where(y == 1)[0], 1], fig=fig, options=opt)\n",
    "    opt = {'marker': 'ro', 'label': '2', 'x_label': '$x$', 'y_label': '$y$', 'size': 8, 'legend': True}\n",
    "    plot_helpers.plot_data(X[np.where(y == 2)[0], 0], X[np.where(y == 2)[0], 1], fig=fig, options=opt)\n",
    "    \n",
    "\n",
    "    def plot_hyperplane(coef, intercept, color):\n",
    "        def line(x0):\n",
    "            return (-(x0 * coef[0, 0]) - intercept[0]) / coef[0, 1]\n",
    "\n",
    "        plt.plot([x_min, x_max], [line(x_min), line(x_max)],\n",
    "                 ls=\"--\", color=color)\n",
    "\n",
    "    \n",
    "    if hasattr(classifier, 'estimators_'):\n",
    "        for i, (estimator, color) in enumerate(zip(classifier.estimators_, colors)):\n",
    "            plot_hyperplane(estimator.coef_, estimator.intercept_, color)\n",
    "            print('w{} = [{:.2f} {:.2f} {:.2f}]'.format(i, *estimator.coef_[0, :], estimator.intercept_[0]))\n",
    "    else:\n",
    "        for i, (coef, intercept, color) in enumerate(zip(classifier.coef_, classifier.intercept_, colors)):\n",
    "            plot_hyperplane(coef[np.newaxis], intercept[np.newaxis], color)\n",
    "            print('w{} = [{:.2f} {:.2f} {:.2f}]'.format(i, *coef[:], intercept))\n",
    "            \n",
    "    fig.set_xlim([x_min, x_max])\n",
    "    fig.set_ylim([y_min, y_max]);\n",
    "    \n",
    "    print(\"\")\n",
    "    print_metrics(X, y, classifier)\n",
    "\n",
    "noise_widget = ipywidgets.FloatSlider(value=0, min=0, max=2, step=0.1, continuous_update=False)\n",
    "interact(multiclass, strategy=['OvA', 'OvO', 'multi-class'], classifier=['svm', 'perceptron'], noise=noise_widget); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
