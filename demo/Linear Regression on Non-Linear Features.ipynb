{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code source: Sebastian Curi and Andreas Krause.\n",
    "\n",
    "# Python Notebook Commands\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Numerical Libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize'] = (10, 5)   # Change this if figures look ugly. \n",
    "\n",
    "# IPython Libraries\n",
    "import IPython\n",
    "import ipywidgets\n",
    "from ipywidgets import interact, interactive, interact_manual\n",
    "\n",
    "\n",
    "# Custom Libraries\n",
    "from utilities.load_data import polynomial_data\n",
    "from utilities import plot_helpers\n",
    "from utilities.regressors import LinearRegressor\n",
    "from utilities.util import gradient_descent \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_points = 100  # Number of training points.\n",
    "noise = 0.3  # Noise Level (needed for data generation).\n",
    "\n",
    "w_true = np.array([-.5, .5, 1, -1])\n",
    "X, Y = polynomial_data(num_points, noise, w_true)\n",
    "\n",
    "# Plot Data\n",
    "fig = plt.subplot(111);\n",
    "plot_opts = {'x_label': '$x$', 'y_label': '$y$', 'title': 'Generated Data', 'y_lim': [np.min(Y)-0.5, np.max(Y)+0.5]}\n",
    "plot_helpers.plot_data(X[:, -2], Y, fig=fig, options=plot_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close form solution remains the same! \n",
    "\n",
    "dim = X.shape[1]\n",
    "reg = 0  # The regularizer is set to zero by now\n",
    "w_hat_closed_form = np.dot(np.linalg.pinv(np.dot(X.T, X) + reg * np.eye(dim)), np.dot(X.T, Y))\n",
    "fig = plt.subplot(111)\n",
    "plot_opts = {'x_label': '$x$', 'y_label': '$y$', 'title': 'Closed Form Solution', 'legend': True,\n",
    "             'y_lim': [np.min(Y)-0.5, np.max(Y)+0.5]}\n",
    "\n",
    "plot_helpers.plot_data(X[:, -2], Y, fig=fig, options=plot_opts)\n",
    "plot_helpers.plot_fit(X, w_hat_closed_form, fig=fig, options=plot_opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_widget = ipywidgets.FloatSlider(value=1e-2, min=1e-3, max=1, step=1e-3, description='Learning rate:', \n",
    "                                   style={'description_width': 'initial'}, continuous_update=False,\n",
    "                                   readout_format='.3f')\n",
    "n_iter_widget = ipywidgets.IntSlider(value=10, min=5, max=50, step=1, description='Number of iterations:',\n",
    "                                     style={'description_width': 'initial'}, \n",
    "                                     continuous_update=False)\n",
    "bs_widget = ipywidgets.IntSlider(value=32, min=1, max=X.shape[0], step=1, description='Batch size:',\n",
    "                                 style={'description_width': 'initial'}, continuous_update=False)\n",
    "schedule_widget = ipywidgets.RadioButtons(options=['Bold driver', 'AdaGrad', 'Annealing', 'None'],\n",
    "                                          value='None', description='Learning rate heuristics:',\n",
    "                                          style={'description_width': 'initial'})\n",
    "def optimize_cubic(eta, n_iter, batch_size, learning_rate_scheduling):\n",
    "    regressor = LinearRegressor(X, Y)\n",
    "    w0 = np.array([0., 0., 0., 0.])\n",
    "    if learning_rate_scheduling == 'None':\n",
    "        learning_rate_scheduling = None\n",
    "\n",
    "    opts = {'eta0': eta,\n",
    "            'n_iter': n_iter,\n",
    "            'batch_size': batch_size,\n",
    "            'n_samples': X.shape[0],\n",
    "            'algorithm': 'SGD',\n",
    "            'learning_rate_scheduling': learning_rate_scheduling\n",
    "            }\n",
    "    trajectory, indexes = gradient_descent(w0, regressor, opts=opts)\n",
    "\n",
    "    contourplot = None\n",
    "    dataplot = plt.subplot(111)\n",
    "    data_opts = {'x_label': '$x$', 'y_label': '$y$', 'title': 'Regression trajectory', 'legend': False,\n",
    "                'y_lim': [np.min(Y)-0.5, np.max(Y)+0.5], 'sgd_point': True}\n",
    "    plot_opts = {'data_opts': data_opts}\n",
    "\n",
    "    plot_helpers.linear_regression_progression(X, Y, trajectory, indexes, regressor.test_loss,\n",
    "                                               contourplot, dataplot, options=plot_opts)\n",
    "\n",
    "\n",
    "interact_manual(optimize_cubic, eta=lr_widget, n_iter=n_iter_widget, batch_size=bs_widget,\n",
    "                learning_rate_scheduling=schedule_widget);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
