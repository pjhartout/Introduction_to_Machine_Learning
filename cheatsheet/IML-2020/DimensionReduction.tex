\section*{Dimension reduction}
\subsection*{PCA}
$D={x_1,...,x_n} \subset \mathbb{R}^d$,
$\Sigma = \frac{1}{n}\sum_{i=1}^n x_i x_i^T$, $\mu = 0$\\
$(W,z_1,...,z_n) = \operatorname{argmin} \sum_{i=1}^n||W z_i - x_i||_2^2$,\\
$W = (v_1|...|v_k) \in \mathbb{R}^{d \times k}$, orthogonal; $z_i = W^T x_i$ \\ 
$v_i$ are the eigenvectors of $\Sigma$

\subsection*{Kernel PCA}
Kernel PC: $\alpha^{(1)},...,\alpha^{(k)}\in \mathbb{R}^n$, $\alpha^{(i)} = \frac{1}{\sqrt{\lambda_i}}v_i$, $K = \sum_{i=1}^n \lambda_i v_i v_i^T$, $\lambda_1 \geq ... \geq \lambda_d \geq 0$\\
New point: $\hat{z} = f(\hat{x}) = \sum_{j=1}^n\alpha_j^{(i)}k(\hat{x},x_j)$

\subsection*{Autoencoders}
Find identity function: $x \approx f(x;\theta)$\\
$f(x;\theta) = f_{decode}(f_{encode}(x;\theta_{encode});\theta_{decode})$