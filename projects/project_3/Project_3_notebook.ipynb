{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import ADASYN, SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"data\\\\train.csv\")\n",
    "df_val = pd.read_csv(\"data\\\\test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Active</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>112000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.037616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.190267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Active\n",
       "count  112000.000000\n",
       "mean        0.037616\n",
       "std         0.190267\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         0.000000\n",
       "75%         0.000000\n",
       "max         1.000000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# very imbalanced!\n",
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split strings into amino acids sequences\n",
    "X_train = df_train[\"Sequence\"].values\n",
    "X_train = [list(X_train[i]) for i in range(len(X_train))]\n",
    "y_train = df_train[\"Active\"].values\n",
    "X_val = df_val[\"Sequence\"].values\n",
    "X_val = [list(X_val[i]) for i in range(len(X_val))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage active mutations :  3.76  %\n"
     ]
    }
   ],
   "source": [
    "# percentage active \n",
    "print(\"Percentage active mutations : \",np.around(sum(y_train)/len(y_train)*100,2),\" %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encode the mutations, taking into consideration mutation position\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc.fit(X_train)\n",
    "X_train_onehot = enc.transform(X_train).toarray()\n",
    "X_val_onehot = enc.transform(X_val).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the input\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled =scaler.fit_transform(X_train_onehot)\n",
    "X_val_scaled = scaler.transform(X_val_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define f1 score, precision and recall for keras to be able to follow real time\n",
    "# taken from https://medium.com/@aakashgoel12/how-to-add-user-defined-function-get-f1-score-in-keras-metrics-3013f979ce0d\n",
    "# and https://datascience.stackexchange.com/questions/45165/how-to-get-accuracy-f1-precision-and-recall-for-a-keras-model\n",
    "def get_f1(y_true, y_pred): \n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    f1_val = 2*(precision*recall)/(precision+recall+K.epsilon())\n",
    "    return f1_val\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct ANN to perform binary classification\n",
    "def get_ANN(X_train_scaled,y_train,n_layers,hidden_units):\n",
    "    \"\"\"Constructs an ANN model to perform binary classification\n",
    "    \n",
    "    Args: X_train_scaled (np.ndarray): scaled array of one hot encoded AA mutation sequences \n",
    "        y_train (np.ndarray): labels (active or inactive)\n",
    "        n_layers (int): number of hidden layers for the ANN\n",
    "        hidden_units (int): number of units per hidden layer\n",
    "        \n",
    "    Returns: model (keras.models.Sequential): trained ANN \n",
    "    \"\"\"\n",
    "    print(\"Starting train_test_split\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_train_scaled, y_train, test_size=0.15, random_state=42, shuffle=True\n",
    "    )   \n",
    "    \n",
    "    print(\"Resampling to account for imbalance in data\")\n",
    "    sampler = ADASYN()\n",
    "    X_train_res, y_train_res = sampler.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # ANN architecture definition\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_units, activation=\"relu\", input_shape=(X_train.shape[1],)))\n",
    "    model.add(Dropout(0.5))\n",
    "    for i in range(1,n_layers):\n",
    "        model.add(Dense(hidden_units, activation=\"relu\"))\n",
    "        model.add(Dropout(0.5))\n",
    "    model.add(Dense(1,activation=\"sigmoid\"))\n",
    "    \n",
    "    # use Adam as optimizer\n",
    "    opt = Adam()\n",
    "    \n",
    "    model.compile(optimizer=opt, loss=\"binary_crossentropy\", metrics=[precision_m, recall_m, get_f1])\n",
    "    model.fit(X_train_res,y_train_res,epochs=55,batch_size=32)\n",
    "    \n",
    "    # evaluate the model on test set\n",
    "    score = model.evaluate(X_test, y_test, batch_size=64)\n",
    "    print(\"Loss, precision, recall, F1 : \",score)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting train_test_split\n",
      "Resampling to account for imbalance in data\n",
      "Epoch 1/55\n",
      "183128/183128 [==============================] - 9s 50us/step - loss: 0.1300 - precision_m: 0.9395 - recall_m: 0.9653 - get_f1: 0.9508\n",
      "Epoch 2/55\n",
      "183128/183128 [==============================] - 10s 53us/step - loss: 0.0519 - precision_m: 0.9767 - recall_m: 0.9910 - get_f1: 0.9833\n",
      "Epoch 3/55\n",
      "183128/183128 [==============================] - 10s 54us/step - loss: 0.0409 - precision_m: 0.9821 - recall_m: 0.9934 - get_f1: 0.9873\n",
      "Epoch 4/55\n",
      "183128/183128 [==============================] - 10s 54us/step - loss: 0.0350 - precision_m: 0.9848 - recall_m: 0.9944 - get_f1: 0.9892\n",
      "Epoch 5/55\n",
      "183128/183128 [==============================] - 10s 55us/step - loss: 0.0319 - precision_m: 0.9858 - recall_m: 0.9951 - get_f1: 0.9901\n",
      "Epoch 6/55\n",
      "183128/183128 [==============================] - 10s 57us/step - loss: 0.0298 - precision_m: 0.9867 - recall_m: 0.9958 - get_f1: 0.9909\n",
      "Epoch 7/55\n",
      "183128/183128 [==============================] - 10s 56us/step - loss: 0.0282 - precision_m: 0.9872 - recall_m: 0.9964 - get_f1: 0.9915\n",
      "Epoch 8/55\n",
      "183128/183128 [==============================] - 10s 56us/step - loss: 0.0260 - precision_m: 0.9885 - recall_m: 0.9966 - get_f1: 0.9923\n",
      "Epoch 9/55\n",
      "183128/183128 [==============================] - 10s 57us/step - loss: 0.0256 - precision_m: 0.9887 - recall_m: 0.9969 - get_f1: 0.9925\n",
      "Epoch 10/55\n",
      "183128/183128 [==============================] - 10s 57us/step - loss: 0.0239 - precision_m: 0.9894 - recall_m: 0.9967 - get_f1: 0.9928\n",
      "Epoch 11/55\n",
      "183128/183128 [==============================] - 10s 56us/step - loss: 0.0228 - precision_m: 0.9901 - recall_m: 0.9971 - get_f1: 0.9934\n",
      "Epoch 12/55\n",
      "183128/183128 [==============================] - 10s 56us/step - loss: 0.0219 - precision_m: 0.9907 - recall_m: 0.9972 - get_f1: 0.9938\n",
      "Epoch 13/55\n",
      "183128/183128 [==============================] - 10s 56us/step - loss: 0.0224 - precision_m: 0.9902 - recall_m: 0.9972 - get_f1: 0.9935\n",
      "Epoch 14/55\n",
      "183128/183128 [==============================] - 10s 56us/step - loss: 0.0211 - precision_m: 0.9909 - recall_m: 0.9979 - get_f1: 0.9942\n",
      "Epoch 15/55\n",
      "183128/183128 [==============================] - 10s 56us/step - loss: 0.0209 - precision_m: 0.9913 - recall_m: 0.9979 - get_f1: 0.9944\n",
      "Epoch 16/55\n",
      "183128/183128 [==============================] - 10s 56us/step - loss: 0.0198 - precision_m: 0.9917 - recall_m: 0.9976 - get_f1: 0.9945\n",
      "Epoch 17/55\n",
      "183128/183128 [==============================] - 10s 56us/step - loss: 0.0188 - precision_m: 0.9916 - recall_m: 0.9977 - get_f1: 0.9945\n",
      "Epoch 18/55\n",
      "183128/183128 [==============================] - 11s 57us/step - loss: 0.0197 - precision_m: 0.9915 - recall_m: 0.9978 - get_f1: 0.9945\n",
      "Epoch 19/55\n",
      "183128/183128 [==============================] - 10s 56us/step - loss: 0.0190 - precision_m: 0.9918 - recall_m: 0.9978 - get_f1: 0.9946\n",
      "Epoch 20/55\n",
      "183128/183128 [==============================] - 10s 56us/step - loss: 0.0186 - precision_m: 0.9923 - recall_m: 0.9980 - get_f1: 0.9950\n",
      "Epoch 21/55\n",
      "183128/183128 [==============================] - 10s 56us/step - loss: 0.0182 - precision_m: 0.9926 - recall_m: 0.9980 - get_f1: 0.9952\n",
      "Epoch 22/55\n",
      "183128/183128 [==============================] - 10s 57us/step - loss: 0.0181 - precision_m: 0.9923 - recall_m: 0.9981 - get_f1: 0.9950\n",
      "Epoch 23/55\n",
      "183128/183128 [==============================] - 10s 56us/step - loss: 0.0166 - precision_m: 0.9930 - recall_m: 0.9982 - get_f1: 0.9954\n",
      "Epoch 24/55\n",
      "183128/183128 [==============================] - 10s 57us/step - loss: 0.0167 - precision_m: 0.9929 - recall_m: 0.9980 - get_f1: 0.9953\n",
      "Epoch 25/55\n",
      "183128/183128 [==============================] - 11s 59us/step - loss: 0.0159 - precision_m: 0.9934 - recall_m: 0.9981 - get_f1: 0.9956\n",
      "Epoch 26/55\n",
      "183128/183128 [==============================] - 10s 56us/step - loss: 0.0171 - precision_m: 0.9930 - recall_m: 0.9981 - get_f1: 0.9954\n",
      "Epoch 27/55\n",
      "183128/183128 [==============================] - 11s 58us/step - loss: 0.0167 - precision_m: 0.9931 - recall_m: 0.9983 - get_f1: 0.9956\n",
      "Epoch 28/55\n",
      "183128/183128 [==============================] - 10s 57us/step - loss: 0.0167 - precision_m: 0.9929 - recall_m: 0.9982 - get_f1: 0.9954\n",
      "Epoch 29/55\n",
      "183128/183128 [==============================] - 11s 58us/step - loss: 0.0158 - precision_m: 0.9934 - recall_m: 0.9983 - get_f1: 0.9957\n",
      "Epoch 30/55\n",
      "183128/183128 [==============================] - 10s 57us/step - loss: 0.0160 - precision_m: 0.9936 - recall_m: 0.9984 - get_f1: 0.9959\n",
      "Epoch 31/55\n",
      "183128/183128 [==============================] - 10s 57us/step - loss: 0.0166 - precision_m: 0.9932 - recall_m: 0.9985 - get_f1: 0.9957\n",
      "Epoch 32/55\n",
      "183128/183128 [==============================] - 10s 57us/step - loss: 0.0151 - precision_m: 0.9940 - recall_m: 0.9985 - get_f1: 0.9961\n",
      "Epoch 33/55\n",
      "183128/183128 [==============================] - 11s 58us/step - loss: 0.0149 - precision_m: 0.9943 - recall_m: 0.9984 - get_f1: 0.9962\n",
      "Epoch 34/55\n",
      "183128/183128 [==============================] - 11s 58us/step - loss: 0.0150 - precision_m: 0.9938 - recall_m: 0.9984 - get_f1: 0.9960\n",
      "Epoch 35/55\n",
      "183128/183128 [==============================] - 10s 57us/step - loss: 0.0151 - precision_m: 0.9940 - recall_m: 0.9985 - get_f1: 0.9961\n",
      "Epoch 36/55\n",
      "183128/183128 [==============================] - 10s 57us/step - loss: 0.0150 - precision_m: 0.9940 - recall_m: 0.9985 - get_f1: 0.9961\n",
      "Epoch 37/55\n",
      "183128/183128 [==============================] - 10s 57us/step - loss: 0.0146 - precision_m: 0.9943 - recall_m: 0.9986 - get_f1: 0.9963\n",
      "Epoch 38/55\n",
      "183128/183128 [==============================] - 11s 58us/step - loss: 0.0144 - precision_m: 0.9944 - recall_m: 0.9986 - get_f1: 0.9964\n",
      "Epoch 39/55\n",
      "183128/183128 [==============================] - 10s 57us/step - loss: 0.0150 - precision_m: 0.9940 - recall_m: 0.9984 - get_f1: 0.9961\n",
      "Epoch 40/55\n",
      "183128/183128 [==============================] - 10s 57us/step - loss: 0.0141 - precision_m: 0.9946 - recall_m: 0.9987 - get_f1: 0.9965\n",
      "Epoch 41/55\n",
      "183128/183128 [==============================] - 12s 64us/step - loss: 0.0143 - precision_m: 0.9947 - recall_m: 0.9988 - get_f1: 0.9966\n",
      "Epoch 42/55\n",
      "183128/183128 [==============================] - 11s 58us/step - loss: 0.0138 - precision_m: 0.9949 - recall_m: 0.9988 - get_f1: 0.9967\n",
      "Epoch 43/55\n",
      "183128/183128 [==============================] - 11s 58us/step - loss: 0.0135 - precision_m: 0.9947 - recall_m: 0.9986 - get_f1: 0.9966\n",
      "Epoch 44/55\n",
      "183128/183128 [==============================] - 11s 58us/step - loss: 0.0147 - precision_m: 0.9944 - recall_m: 0.9986 - get_f1: 0.9964\n",
      "Epoch 45/55\n",
      "183128/183128 [==============================] - 11s 59us/step - loss: 0.0142 - precision_m: 0.9942 - recall_m: 0.9986 - get_f1: 0.9963\n",
      "Epoch 46/55\n",
      "183128/183128 [==============================] - 11s 59us/step - loss: 0.0140 - precision_m: 0.9945 - recall_m: 0.9987 - get_f1: 0.9965\n",
      "Epoch 47/55\n",
      "183128/183128 [==============================] - 10s 57us/step - loss: 0.0143 - precision_m: 0.9945 - recall_m: 0.9987 - get_f1: 0.9965\n",
      "Epoch 48/55\n",
      "183128/183128 [==============================] - 11s 57us/step - loss: 0.0149 - precision_m: 0.9942 - recall_m: 0.9987 - get_f1: 0.9963\n",
      "Epoch 49/55\n",
      "183128/183128 [==============================] - 11s 58us/step - loss: 0.0135 - precision_m: 0.9948 - recall_m: 0.9988 - get_f1: 0.9967\n",
      "Epoch 50/55\n",
      "183128/183128 [==============================] - 11s 59us/step - loss: 0.0134 - precision_m: 0.9950 - recall_m: 0.9988 - get_f1: 0.9968\n",
      "Epoch 51/55\n",
      "183128/183128 [==============================] - 11s 57us/step - loss: 0.0131 - precision_m: 0.9948 - recall_m: 0.9987 - get_f1: 0.9966\n",
      "Epoch 52/55\n",
      "183128/183128 [==============================] - 10s 57us/step - loss: 0.0130 - precision_m: 0.9950 - recall_m: 0.9985 - get_f1: 0.9966\n",
      "Epoch 53/55\n",
      "183128/183128 [==============================] - 10s 56us/step - loss: 0.0132 - precision_m: 0.9949 - recall_m: 0.9989 - get_f1: 0.9968\n",
      "Epoch 54/55\n",
      "183128/183128 [==============================] - 10s 56us/step - loss: 0.0130 - precision_m: 0.9949 - recall_m: 0.9988 - get_f1: 0.9968\n",
      "Epoch 55/55\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183128/183128 [==============================] - 10s 56us/step - loss: 0.0139 - precision_m: 0.9946 - recall_m: 0.9988 - get_f1: 0.9966\n",
      "16800/16800 [==============================] - 0s 13us/step\n",
      "Loss, precision, recall, F1 :  [0.07760541392854743, 0.8240089416503906, 0.8390276432037354, 0.8182798027992249]\n"
     ]
    }
   ],
   "source": [
    "# train the ANN\n",
    "## beware the real time loss, precision, recall and F1 are calculated on batches so are not accurate\n",
    "model = get_ANN(X_train_scaled, y_train, 3, 125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform predictions\n",
    "y_pred = np.around(model.predict(X_val_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "np.savetxt(\"predictions.csv\", y_pred, fmt=\"%i\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
