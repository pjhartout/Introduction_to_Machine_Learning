{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install tensorflow_addons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import keras.applications\n",
    "from keras import backend as K\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "import keras.layers as kl\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2 \n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n",
      "2.1.0\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 5580040924922057973\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 3057333044\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 11000566993280843546\n",
      "physical_device_desc: \"device: 0, name: Quadro T2000, pci bus id: 0000:01:00.0, compute capability: 7.5\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "print(keras.__version__)\n",
    "import tensorflow\n",
    "print(tensorflow.__version__)\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "T_G_WIDTH = 100\n",
    "T_G_HEIGHT = 100\n",
    "T_G_NUMCHANNELS = 3\n",
    "CHUNKSIZE = 16\n",
    "BATCHSIZE = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02461</td>\n",
       "      <td>03450</td>\n",
       "      <td>02678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02299</td>\n",
       "      <td>02499</td>\n",
       "      <td>04987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04663</td>\n",
       "      <td>01056</td>\n",
       "      <td>03029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04532</td>\n",
       "      <td>01186</td>\n",
       "      <td>01297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03454</td>\n",
       "      <td>03809</td>\n",
       "      <td>02204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       A      B      C\n",
       "0  02461  03450  02678\n",
       "1  02299  02499  04987\n",
       "2  04663  01056  03029\n",
       "3  04532  01186  01297\n",
       "4  03454  03809  02204"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_triplets = pd.read_csv(\"data/train_triplets.txt\", names=[\"A\", \"B\", \"C\"], sep=\" \")\n",
    "test_triplets = pd.read_csv(\"data/test_triplets.txt\", names=[\"A\", \"B\", \"C\"], sep=\" \")\n",
    "\n",
    "for column in [\"A\", \"B\", \"C\"]:\n",
    "    train_triplets[column] = train_triplets[column].astype(str)\n",
    "    test_triplets[column] = test_triplets[column].astype(str)\n",
    "    train_triplets[column] = train_triplets[column].apply(lambda x: x.zfill(5))\n",
    "    test_triplets[column] = test_triplets[column].apply(lambda x: x.zfill(5))\n",
    "train_triplets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# split in test and training set, we take 0.3 of the dataframe and use it for testing and the rest for training\n",
    "train_triplets = train_triplets.sample(frac=1)\n",
    "n_test = 500\n",
    "test_images = train_triplets[:n_test]\n",
    "train_images = train_triplets[n_test:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# def createCNNModel(emb_size):\n",
    "\n",
    "#     # Initialize a ResNet50_ImageNet Model\n",
    "# #     resnet_input = kl.Input(shape=(T_G_WIDTH,T_G_HEIGHT,T_G_NUMCHANNELS))\n",
    "#     model = tf.keras.Sequential([\n",
    "#         tf.keras.layers.Conv2D(filters=10, kernel_size=2, padding='same', activation='relu', input_shape=(T_G_HEIGHT,T_G_WIDTH,3)),\n",
    "#         tf.keras.layers.MaxPooling2D(pool_size=2),\n",
    "#         tf.keras.layers.Dropout(0.3),\n",
    "#         tf.keras.layers.Flatten(),\n",
    "#         tf.keras.layers.Dense(emb_size, activation=None), # No activation on final dense layer\n",
    "#         tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1)) # L2 normalize embeddings\n",
    "#     ])\n",
    "\n",
    "#     print(type(model))\n",
    "#     # triplet framework, shared weights\n",
    "#     input_shape=(T_G_WIDTH,T_G_HEIGHT,T_G_NUMCHANNELS)\n",
    "#     input_anchor = kl.Input(shape=input_shape, name='input_anchor')\n",
    "#     input_positive = kl.Input(shape=input_shape, name='input_pos')\n",
    "#     input_negative = kl.Input(shape=input_shape, name='input_neg')\n",
    "#     print(type(model))\n",
    "#     print(type(input_positive))\n",
    "#     model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "#     loss=tfa.losses.TripletSemiHardLoss())\n",
    "#     net_anchor = model(input_anchor)\n",
    "#     net_positive = model(input_positive)\n",
    "#     net_negative = model(input_negative)\n",
    "\n",
    "#     # The Lamda layer produces output using given function. Here its Euclidean distance.\n",
    "#     positive_dist = kl.Lambda(euclidean_distance, name='pos_dist')([net_anchor, net_positive])\n",
    "#     negative_dist = kl.Lambda(euclidean_distance, name='neg_dist')([net_anchor, net_negative])\n",
    "#     tertiary_dist = kl.Lambda(euclidean_distance, name='ter_dist')([net_positive, net_negative])\n",
    "\n",
    "#     # This lambda layer simply stacks outputs so both distances are available to the objective\n",
    "#     stacked_dists = kl.Lambda(lambda vects: K.stack(vects, axis=1), name='stacked_dists')([positive_dist, negative_dist, tertiary_dist])\n",
    "\n",
    "#     model = Model([input_anchor, input_positive, input_negative], stacked_dists, name='triple_siamese')\n",
    "\n",
    "#     v_optimizer = optimizers.Adam(lr=0.001)\n",
    "\n",
    "#     model.compile(optimizer=v_optimizer, loss=triplet_loss, metrics=[accuracy])\n",
    "\n",
    "#     return model\n",
    "# createCNNModel(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def createResNetModel(emb_size):\n",
    "\n",
    "    # Initialize a ResNet50_ImageNet Model\n",
    "    xception_input = kl.Input(shape=(T_G_WIDTH,T_G_HEIGHT,T_G_NUMCHANNELS))\n",
    "    xception_model = keras.applications.Xception(include_top=False,\n",
    "        weights=None,\n",
    "        input_tensor=xception_input,\n",
    "        input_shape=None,\n",
    "        pooling=max,\n",
    "    )\n",
    "\n",
    "    # New Layers over ResNet50\n",
    "    net = xception_model.output\n",
    "    net = kl.GlobalAveragePooling2D(name='gap')(net)\n",
    "    net = kl.Dropout(0.5)(net)\n",
    "    net = kl.Dense(emb_size,activation='relu',name='t_emb_1')(net)\n",
    "    net = kl.Lambda(lambda  x: K.l2_normalize(x,axis=1), name='t_emb_1_l2norm')(net)\n",
    "    \n",
    "    # model creation\n",
    "    base_model = Model(xception_model.input, net, name=\"base_model\")\n",
    "\n",
    "    # triplet framework, shared weights\n",
    "    input_shape=(T_G_WIDTH,T_G_HEIGHT,T_G_NUMCHANNELS)\n",
    "    input_anchor = kl.Input(shape=input_shape, name='input_anchor')\n",
    "    input_positive = kl.Input(shape=input_shape, name='input_pos')\n",
    "    input_negative = kl.Input(shape=input_shape, name='input_neg')\n",
    "    print(type(base_model))\n",
    "    print(type(input_positive))\n",
    "    net_anchor = base_model(input_anchor)\n",
    "    net_positive = base_model(input_positive)\n",
    "    net_negative = base_model(input_negative)\n",
    "\n",
    "    # The Lamda layer produces output using given function. Here its Euclidean distance.\n",
    "    positive_dist = kl.Lambda(euclidean_distance, name='pos_dist')([net_anchor, net_positive])\n",
    "    negative_dist = kl.Lambda(euclidean_distance, name='neg_dist')([net_anchor, net_negative])\n",
    "    tertiary_dist = kl.Lambda(euclidean_distance, name='ter_dist')([net_positive, net_negative])\n",
    "\n",
    "    # This lambda layer simply stacks outputs so both distances are available to the objective\n",
    "    stacked_dists = kl.Lambda(lambda vects: K.stack(vects, axis=1), name='stacked_dists')([positive_dist, negative_dist, tertiary_dist])\n",
    "\n",
    "    model = Model([input_anchor, input_positive, input_negative], stacked_dists, name='triple_siamese')\n",
    "\n",
    "    v_optimizer = optimizers.Adam(lr=0.001)\n",
    "\n",
    "    model.compile(optimizer=v_optimizer, loss=triplet_loss, metrics=[accuracy])\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def triplet_loss(y_true, y_pred):\n",
    "    margin = K.constant(1)\n",
    "    return K.mean(K.maximum(K.constant(0), K.square(y_pred[:,0,0]) - 0.5*(K.square(y_pred[:,1,0])+K.square(y_pred[:,2,0])) + margin))\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    return K.mean(y_pred[:,0,0] < y_pred[:,1,0])\n",
    "\n",
    "def l2Norm(x):\n",
    "    return  K.l2_normalize(x, axis=-1)\n",
    "\n",
    "def euclidean_distance(vects):\n",
    "    x, y = vects\n",
    "    return K.sqrt(K.maximum(K.sum(K.square(x - y), axis=1, keepdims=True), K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def t_read_image(loc):\n",
    "    t_image = cv2.imread(loc)\n",
    "    t_image = cv2.resize(t_image, (T_G_HEIGHT,T_G_WIDTH))\n",
    "    t_image = t_image.astype(\"float32\")\n",
    "    t_image = keras.applications.resnet50.preprocess_input(t_image, data_format='channels_last')\n",
    "\n",
    "    return t_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load file names\n",
    "for direc, subdir, file in os.walk(r\"data/food\"):\n",
    "    list_dir = file[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aab7a939b51c4102af522e33367be5a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# load the image\n",
    "img_array = {}\n",
    "for file in tqdm(list_dir):\n",
    "    img = t_read_image(os.path.join(\"data/food\", file))\n",
    "    img_array[file.split(\".jpg\")[0]]=img_to_array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# create model\n",
    "# int is the embedding size \n",
    "# resnet_model = createResNetModel(300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from disk\n"
     ]
    }
   ],
   "source": [
    "use_pretrained_model = True\n",
    "if use_pretrained_model == False:\n",
    "    cnn_model = createResNetModel(300) \n",
    "else:\n",
    "    json_file = open('model.json', 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    cnn_model = keras.models.model_from_json(loaded_model_json)\n",
    "    # load weights into new model\n",
    "    cnn_model.load_weights(\"Xception.h5\")\n",
    "    cnn_model.compile(optimizer=optimizers.Adam(lr=0.001), loss=triplet_loss, metrics=[accuracy])\n",
    "    print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting anchors train ...\n",
      "Getting positives train ...\n",
      "Getting negatives train ...\n"
     ]
    }
   ],
   "source": [
    "print(\"Getting anchors train ...\")\n",
    "anchors_train = [img_array[img] for img in np.array(train_images[\"A\"])]\n",
    "print(\"Getting positives train ...\")\n",
    "positives_train = [img_array[img] for img in np.array(train_images[\"B\"])]\n",
    "print(\"Getting negatives train ...\")\n",
    "negatives_train = [img_array[img] for img in np.array(train_images[\"C\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting anchors test ...\n",
      "Getting positives test ...\n",
      "Getting negatives test ...\n"
     ]
    }
   ],
   "source": [
    "print(\"Getting anchors test ...\")\n",
    "anchors_test = [img_array[img] for img in np.array(test_images[\"A\"])]\n",
    "print(\"Getting positives test ...\")\n",
    "positives_test = [img_array[img] for img in np.array(test_images[\"B\"])]\n",
    "print(\"Getting negatives test ...\")\n",
    "negatives_test = [img_array[img] for img in np.array(test_images[\"C\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "numepochs = 50\n",
    "total_t_ch = int(np.ceil(len(anchors_train) / float(CHUNKSIZE)))\n",
    "total_v_ch = int(np.ceil(len(anchors_test) / float(CHUNKSIZE)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for e in range(0, numepochs):\n",
    "    for t in range(0, total_t_ch):\n",
    "        print (\"Epoch :{}, train chunk {}/{}\".format(e,t+1,total_t_ch))\n",
    "        anchors_t = anchors_train[t*CHUNKSIZE:(t+1)*CHUNKSIZE]\n",
    "        positives_t =positives_train[t*CHUNKSIZE:(t+1)*CHUNKSIZE]\n",
    "        negatives_t = negatives_train[t*CHUNKSIZE:(t+1)*CHUNKSIZE]\n",
    "        Y_train = np.random.randint(2, size=(1,2,len(anchors_t))).T\n",
    "        # This method does NOT use data augmentation\n",
    "        cnn_model.fit([anchors_t, positives_t, negatives_t], Y_train, epochs=1,  batch_size=BATCHSIZE)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# In case the validation images don't fit in memory, we load chunks from disk again. \n",
    "val_res = [0.0, 0.0]\n",
    "total_w = 0.0\n",
    "for v in range(0, total_v_ch):\n",
    "\n",
    "    print('Loading validation image lists ...')\n",
    "    print (\"Epoch :{}, train chunk {}/{}...\".format(e,v+1,total_v_ch))\n",
    "    anchors_v = anchors_test[v*CHUNKSIZE:(v+1)*CHUNKSIZE]\n",
    "    positives_v =positives_test[v*CHUNKSIZE:(v+1)*CHUNKSIZE]\n",
    "    negatives_v = negatives_test[v*CHUNKSIZE:(v+1)*CHUNKSIZE]\n",
    "    Y_val = np.random.randint(2, size=(1,2,len(anchors_v))).T\n",
    "\n",
    "    # Weight of current validation measurement. \n",
    "    # if loaded expected number of items, this will be 1.0, otherwise < 1.0, and > 0.0.\n",
    "    w = float(len(anchors_v)) / float(CHUNKSIZE)\n",
    "    total_w = total_w + w\n",
    "\n",
    "    curval = cnn_model.evaluate([anchors_v, positives_v, negatives_v], Y_val, batch_size=BATCHSIZE)\n",
    "    val_res[0] = val_res[0] + w*curval[0]\n",
    "    val_res[1] = val_res[1] + w*curval[1]\n",
    "#     print(pd.Series(np.argmax(val_res)).value_counts())\n",
    "val_res = [x / total_w for x in val_res]\n",
    "\n",
    "print('Validation Results: ', str(val_res))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# serialize model to JSON\n",
    "model_json = cnn_model.to_json()\n",
    "with open(\"model_2.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "cnn_model.save_weights(\"Xception_2.h5\")\n",
    "print(\"Saved model to disk\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we want to generate the output 0, for each triplet of image on the validation to get the score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting anchors test ...\n",
      "Getting first images ...\n",
      "Getting second test ...\n"
     ]
    }
   ],
   "source": [
    "print(\"Getting anchors test ...\")\n",
    "anchors_val = [img_array[img] for img in np.array(test_triplets[\"A\"])]\n",
    "print(\"Getting first images ...\")\n",
    "first_val = [img_array[img] for img in np.array(test_triplets[\"B\"])]\n",
    "print(\"Getting second test ...\")\n",
    "second_val = [img_array[img] for img in np.array(test_triplets[\"C\"])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c04ea1457e174c87b8baa49bef961a5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3722.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "total_v_ch = int(np.ceil(len(anchors_val) / float(CHUNKSIZE)))\n",
    "# for each chunk we have to compute the embedding and the distance to the closest neighbour.\n",
    "predictions_list = []\n",
    "errors = 0\n",
    "for v in tqdm(range(0, total_v_ch)):\n",
    "    anchors_val_chunk = anchors_val[v*CHUNKSIZE:(v+1)*CHUNKSIZE]\n",
    "    first_val_chunk =first_val[v*CHUNKSIZE:(v+1)*CHUNKSIZE]\n",
    "    second_val_chunk = second_val[v*CHUNKSIZE:(v+1)*CHUNKSIZE]\n",
    "    predictions = cnn_model.predict([anchors_val_chunk, first_val_chunk, second_val_chunk], batch_size=BATCHSIZE)\n",
    "    for distance in predictions:\n",
    "        predictions_list.append(np.argmin(np.array([distance[1], distance[0]])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_array = np.asarray(predictions_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('predictions.txt', predictions_array, fmt='%d', delimiter='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
