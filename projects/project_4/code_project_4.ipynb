{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal here is to apply triplet loss to our dataset\n",
    "\n",
    "A good explanation of triplet loss referenced on the TF website is done here along with a code implementation.\n",
    "https://omoindrot.github.io/triplet-loss\n",
    "\n",
    "In order to do this we need to achieve the following steps:\n",
    "- preprocess our images for processing in the network\n",
    "- define the neural network\n",
    "- train the model using triplet loss\n",
    "- compute the pairwise between each of the points in the learned embedding which gives us the desired label\n",
    "\n",
    "*dependency warning*: tensorflow 2.1 is recommended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import array_to_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2 \n",
    "import io\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data and preprocessing labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "IMG_WIDTH = 300\n",
    "IMG_HEIGHT = 400\n",
    "N_EPOCH = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02461</td>\n",
       "      <td>03450</td>\n",
       "      <td>02678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>02299</td>\n",
       "      <td>02499</td>\n",
       "      <td>04987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>04663</td>\n",
       "      <td>01056</td>\n",
       "      <td>03029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>04532</td>\n",
       "      <td>01186</td>\n",
       "      <td>01297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>03454</td>\n",
       "      <td>03809</td>\n",
       "      <td>02204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       A      B      C\n",
       "0  02461  03450  02678\n",
       "1  02299  02499  04987\n",
       "2  04663  01056  03029\n",
       "3  04532  01186  01297\n",
       "4  03454  03809  02204"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_triplets = pd.read_csv(\"data/train_triplets.txt\", names=[\"A\", \"B\", \"C\"], sep=\" \")\n",
    "test_triplets = pd.read_csv(\"data/test_triplets.txt\", names=[\"A\", \"B\", \"C\"], sep=\" \")\n",
    "\n",
    "for column in [\"A\", \"B\", \"C\"]:\n",
    "    train_triplets[column] = train_triplets[column].astype(str)\n",
    "    test_triplets[column] = test_triplets[column].astype(str)\n",
    "    train_triplets[column] = train_triplets[column].apply(lambda x: x.zfill(5))\n",
    "    test_triplets[column] = test_triplets[column].apply(lambda x: x.zfill(5))\n",
    "train_triplets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split in test and training set, we take 0.3 of the dataframe and use it for testing and the rest for training\n",
    "train_triplets = train_triplets.sample(frac=1)\n",
    "n_test = 500\n",
    "test_images = train_triplets[:n_test]\n",
    "train_images = train_triplets[n_test:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define and compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Conv2D(filters=64, kernel_size=2, padding='same', activation='relu', input_shape=(IMG_HEIGHT,IMG_WIDTH,3)),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=2),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Conv2D(filters=32, kernel_size=2, padding='same', activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=2),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(256, activation=None), # No activation on final dense layer\n",
    "    tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1)) # L2 normalize embeddings\n",
    "\n",
    "])\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "    loss=tfa.losses.TripletSemiHardLoss())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### High level overview\n",
    "Train time\n",
    "- loop through triplets - randomly swap second and third choice\n",
    "- foorward pass ->  output is three vectors (dimensions to be determined)\n",
    "- normalize embedding (?)\n",
    "- evaluate triplet loss using euclidean distance\n",
    "- backward pass\n",
    "\n",
    "Test time\n",
    "- predict embedding\n",
    "- evaluate distance\n",
    "- take minimum -> give 0,1 label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and testing dataset object definition\n",
    "\n",
    "The goal here is to make sure that we have something that resembles the type of the object used for training in losses_triplet, which is something like PrefetchDataset (see added type definition in notebook of the repo and here: https://www.tensorflow.org/addons/tutorials/losses_triplet). We have found something quite useful for that, and it is explained here: https://www.tensorflow.org/tutorials/load_data/images as indicated in the notebook in the repo, this results in an object of type <class 'tensorflow.python.data.ops.dataset_ops.PrefetchDataset'> which is probably what we want and is the most efficient way to load data into tensorflow. Therefore we proceed as they do with our dataset. \n",
    "\n",
    "However, this is not enough. We want to generate a label for each triplet, 1 or 0 (1: default config ABC and 0: randomly sampled half the time ACB) which we are going to use as a function to measure the loss\n",
    "\n",
    "Step by step plan:\n",
    "1. load triplets\n",
    "2. swap them half the time\n",
    "3. compute label\n",
    "\n",
    "Data structure done at each epoch is:\n",
    "- For each batch, we compute a forward pass of the network for each of the triplet, together with a label corresponding to whether or not the labels have been swaped\n",
    "- the evaluate loss and do backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ds = tf.data.Dataset.list_files(\"data/food/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filename(file_path):\n",
    "    \"\"\"This function gets the name of the image, which is going to be useful at training time \n",
    "    \"\"\"\n",
    "    basename = str(os.path.splitext(os.path.basename(file_path))[0])\n",
    "    return filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_triplets[train_triplets==3450].any()[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we define a couple of tf functions as defined here https://www.tensorflow.org/tutorials/load_data/images with some helpers from opencv\n",
    "def _normalize_img(img):\n",
    "    img = tf.cast(img, tf.float32) / 255.\n",
    "    return img\n",
    "\n",
    "def decode_img(img):\n",
    "    # convert the compressed string to a 3D uint8 tensor\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    # Use `convert_image_dtype` to convert to floats in the [0,1] range.\n",
    "    img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "    # resize the image to the desired size.\n",
    "    return tf.image.resize(img, [IMG_WIDTH, IMG_HEIGHT])\n",
    "\n",
    "def process_path(file_path):\n",
    "    # In the tutorial the label is given here but for us this can only be determined at training time\n",
    "    # load the raw data from the file as a string\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = decode_img(img)\n",
    "    return img    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then we define some functions adapted to our dataset:\n",
    "def process_triplets(dataset):\n",
    "    \"\"\"this function processes the triplets and loads the appropriate images\"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_ds = list_ds.map(process_path, num_parallel_calls=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_training(ds, cache=True, shuffle_buffer_size=1000):\n",
    "    # This is a small dataset, only load it once, and keep it in memory.\n",
    "    # use `.cache(filename)` to cache preprocessing work for datasets that don't\n",
    "    # fit in memory.\n",
    "    if cache:\n",
    "        if isinstance(cache, str):\n",
    "            ds = ds.cache(cache)\n",
    "        else:\n",
    "            ds = ds.cache()\n",
    "\n",
    "    ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n",
    "\n",
    "    # Repeat forever\n",
    "    ds = ds.repeat()\n",
    "\n",
    "    ds = ds.batch(BATCH_SIZE)\n",
    "\n",
    "    # `prefetch` lets the dataset fetch batches in the background while the model\n",
    "    # is training.\n",
    "    ds = ds.prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: (None, 300, 400, 3), types: tf.float32>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = prepare_for_training(preprocessed_ds)\n",
    "# So now we have our unlabeled dataset in the correct format. \n",
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.shuffle(1024).batch(32)\n",
    "train_ds = train_ds.map(_normalize_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = train_ds.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train time\n",
    "- loop through triplets - randomly swap second and third choice\n",
    "- foorward pass ->  output is three vectors (dimensions to be determined)\n",
    "- normalize embedding (?)\n",
    "- evaluate triplet loss using euclidean distance\n",
    "- backward pass\n",
    "\n",
    "Test time\n",
    "- predict embedding\n",
    "- evaluate distance\n",
    "- take minimum -> give 0,1 label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data and preprocessing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to load n triplets depending on the batch size\n",
    "def get_triplet(row, dataset):\n",
    "    # This should actually swap them\n",
    "    row = dataset.iloc[row]\n",
    "    a = row[\"A\"]\n",
    "    p = row[\"B\"]\n",
    "    n = row[\"C\"]\n",
    "    return a, p, n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_triplet_batch(batch_index, dataset):\n",
    "    batch = []\n",
    "    for i in range(batch_index, batch_index+BATCH_SIZE):\n",
    "        batch.append(get_triplet(i, dataset))\n",
    "    return batch\n",
    "\n",
    "def get_triplet_batches(dataset):\n",
    "    num_of_batches = int(len(dataset)/BATCH_SIZE)\n",
    "    triplet_batches = []\n",
    "    for i in range(num_of_batches):\n",
    "        triplet_batches.append(get_triplet_batch(i, dataset))\n",
    "    return triplet_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet_batches = get_triplet_batches(train_triplets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we want to load the images\n",
    "\n",
    "a = []\n",
    "p = []\n",
    "n = []\n",
    "for batch in triplet_batches:\n",
    "    for triplet in batch:\n",
    "        a.append(cv2.resize(img_to_array(load_img(f\"data/food/{triplet[0]}.jpg\")), (300, 400), interpolation=cv2.INTER_NEAREST))\n",
    "        p.append(cv2.resize(img_to_array(load_img(f\"data/food/{triplet[1]}.jpg\")), (300, 400), interpolation=cv2.INTER_NEAREST))\n",
    "        n.append(cv2.resize(img_to_array(load_img(f\"data/food/{triplet[2]}.jpg\")), (300, 400), interpolation=cv2.INTER_NEAREST))\n",
    "    # model.fit([np.asarray(a), np.asarray(p), np.asarray(n)], epochs=5)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.0011105   0.00564785 -0.07175665 ...  0.0770436  -0.0287843\n",
      "  -0.1274297 ]\n",
      " [-0.05616327  0.05031188  0.00264205 ...  0.06290061 -0.02598775\n",
      "  -0.12811399]\n",
      " [-0.01504388  0.03885714 -0.02716522 ...  0.05785563 -0.04538602\n",
      "  -0.12832291]\n",
      " ...\n",
      " [ 0.05035898 -0.01174408 -0.09920428 ... -0.00512359  0.04461445\n",
      "  -0.11217123]\n",
      " [-0.04062364 -0.01577492  0.00662433 ...  0.04847068 -0.02250861\n",
      "  -0.05676426]\n",
      " [-0.04781388  0.00743341 -0.02643654 ...  0.05733903 -0.00036587\n",
      "  -0.10265759]]\n",
      "[[-0.05616327  0.05031188  0.00264205 ...  0.06290061 -0.02598775\n",
      "  -0.12811399]\n",
      " [-0.01504388  0.03885714 -0.02716522 ...  0.05785563 -0.04538602\n",
      "  -0.12832291]\n",
      " [-0.0344062   0.03933987 -0.01813139 ...  0.04065222 -0.02028476\n",
      "  -0.07383763]\n",
      " ...\n",
      " [-0.04062364 -0.01577492  0.00662433 ...  0.04847068 -0.02250861\n",
      "  -0.05676426]\n",
      " [-0.04781388  0.00743341 -0.02643654 ...  0.05733903 -0.00036587\n",
      "  -0.10265759]\n",
      " [-0.02838682  0.03429373 -0.05047571 ...  0.04863847 -0.03732213\n",
      "  -0.10110778]]\n",
      "[[-0.01504388  0.03885714 -0.02716522 ...  0.05785563 -0.04538602\n",
      "  -0.12832291]\n",
      " [-0.0344062   0.03933987 -0.01813139 ...  0.04065222 -0.02028476\n",
      "  -0.07383763]\n",
      " [-0.04915229  0.06066031 -0.01182671 ...  0.01155497 -0.03556968\n",
      "  -0.07103511]\n",
      " ...\n",
      " [-0.04781388  0.00743341 -0.02643654 ...  0.05733903 -0.00036587\n",
      "  -0.10265759]\n",
      " [-0.02838682  0.03429373 -0.05047571 ...  0.04863847 -0.03732213\n",
      "  -0.10110778]\n",
      " [-0.08862346  0.01163398 -0.03955688 ...  0.02635714 -0.0755083\n",
      "  -0.06071254]]\n",
      "[[-0.0344062   0.03933987 -0.01813139 ...  0.04065222 -0.02028476\n",
      "  -0.07383763]\n",
      " [-0.04915229  0.06066031 -0.01182671 ...  0.01155497 -0.03556968\n",
      "  -0.07103511]\n",
      " [-0.04536226 -0.01605111 -0.03590634 ...  0.04232857 -0.02497109\n",
      "  -0.08376148]\n",
      " ...\n",
      " [-0.02838682  0.03429373 -0.05047571 ...  0.04863847 -0.03732213\n",
      "  -0.10110778]\n",
      " [-0.08862346  0.01163398 -0.03955688 ...  0.02635714 -0.0755083\n",
      "  -0.06071254]\n",
      " [-0.07456224 -0.0363916   0.02076552 ... -0.01297862 -0.06643797\n",
      "  -0.04787173]]\n",
      "[[-0.04915229  0.06066031 -0.01182671 ...  0.01155497 -0.03556968\n",
      "  -0.07103511]\n",
      " [-0.04536226 -0.01605111 -0.03590634 ...  0.04232857 -0.02497109\n",
      "  -0.08376148]\n",
      " [-0.07253013  0.01753487 -0.04101747 ...  0.02954994 -0.03404288\n",
      "  -0.05350939]\n",
      " ...\n",
      " [-0.08862346  0.01163398 -0.03955688 ...  0.02635714 -0.0755083\n",
      "  -0.06071254]\n",
      " [-0.07456224 -0.0363916   0.02076552 ... -0.01297862 -0.06643797\n",
      "  -0.04787173]\n",
      " [-0.03508723  0.03041566 -0.03826993 ...  0.08938307 -0.01281898\n",
      "  -0.08652281]]\n",
      "[[-0.04536226 -0.01605111 -0.03590634 ...  0.04232857 -0.02497109\n",
      "  -0.08376148]\n",
      " [-0.07253013  0.01753487 -0.04101747 ...  0.02954994 -0.03404288\n",
      "  -0.05350939]\n",
      " [-0.0534285   0.02161023 -0.02925505 ...  0.06573202 -0.02197079\n",
      "  -0.08747695]\n",
      " ...\n",
      " [-0.07456224 -0.0363916   0.02076552 ... -0.01297862 -0.06643797\n",
      "  -0.04787173]\n",
      " [-0.03508723  0.03041566 -0.03826993 ...  0.08938307 -0.01281898\n",
      "  -0.08652281]\n",
      " [-0.08452839  0.04993946 -0.04793018 ...  0.041708   -0.02160953\n",
      "  -0.04805173]]\n",
      "[[-0.07253013  0.01753487 -0.04101747 ...  0.02954994 -0.03404288\n",
      "  -0.05350939]\n",
      " [-0.0534285   0.02161023 -0.02925505 ...  0.06573202 -0.02197079\n",
      "  -0.08747695]\n",
      " [-0.06349613  0.03591449  0.00073769 ...  0.07535663 -0.04010136\n",
      "  -0.07934114]\n",
      " ...\n",
      " [-0.03508723  0.03041566 -0.03826993 ...  0.08938307 -0.01281898\n",
      "  -0.08652281]\n",
      " [-0.08452839  0.04993946 -0.04793018 ...  0.041708   -0.02160953\n",
      "  -0.04805173]\n",
      " [-0.0157007   0.01307269 -0.02040444 ...  0.03063154 -0.06171769\n",
      "  -0.09504759]]\n",
      "[[-0.0534285   0.02161023 -0.02925505 ...  0.06573202 -0.02197079\n",
      "  -0.08747695]\n",
      " [-0.06349613  0.03591449  0.00073769 ...  0.07535663 -0.04010136\n",
      "  -0.07934114]\n",
      " [-0.02658561  0.01072232  0.00381287 ...  0.07219388 -0.04389179\n",
      "  -0.0750121 ]\n",
      " ...\n",
      " [-0.08452839  0.04993946 -0.04793018 ...  0.041708   -0.02160953\n",
      "  -0.04805173]\n",
      " [-0.0157007   0.01307269 -0.02040444 ...  0.03063154 -0.06171769\n",
      "  -0.09504759]\n",
      " [-0.06446678  0.0196016  -0.00336902 ...  0.03727269 -0.01958744\n",
      "  -0.07378238]]\n",
      "[[-0.06349613  0.03591449  0.00073769 ...  0.07535663 -0.04010136\n",
      "  -0.07934114]\n",
      " [-0.02658561  0.01072232  0.00381287 ...  0.07219388 -0.04389179\n",
      "  -0.0750121 ]\n",
      " [-0.09118526  0.02069968 -0.01019846 ...  0.06561064 -0.06364325\n",
      "  -0.05840389]\n",
      " ...\n",
      " [-0.0157007   0.01307269 -0.02040444 ...  0.03063154 -0.06171769\n",
      "  -0.09504759]\n",
      " [-0.06446678  0.0196016  -0.00336902 ...  0.03727269 -0.01958744\n",
      "  -0.07378238]\n",
      " [-0.06134593  0.01521551 -0.0469856  ...  0.06685945 -0.02945852\n",
      "  -0.09207166]]\n",
      "[[-0.02658561  0.01072232  0.00381287 ...  0.07219388 -0.04389179\n",
      "  -0.0750121 ]\n",
      " [-0.09118526  0.02069968 -0.01019846 ...  0.06561064 -0.06364325\n",
      "  -0.05840389]\n",
      " [-0.05292714  0.03678935 -0.00748534 ...  0.04226467 -0.02037033\n",
      "  -0.08085877]\n",
      " ...\n",
      " [-0.06446678  0.0196016  -0.00336902 ...  0.03727269 -0.01958744\n",
      "  -0.07378238]\n",
      " [-0.06134593  0.01521551 -0.0469856  ...  0.06685945 -0.02945852\n",
      "  -0.09207166]\n",
      " [-0.07787411  0.03531993 -0.01987386 ...  0.06154708 -0.04672166\n",
      "  -0.13144086]]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "float() argument must be a string or a number, not 'JpegImageFile'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-106-6b531a7587c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtriplet\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"data/food/{triplet[0]}.jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINTER_NEAREST\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"data/food/{triplet[1]}.jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINTER_NEAREST\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0mn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mload_img\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"data/food/{triplet[2]}.jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mINTER_NEAREST\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/iml/lib/python3.7/site-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mimg_to_array\u001b[0;34m(img, data_format, dtype)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloatx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_to_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/iml/lib/python3.7/site-packages/keras_preprocessing/image/utils.py\u001b[0m in \u001b[0;36mimg_to_array\u001b[0;34m(img, data_format, dtype)\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0;31m# or (channel, height, width)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m     \u001b[0;31m# but original PIL image has format (width, height, channel)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdata_format\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'channels_first'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/iml/lib/python3.7/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: float() argument must be a string or a number, not 'JpegImageFile'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load file names\n",
    "for direc, subdir, file in  os.walk(r\"data/food\"):\n",
    "    list_dir = file[1:]\n",
    "    \n",
    "# take half of files\n",
    "list_dir = list_dir[:int(len(list_dir)/2)]\n",
    "\n",
    "# load the image\n",
    "img_array = []\n",
    "for file in tqdm(list_dir):\n",
    "    img = load_img(os.path.join(\"data/food\", file))\n",
    "\n",
    "    # convert to numpy array\n",
    "    img_array.append(img_to_array(img))\n",
    "# in memory swapping for faster execution and less memory consumption.\n",
    "img_array = [cv2.resize(img, (300, 400), interpolation=cv2.INTER_NEAREST) for img in img_array]\n",
    "img_array = np.array(img_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split in test and training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
