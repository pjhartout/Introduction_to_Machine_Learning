{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of the solution to project 2 from scratch\n",
    "To note:\n",
    "- For clarity the df_test was renamed to df_val as the test word was used when splitting the labeled data into train and test. \n",
    "    - Val stands for validation\n",
    "\n",
    "To try out:\n",
    "- Preprocessing\n",
    "    - Tweak data imputer\n",
    "    - Tweak scaler (Robust scaler, minmax, etc..)\n",
    "    - Tweak feature selection parameter\n",
    "    - Tweak order of operations above to see the effect\n",
    "- Modelling\n",
    "    - XGBoost\n",
    "    - SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import zipfile\n",
    "import time\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import ADASYN, SMOTE\n",
    "from imblearn.under_sampling import ClusterCentroids, RandomUnderSampler\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, chi2, f_classif\n",
    "from sklearn.metrics import f1_score, mean_squared_error, accuracy_score, r2_score, roc_auc_score, recall_score, precision_score\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.metrics import label_ranking_average_precision_score as LRAPS\n",
    "from sklearn.metrics import label_ranking_loss as LRL\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LinearRegression, BayesianRidge, LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Global variables\n",
    "IDENTIFIERS = [\"pid\", \"Time\"]\n",
    "MEDICAL_TESTS = [\n",
    "    \"LABEL_BaseExcess\",\n",
    "    \"LABEL_Fibrinogen\",\n",
    "    \"LABEL_AST\",\n",
    "    \"LABEL_Alkalinephos\",\n",
    "    \"LABEL_Bilirubin_total\",\n",
    "    \"LABEL_Lactate\",\n",
    "    \"LABEL_TroponinI\",\n",
    "    \"LABEL_SaO2\",\n",
    "    \"LABEL_Bilirubin_direct\",\n",
    "    \"LABEL_EtCO2\",\n",
    "]\n",
    "VITAL_SIGNS = [\"LABEL_RRate\", \"LABEL_ABPm\", \"LABEL_SpO2\", \"LABEL_Heartrate\"]\n",
    "SEPSIS = [\"LABEL_Sepsis\"]\n",
    "ESTIMATOR = {\"bayesian\": BayesianRidge(), \"decisiontree\": DecisionTreeRegressor(max_features=\"sqrt\", random_state=0), \n",
    "                \"extratree\": ExtraTreesRegressor(n_estimators=10, random_state=0), \n",
    "                \"knn\": KNeighborsRegressor(n_neighbors=10, weights=\"distance\")}\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_f(x):\n",
    "    \"\"\"To get predictions as confidence level, the model predicts for all 12 sets of measures for\n",
    "    each patient a distance to the hyperplane ; it is then transformed into a confidence level using\n",
    "    the sigmoid function ; the confidence level reported is the mean of all confidence levels for a\n",
    "    single patient\n",
    "\n",
    "    Args:\n",
    "        x (float): input of the sigmoid function\n",
    "\n",
    "    Returns:\n",
    "       float: result of the sigmoid computation.\n",
    "\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(r\"data/train_features.csv\")\n",
    "df_train_label = pd.read_csv(r\"data/train_labels.csv\")\n",
    "df_val = pd.read_csv(r\"data/test_features.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data imputation methodology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit imputer to missing data\n",
    "pid_train = df_train[\"pid\"].unique()\n",
    "columns = df_train.columns\n",
    "df_train_preprocessed = pd.DataFrame(columns=columns, index=pid_train)\n",
    "\n",
    "imputer = SimpleImputer()\n",
    "columns = df_train.columns\n",
    "df_train = imputer.fit_transform(df_train.values)\n",
    "df_train = pd.DataFrame(df_train, columns=columns)\n",
    "for patient in tqdm(pid_train):\n",
    "    for column in df_train.columns:\n",
    "        df_train.groupby([\"pid\"], as_index=False).mean()\n",
    "        \"\"\"df_train_preprocessed.at[patient, column] = df_train.loc[\n",
    "            df_train[\"pid\"] == patient\n",
    "        ][column].mean()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tranform test data according to same imputer\n",
    "pid_val = df_val[\"pid\"].unique()\n",
    "columns = df_val.columns\n",
    "df_val_preprocessed = pd.DataFrame(columns=columns, index=pid_val)\n",
    "\n",
    "df_val = imputer.transform(df_val.values)\n",
    "df_val = pd.DataFrame(df_val, columns=columns)\n",
    "for patient in tqdm(pid_val):\n",
    "    for column in df_val.columns:\n",
    "        df_val_preprocessed.at[patient, column] = df_val.loc[\n",
    "            df_val[\"pid\"] == patient\n",
    "        ][column].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_preprocessed.to_csv(\"df_train_philip.csv\")\n",
    "df_val_preprocessed.to_csv(\"df_val_philip.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_preprocessed = pd.read_csv(\"df_train_philip.csv\")\n",
    "df_val_preprocessed = pd.read_csv(\"df_val_philip.csv\")\n",
    "df_train_preprocessed = df_train_preprocessed.sort_values(by=[\"pid\"])\n",
    "df_val_preprocessed = df_val_preprocessed.sort_values(by=[\"pid\"])\n",
    "df_train_label = df_train_label.sort_values(by=[\"pid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a list of labels for each medical test\n",
      "Creating a list of labels for each medical test\n",
      "Creating a list of labels for each vital sign\n"
     ]
    }
   ],
   "source": [
    "# Data formatting\n",
    "X_train = df_train_preprocessed.drop(columns=IDENTIFIERS+['Unnamed: 0']).values\n",
    "X_val = df_val_preprocessed.drop(columns=IDENTIFIERS+['Unnamed: 0']).values\n",
    "# Create list with different label for each medical test\n",
    "print(\"Creating a list of labels for each medical test\")\n",
    "y_train_medical_tests = []\n",
    "for test in MEDICAL_TESTS:\n",
    "    y_train_medical_tests.append(df_train_label[test].astype(int).values)\n",
    "\n",
    "# Create list with different label for sepsis\n",
    "print(\"Creating a list of labels for each medical test\")\n",
    "y_train_sepsis = []\n",
    "for sepsis in SEPSIS:\n",
    "    y_train_sepsis.append(df_train_label[sepsis].astype(int).values)\n",
    "\n",
    "# Create list with different label for each vital sign\n",
    "print(\"Creating a list of labels for each vital sign\")\n",
    "y_train_vital_signs = []\n",
    "for sign in VITAL_SIGNS:\n",
    "    y_train_vital_signs.append(df_train_label[sign].astype(int).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data \n",
    "scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling medical tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Modelling of medical tests using logistic regression with cross validation\n",
    "# models = []\n",
    "# losses = []\n",
    "# columns_medical_tests = []\n",
    "# for i, test in enumerate(MEDICAL_TESTS):\n",
    "#     print(f\"Fitting model for {test}.\")\n",
    "\n",
    "#     print(\"Applying feature selection\")\n",
    "#     feature_selector = SelectKBest(score_func=f_classif, k=3)\n",
    "#     X_train = feature_selector.fit_transform(X_train, y_train_medical_tests[i])\n",
    "#     X_test = feature_selector.transform(X_test)\n",
    "#     columns = feature_selector.get_support(indices=True)\n",
    "#     columns_medical_tests.append(columns)\n",
    "\n",
    "#     print(\"Fitting model\")\n",
    "#     clf = LogisticRegressionCV(cv=5, random_state=42).fit(X_train, y_train_medical_tests[i])\n",
    "#     models.append(clf)\n",
    "#     print(roc_auc_score(y_test, clf.predict_proba(X_test)[:,1]))\n",
    "#     print(f\"Finished test for medical tests.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model for LABEL_BaseExcess.\n",
      "Resampling\n",
      "Applying feature selection\n",
      "Fitting model\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    5.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9133649  0.15137842 0.35653293 ... 0.8404726  0.23370351 0.7504211 ]\n",
      "ROC score on test set 0.8720664367091563\n",
      "CV score 0.8499881710752918\n",
      "Fitting model for LABEL_Fibrinogen.\n",
      "Resampling\n",
      "Applying feature selection\n",
      "Fitting model\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    1.6s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9167671  0.55924815 0.41805124 ... 0.43052113 0.17055517 0.38804427]\n",
      "ROC score on test set 0.7164732394366197\n",
      "CV score 0.7069711649365629\n",
      "Fitting model for LABEL_AST.\n",
      "Resampling\n",
      "Applying feature selection\n",
      "Fitting model\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    9.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7652198  0.598451   0.38443807 ... 0.59787625 0.44218227 0.55905485]\n",
      "ROC score on test set 0.735198420677427\n",
      "CV score 0.6865353955978584\n",
      "Fitting model for LABEL_Alkalinephos.\n",
      "Resampling\n",
      "Applying feature selection\n",
      "Fitting model\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    6.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.85528696 0.62137836 0.3826815  ... 0.5930465  0.46166366 0.55182856]\n",
      "ROC score on test set 0.7346409509051555\n",
      "CV score 0.707020405683737\n",
      "Fitting model for LABEL_Bilirubin_total.\n",
      "Resampling\n",
      "Applying feature selection\n",
      "Fitting model\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    7.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.95152473 0.7586239  0.46238422 ... 0.35689822 0.37892026 0.4866535 ]\n",
      "ROC score on test set 0.7109291968599034\n",
      "CV score 0.6742333694448884\n",
      "Fitting model for LABEL_Lactate.\n",
      "Resampling\n",
      "Applying feature selection\n",
      "Fitting model\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    5.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7189623  0.28091273 0.3274959  ... 0.52449685 0.28091273 0.52449685]\n",
      "ROC score on test set 0.7413826979550004\n",
      "CV score 0.7381401210895115\n",
      "Fitting model for LABEL_TroponinI.\n",
      "Resampling\n",
      "Applying feature selection\n",
      "Fitting model\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    3.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.06050481 0.72526693 0.8421724  ... 0.27953982 0.55598676 0.16569886]\n",
      "ROC score on test set 0.7206476190476191\n",
      "CV score 0.737759430773391\n",
      "Fitting model for LABEL_SaO2.\n",
      "Resampling\n",
      "Applying feature selection\n",
      "Fitting model\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    5.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.70416594 0.2661018  0.43171635 ... 0.5904     0.31374696 0.5670996 ]\n",
      "ROC score on test set 0.7477238009408397\n",
      "CV score 0.7326060895552016\n",
      "Fitting model for LABEL_Bilirubin_direct.\n",
      "Resampling\n",
      "Applying feature selection\n",
      "Fitting model\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    1.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.84498245 0.70148903 0.15177833 ... 0.34292573 0.4206406  0.5721898 ]\n",
      "ROC score on test set 0.6785011709601874\n",
      "CV score 0.6895317878818028\n",
      "Fitting model for LABEL_EtCO2.\n",
      "Resampling\n",
      "Applying feature selection\n",
      "Fitting model\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed:    2.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.39310133 0.39310133 0.29227838 ... 0.49772987 0.29227838 0.3871921 ]\n",
      "ROC score on test set 0.7955803571428572\n",
      "CV score 0.7573856790289858\n",
      "Finished test for medical tests.\n"
     ]
    }
   ],
   "source": [
    "# Modelling using extreme gradient boosting\n",
    "clf = xgb.XGBClassifier(objective=\"binary:logistic\", n_thread=-1)\n",
    "models = []\n",
    "losses = []\n",
    "feature_selector_medical_tests = []\n",
    "for i, test in enumerate(MEDICAL_TESTS):\n",
    "    print(f\"Fitting model for {test}.\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_train_scaled, y_train_medical_tests[i], test_size=0.10, random_state=42, shuffle=True\n",
    "    )\n",
    "    # Coarse parameter grid not optimized at all yet\n",
    "    param_grid = {\n",
    "        \"booster\": [\"dart\", \"gbtree\", \"gblinear\"],\n",
    "        \"eta\": [0.4],\n",
    "        \"min_child_weight\": range(1, 10, 1),\n",
    "        \"max_depth\": range(3, 8, 1),\n",
    "        \"gamma\": range(0, 100, 2),\n",
    "        \"max_delta_step\": range(1, 10, 1),\n",
    "        \"subsample\": np.arange(0.1, 1, 0.05),\n",
    "        \"colsample_bytree\": np.arange(0.3, 1, 0.05),\n",
    "        \"n_estimators\": range(50, 120, 2),\n",
    "        \"scale_pos_weight\": [1],\n",
    "        \"reg_lambda\": [0, 1], # Ridge regularization\n",
    "        \"reg_alpha\": [0, 1], # Lasso regularization\n",
    "        \"eval_metric\": [\"error\"],\n",
    "        \"verbosity\": [1]\n",
    "    }\n",
    "    \n",
    "    print(\"Resampling\")\n",
    "    sampler = RandomUnderSampler(random_state=42)\n",
    "    X_train_res, y_train_res = sampler.fit_resample(X_train, y_train)\n",
    "    \n",
    "    print(\"Applying feature selection\")\n",
    "    feature_selector = SelectKBest(score_func=f_classif, k=5)\n",
    "    X_train_selected = feature_selector.fit_transform(X_train_res, y_train_res)\n",
    "    X_test = feature_selector.transform(X_test)\n",
    "    feature_selector_medical_tests.append(feature_selector)\n",
    "\n",
    "    print(\"Fitting model\")\n",
    "    coarse_search = RandomizedSearchCV(estimator=clf,\n",
    "            param_distributions=param_grid, scoring=\"roc_auc\",\n",
    "            n_jobs=-1, cv=5, n_iter=10, verbose=1)\n",
    "    coarse_search.fit(X_train_selected, y_train_res)\n",
    "    \n",
    "    models.append(coarse_search.best_estimator_)\n",
    "    print(coarse_search.best_estimator_.predict_proba(X_test)[:,1])\n",
    "    print(f\"ROC score on test set {roc_auc_score(y_test, coarse_search.best_estimator_.predict_proba(X_test)[:,1])}\")\n",
    "    print(f\"CV score {coarse_search.best_score_}\")\n",
    "print(f\"Finished test for medical tests.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_pids = np.unique(df_val[\"pid\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions for medical tests\n",
    "df_pred_medical_test = pd.DataFrame(index=val_pids, columns=MEDICAL_TESTS)\n",
    "for i, test in enumerate(MEDICAL_TESTS):\n",
    "    feature_selector = feature_selector_medical_tests[i]\n",
    "    X_val_vital_sign = feature_selector.transform(X_val_scaled)\n",
    "    model_for_test = models[i]\n",
    "#     print(model_for_test.predict_proba(X_val_vital_sign))\n",
    "    y_pred = model_for_test.predict_proba(X_val_vital_sign)[:, 1]\n",
    "    df_pred_medical_test[test] = y_pred\n",
    "\n",
    "df_pred_medical_test = df_pred_medical_test.reset_index().rename(columns={\"index\": \"pid\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>LABEL_BaseExcess</th>\n",
       "      <th>LABEL_Fibrinogen</th>\n",
       "      <th>LABEL_AST</th>\n",
       "      <th>LABEL_Alkalinephos</th>\n",
       "      <th>LABEL_Bilirubin_total</th>\n",
       "      <th>LABEL_Lactate</th>\n",
       "      <th>LABEL_TroponinI</th>\n",
       "      <th>LABEL_SaO2</th>\n",
       "      <th>LABEL_Bilirubin_direct</th>\n",
       "      <th>LABEL_EtCO2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.871570</td>\n",
       "      <td>0.414509</td>\n",
       "      <td>0.734938</td>\n",
       "      <td>0.797877</td>\n",
       "      <td>0.940729</td>\n",
       "      <td>0.727136</td>\n",
       "      <td>0.186444</td>\n",
       "      <td>0.632642</td>\n",
       "      <td>0.746171</td>\n",
       "      <td>0.393101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0.191440</td>\n",
       "      <td>0.262532</td>\n",
       "      <td>0.447075</td>\n",
       "      <td>0.462094</td>\n",
       "      <td>0.482383</td>\n",
       "      <td>0.280913</td>\n",
       "      <td>0.704378</td>\n",
       "      <td>0.347416</td>\n",
       "      <td>0.454505</td>\n",
       "      <td>0.292278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>0.346440</td>\n",
       "      <td>0.262532</td>\n",
       "      <td>0.486703</td>\n",
       "      <td>0.442523</td>\n",
       "      <td>0.507434</td>\n",
       "      <td>0.327496</td>\n",
       "      <td>0.428069</td>\n",
       "      <td>0.469386</td>\n",
       "      <td>0.454505</td>\n",
       "      <td>0.292278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>0.871570</td>\n",
       "      <td>0.993759</td>\n",
       "      <td>0.861413</td>\n",
       "      <td>0.887471</td>\n",
       "      <td>0.840414</td>\n",
       "      <td>0.554652</td>\n",
       "      <td>0.279540</td>\n",
       "      <td>0.590400</td>\n",
       "      <td>0.905170</td>\n",
       "      <td>0.393101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9</td>\n",
       "      <td>0.272734</td>\n",
       "      <td>0.281472</td>\n",
       "      <td>0.486703</td>\n",
       "      <td>0.555995</td>\n",
       "      <td>0.628334</td>\n",
       "      <td>0.532791</td>\n",
       "      <td>0.190030</td>\n",
       "      <td>0.257057</td>\n",
       "      <td>0.495337</td>\n",
       "      <td>0.292278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12659</th>\n",
       "      <td>31647</td>\n",
       "      <td>0.335368</td>\n",
       "      <td>0.262532</td>\n",
       "      <td>0.447075</td>\n",
       "      <td>0.391918</td>\n",
       "      <td>0.396152</td>\n",
       "      <td>0.280913</td>\n",
       "      <td>0.082862</td>\n",
       "      <td>0.330013</td>\n",
       "      <td>0.454505</td>\n",
       "      <td>0.292278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12660</th>\n",
       "      <td>31649</td>\n",
       "      <td>0.233704</td>\n",
       "      <td>0.473012</td>\n",
       "      <td>0.739733</td>\n",
       "      <td>0.742696</td>\n",
       "      <td>0.491331</td>\n",
       "      <td>0.409006</td>\n",
       "      <td>0.704378</td>\n",
       "      <td>0.313747</td>\n",
       "      <td>0.834073</td>\n",
       "      <td>0.292278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12661</th>\n",
       "      <td>31651</td>\n",
       "      <td>0.863581</td>\n",
       "      <td>0.347140</td>\n",
       "      <td>0.447075</td>\n",
       "      <td>0.491088</td>\n",
       "      <td>0.870510</td>\n",
       "      <td>0.608233</td>\n",
       "      <td>0.303133</td>\n",
       "      <td>0.684031</td>\n",
       "      <td>0.348651</td>\n",
       "      <td>0.393101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12662</th>\n",
       "      <td>31652</td>\n",
       "      <td>0.188422</td>\n",
       "      <td>0.244060</td>\n",
       "      <td>0.442182</td>\n",
       "      <td>0.461664</td>\n",
       "      <td>0.243381</td>\n",
       "      <td>0.280913</td>\n",
       "      <td>0.664075</td>\n",
       "      <td>0.266102</td>\n",
       "      <td>0.148458</td>\n",
       "      <td>0.393101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12663</th>\n",
       "      <td>31655</td>\n",
       "      <td>0.191440</td>\n",
       "      <td>0.274955</td>\n",
       "      <td>0.506486</td>\n",
       "      <td>0.513444</td>\n",
       "      <td>0.523357</td>\n",
       "      <td>0.280913</td>\n",
       "      <td>0.363043</td>\n",
       "      <td>0.347416</td>\n",
       "      <td>0.454505</td>\n",
       "      <td>0.393101</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12664 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         pid  LABEL_BaseExcess  LABEL_Fibrinogen  LABEL_AST  \\\n",
       "0          0          0.871570          0.414509   0.734938   \n",
       "1          3          0.191440          0.262532   0.447075   \n",
       "2          5          0.346440          0.262532   0.486703   \n",
       "3          7          0.871570          0.993759   0.861413   \n",
       "4          9          0.272734          0.281472   0.486703   \n",
       "...      ...               ...               ...        ...   \n",
       "12659  31647          0.335368          0.262532   0.447075   \n",
       "12660  31649          0.233704          0.473012   0.739733   \n",
       "12661  31651          0.863581          0.347140   0.447075   \n",
       "12662  31652          0.188422          0.244060   0.442182   \n",
       "12663  31655          0.191440          0.274955   0.506486   \n",
       "\n",
       "       LABEL_Alkalinephos  LABEL_Bilirubin_total  LABEL_Lactate  \\\n",
       "0                0.797877               0.940729       0.727136   \n",
       "1                0.462094               0.482383       0.280913   \n",
       "2                0.442523               0.507434       0.327496   \n",
       "3                0.887471               0.840414       0.554652   \n",
       "4                0.555995               0.628334       0.532791   \n",
       "...                   ...                    ...            ...   \n",
       "12659            0.391918               0.396152       0.280913   \n",
       "12660            0.742696               0.491331       0.409006   \n",
       "12661            0.491088               0.870510       0.608233   \n",
       "12662            0.461664               0.243381       0.280913   \n",
       "12663            0.513444               0.523357       0.280913   \n",
       "\n",
       "       LABEL_TroponinI  LABEL_SaO2  LABEL_Bilirubin_direct  LABEL_EtCO2  \n",
       "0             0.186444    0.632642                0.746171     0.393101  \n",
       "1             0.704378    0.347416                0.454505     0.292278  \n",
       "2             0.428069    0.469386                0.454505     0.292278  \n",
       "3             0.279540    0.590400                0.905170     0.393101  \n",
       "4             0.190030    0.257057                0.495337     0.292278  \n",
       "...                ...         ...                     ...          ...  \n",
       "12659         0.082862    0.330013                0.454505     0.292278  \n",
       "12660         0.704378    0.313747                0.834073     0.292278  \n",
       "12661         0.303133    0.684031                0.348651     0.393101  \n",
       "12662         0.664075    0.266102                0.148458     0.393101  \n",
       "12663         0.363043    0.347416                0.454505     0.393101  \n",
       "\n",
       "[12664 rows x 11 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred_medical_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling sepsis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling\n",
      "Applying feature selection\n",
      "Fitting model\n",
      "[0 0 0 ... 1 1 1]\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   24.6s\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:   29.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC score on test set 0.7518721421525136\n",
      "CV score 0.6942415326633167\n",
      "Finished test for medical tests.\n"
     ]
    }
   ],
   "source": [
    "# Model and predict sepsis\n",
    "\n",
    "clf = xgb.XGBClassifier(objective=\"binary:logistic\", n_thread=-1)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_train_scaled, y_train_sepsis[0], test_size=0.10, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "        \"booster\": [\"dart\", \"gbtree\", \"gblinear\"],\n",
    "        \"eta\": [0.01],\n",
    "        \"min_child_weight\": range(1, 10, 1),\n",
    "        \"max_depth\": range(3, 8, 1),\n",
    "        \"gamma\": range(0, 100, 2),\n",
    "        \"max_delta_step\": range(1, 10, 1),\n",
    "        \"subsample\": np.arange(0.1, 1, 0.05),\n",
    "        \"colsample_bytree\": np.arange(0.3, 1, 0.05),\n",
    "        \"n_estimators\": range(50, 120, 2),\n",
    "        \"scale_pos_weight\": [1],\n",
    "        \"reg_lambda\": [0, 1], # Ridge regularization\n",
    "        \"reg_alpha\": [0, 1], # Lasso regularization\n",
    "        \"eval_metric\": [\"error\"],\n",
    "        \"verbosity\": [1]\n",
    "    }\n",
    "\n",
    "print(\"Resampling\")\n",
    "sampler = RandomUnderSampler()\n",
    "X_train_res, y_train_res = sampler.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"Applying feature selection\")\n",
    "feature_selector = SelectKBest(score_func=f_classif, k=30)\n",
    "X_train = feature_selector.fit_transform(X_train_res, y_train_res)\n",
    "X_test = feature_selector.transform(X_test)\n",
    "\n",
    "\n",
    "print(\"Fitting model\")\n",
    "coarse_search = RandomizedSearchCV(estimator=clf,\n",
    "        param_distributions=param_grid, scoring=\"roc_auc\",\n",
    "        n_jobs=-1, cv=5, n_iter=50, verbose=1)\n",
    "print(y_train_res)\n",
    "coarse_search.fit(X_train, y_train_res)\n",
    "\n",
    "sepsis_model = coarse_search.best_estimator_\n",
    "print(f\"ROC score on test set {roc_auc_score(y_test, coarse_search.best_estimator_.predict_proba(X_test)[:,1])}\")\n",
    "print(f\"CV score {coarse_search.best_score_}\")\n",
    "print(f\"Finished test for medical tests.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_sepsis = feature_selector.transform(X_val_scaled)\n",
    "y_pred = sepsis_model.predict_proba(X_val_sepsis)[:,1]\n",
    "df_pred_sepsis = pd.DataFrame(y_pred, index=val_pids, columns=SEPSIS)\n",
    "df_pred_sepsis = df_pred_sepsis.reset_index().rename(columns={\"index\": \"pid\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling vital signsy_train_sepsis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model for LABEL_RRate.\n",
      "Applying feature selection\n",
      "Fitting model\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    6.6s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   57.2s\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score 0.37595759997833506\n",
      "Test score is 0.35855085021886113\n",
      "Finished test for medical tests.\n",
      "Fitting model for LABEL_ABPm.\n",
      "Applying feature selection\n",
      "Fitting model\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    6.5s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   42.8s\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score 0.5726707286905983\n",
      "Test score is 0.5834844838976045\n",
      "Finished test for medical tests.\n",
      "Fitting model for LABEL_SpO2.\n",
      "Applying feature selection\n",
      "Fitting model\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:    7.1s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   38.9s\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:   56.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score 0.30585736553756443\n",
      "Test score is 0.3310165791896157\n",
      "Finished test for medical tests.\n",
      "Fitting model for LABEL_Heartrate.\n",
      "Applying feature selection\n",
      "Fitting model\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   12.9s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:   56.0s\n",
      "[Parallel(n_jobs=-1)]: Done 250 out of 250 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score 0.5960190629449306\n",
      "Test score is 0.6037441796227132\n",
      "Finished test for medical tests.\n"
     ]
    }
   ],
   "source": [
    "# Modelling of vital signs\n",
    "models = []\n",
    "losses = []\n",
    "feature_selectors_vital_signs = []\n",
    "clf = xgb.XGBRegressor(objective=\"reg:squarederror\", n_thread=-1)\n",
    "\n",
    "for i, sign in enumerate(VITAL_SIGNS):\n",
    "    print(f\"Fitting model for {sign}.\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_train_scaled, y_train_vital_signs[i], test_size=0.10, random_state=42, shuffle=True\n",
    "    )\n",
    "\n",
    "    print(\"Applying feature selection\")\n",
    "    feature_selector = SelectKBest(score_func=f_classif, k=5)\n",
    "    X_train_selected = feature_selector.fit_transform(X_train, y_train)\n",
    "    X_test_selected = feature_selector.transform(X_test)\n",
    "    feature_selectors_vital_signs.append(feature_selector)\n",
    "\n",
    "    print(\"Fitting model\")\n",
    "    \n",
    "    param_grid = {\n",
    "        \"booster\": [\"dart\", \"gbtree\", \"gblinear\"],\n",
    "        \"eta\": [0.4],\n",
    "        \"min_child_weight\": range(1, 10, 1),\n",
    "        \"max_depth\": range(3, 8, 1),\n",
    "        \"gamma\": range(0, 100, 2),\n",
    "        \"max_delta_step\": range(1, 10, 1),\n",
    "        \"subsample\": np.arange(0.1, 1, 0.05),\n",
    "        \"colsample_bytree\": np.arange(0.3, 1, 0.05),\n",
    "        \"n_estimators\": range(50, 120, 2),\n",
    "        \"scale_pos_weight\": [1],\n",
    "        \"reg_lambda\": [0], # Ridge regularization\n",
    "        \"reg_alpha\": [1], # Lasso regularization\n",
    "        \"eval_metric\": [\"error\"],\n",
    "        \"verbosity\": [1]\n",
    "    }\n",
    "    \n",
    "    coarse_search = RandomizedSearchCV(estimator=clf,\n",
    "            param_distributions=param_grid, scoring=\"r2\",\n",
    "            n_jobs=-1, cv=5, n_iter=50, verbose=1)\n",
    "    coarse_search.fit(X_train_selected, y_train)\n",
    "    models.append(coarse_search.best_estimator_)\n",
    "    print(f\"CV score {coarse_search.best_score_}\")\n",
    "    print(f\"Test score is {r2_score(y_test, coarse_search.best_estimator_.predict(X_test_selected))}\")\n",
    "    print(f\"Finished test for medical tests.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions for medical tests\n",
    "df_pred_vital_signs = pd.DataFrame(index=val_pids, columns=VITAL_SIGNS)\n",
    "for i, test in enumerate(VITAL_SIGNS):\n",
    "    feature_selector = feature_selectors_vital_signs[i]\n",
    "    X_val_vital_sign = feature_selector.transform(X_val_scaled)\n",
    "    model_for_test = models[i]\n",
    "    y_pred = model_for_test.predict(X_val_vital_sign)\n",
    "    df_pred_vital_signs[test] = y_pred\n",
    "\n",
    "df_pred_vital_signs = df_pred_vital_signs.reset_index().rename(columns={\"index\": \"pid\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to ZIP file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Export predictions DataFrame to a zip file\n",
      "         pid  LABEL_BaseExcess  LABEL_Fibrinogen  LABEL_AST  \\\n",
      "0          0          0.871570          0.414509   0.734938   \n",
      "1          3          0.191440          0.262532   0.447075   \n",
      "2          5          0.346440          0.262532   0.486703   \n",
      "3          7          0.871570          0.993759   0.861413   \n",
      "4          9          0.272734          0.281472   0.486703   \n",
      "...      ...               ...               ...        ...   \n",
      "12659  31647          0.335368          0.262532   0.447075   \n",
      "12660  31649          0.233704          0.473012   0.739733   \n",
      "12661  31651          0.863581          0.347140   0.447075   \n",
      "12662  31652          0.188422          0.244060   0.442182   \n",
      "12663  31655          0.191440          0.274955   0.506486   \n",
      "\n",
      "       LABEL_Alkalinephos  LABEL_Bilirubin_total  LABEL_Lactate  \\\n",
      "0                0.797877               0.940729       0.727136   \n",
      "1                0.462094               0.482383       0.280913   \n",
      "2                0.442523               0.507434       0.327496   \n",
      "3                0.887471               0.840414       0.554652   \n",
      "4                0.555995               0.628334       0.532791   \n",
      "...                   ...                    ...            ...   \n",
      "12659            0.391918               0.396152       0.280913   \n",
      "12660            0.742696               0.491331       0.409006   \n",
      "12661            0.491088               0.870510       0.608233   \n",
      "12662            0.461664               0.243381       0.280913   \n",
      "12663            0.513444               0.523357       0.280913   \n",
      "\n",
      "       LABEL_TroponinI  LABEL_SaO2  LABEL_Bilirubin_direct  LABEL_EtCO2  \\\n",
      "0             0.186444    0.632642                0.746171     0.393101   \n",
      "1             0.704378    0.347416                0.454505     0.292278   \n",
      "2             0.428069    0.469386                0.454505     0.292278   \n",
      "3             0.279540    0.590400                0.905170     0.393101   \n",
      "4             0.190030    0.257057                0.495337     0.292278   \n",
      "...                ...         ...                     ...          ...   \n",
      "12659         0.082862    0.330013                0.454505     0.292278   \n",
      "12660         0.704378    0.313747                0.834073     0.292278   \n",
      "12661         0.303133    0.684031                0.348651     0.393101   \n",
      "12662         0.664075    0.266102                0.148458     0.393101   \n",
      "12663         0.363043    0.347416                0.454505     0.393101   \n",
      "\n",
      "       LABEL_Sepsis  LABEL_RRate  LABEL_ABPm  LABEL_SpO2  LABEL_Heartrate  \n",
      "0          0.577138    15.736718   85.725754   97.661491        85.047966  \n",
      "1          0.388442    17.514509   84.273941   96.409378        91.425652  \n",
      "2          0.372102    18.120407   71.549240   95.587563        66.753792  \n",
      "3          0.555321    17.050400   87.037567   97.455124        94.772995  \n",
      "4          0.551946    19.805840   88.633247   95.447983        89.689674  \n",
      "...             ...          ...         ...         ...              ...  \n",
      "12659      0.370323    16.804358   69.773308   96.349358        71.669464  \n",
      "12660      0.518852    15.390469   83.029129   96.172165        88.567184  \n",
      "12661      0.520448    16.867298   76.939453   97.582375        85.320686  \n",
      "12662      0.435854    18.136417   94.106163   96.924011       110.513992  \n",
      "12663      0.429495    18.697035   87.352577   98.005089       106.435127  \n",
      "\n",
      "[12664 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "df_predictions = pd.merge(df_pred_medical_test, df_pred_sepsis, on=\"pid\")\n",
    "df_predictions = pd.merge(df_predictions, df_pred_vital_signs, on=\"pid\")\n",
    "print(\"Export predictions DataFrame to a zip file\")\n",
    "print(df_predictions)\n",
    "df_predictions.to_csv(\n",
    "    \"predictions.csv\",\n",
    "    index=None,\n",
    "    sep=\",\",\n",
    "    header=True,\n",
    "    encoding=\"utf-8-sig\",\n",
    "    float_format=\"%.2f\",\n",
    ")\n",
    "\n",
    "with zipfile.ZipFile(\"predictions.zip\", \"w\", compression=zipfile.ZIP_DEFLATED) as zf:\n",
    "    zf.write(\"predictions.csv\")\n",
    "os.remove(\"predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
