{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of the solution to project 2 from scratch\n",
    "To note:\n",
    "- For clarity the df_test was renamed to df_val as the test word was used when splitting the labeled data into train and test. \n",
    "    - Val stands for validation\n",
    "\n",
    "To try out:\n",
    "- Preprocessing\n",
    "    - Tweak data imputer\n",
    "    - Tweak scaler (Robust scaler, minmax, etc..)\n",
    "    - Tweak feature selection parameter\n",
    "    - Tweak order of operations above to see the effect\n",
    "- Modelling\n",
    "    - XGBoost\n",
    "    - SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import zipfile\n",
    "import time\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import ADASYN, SMOTE\n",
    "from imblearn.under_sampling import ClusterCentroids, RandomUnderSampler\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, chi2, f_classif\n",
    "from sklearn.metrics import f1_score, mean_squared_error, accuracy_score, r2_score, roc_auc_score, recall_score, precision_score\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.metrics import label_ranking_average_precision_score as LRAPS\n",
    "from sklearn.metrics import label_ranking_loss as LRL\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LinearRegression, BayesianRidge, LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Global variables\n",
    "IDENTIFIERS = [\"pid\", \"Time\"]\n",
    "MEDICAL_TESTS = [\n",
    "    \"LABEL_BaseExcess\",\n",
    "    \"LABEL_Fibrinogen\",\n",
    "    \"LABEL_AST\",\n",
    "    \"LABEL_Alkalinephos\",\n",
    "    \"LABEL_Bilirubin_total\",\n",
    "    \"LABEL_Lactate\",\n",
    "    \"LABEL_TroponinI\",\n",
    "    \"LABEL_SaO2\",\n",
    "    \"LABEL_Bilirubin_direct\",\n",
    "    \"LABEL_EtCO2\",\n",
    "]\n",
    "VITAL_SIGNS = [\"LABEL_RRate\", \"LABEL_ABPm\", \"LABEL_SpO2\", \"LABEL_Heartrate\"]\n",
    "SEPSIS = [\"LABEL_Sepsis\"]\n",
    "ESTIMATOR = {\"bayesian\": BayesianRidge(), \"decisiontree\": DecisionTreeRegressor(max_features=\"sqrt\", random_state=0), \n",
    "                \"extratree\": ExtraTreesRegressor(n_estimators=10, random_state=0), \n",
    "                \"knn\": KNeighborsRegressor(n_neighbors=10, weights=\"distance\")}\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_f(x):\n",
    "    \"\"\"To get predictions as confidence level, the model predicts for all 12 sets of measures for\n",
    "    each patient a distance to the hyperplane ; it is then transformed into a confidence level using\n",
    "    the sigmoid function ; the confidence level reported is the mean of all confidence levels for a\n",
    "    single patient\n",
    "\n",
    "    Args:\n",
    "        x (float): input of the sigmoid function\n",
    "\n",
    "    Returns:\n",
    "       float: result of the sigmoid computation.\n",
    "\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(r\"data/train_features.csv\")\n",
    "df_train_label = pd.read_csv(r\"data/train_labels.csv\")\n",
    "df_val = pd.read_csv(r\"data/test_features.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data imputation methodology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit imputer to missing data\n",
    "pid_train = df_train[\"pid\"].unique()\n",
    "columns = df_train.columns\n",
    "df_train_preprocessed = pd.DataFrame(columns=columns, index=pid_train)\n",
    "\n",
    "imputer = SimpleImputer()\n",
    "columns = df_train.columns\n",
    "df_train = imputer.fit_transform(df_train.values)\n",
    "df_train = pd.DataFrame(df_train, columns=columns)\n",
    "for patient in tqdm(pid_train):\n",
    "    for column in df_train.columns:\n",
    "        df_train_preprocessed.at[patient, column] = df_train.loc[\n",
    "            df_train[\"pid\"] == patient\n",
    "        ][column].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tranform test data according to same imputer\n",
    "pid_val = df_val[\"pid\"].unique()\n",
    "columns = df_val.columns\n",
    "df_val_preprocessed = pd.DataFrame(columns=columns, index=pid_val)\n",
    "\n",
    "columns = df_val.columns\n",
    "df_val = imputer.transform(df_val.values)\n",
    "df_val = pd.DataFrame(df_val, columns=columns)\n",
    "for patient in tqdm(pid_val):\n",
    "    for column in df_val.columns:\n",
    "        df_val_preprocessed.at[patient, column] = df_val.loc[\n",
    "            df_val[\"pid\"] == patient\n",
    "        ][column].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_preprocessed.to_csv(\"df_train_philip.csv\")\n",
    "df_val_preprocessed.to_csv(\"df_val_philip.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_preprocessed = pd.read_csv(\"df_train_philip.csv\")\n",
    "df_val_preprocessed = pd.read_csv(\"df_val_philip.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a list of labels for each medical test\n",
      "Creating a list of labels for each medical test\n",
      "Creating a list of labels for each vital sign\n"
     ]
    }
   ],
   "source": [
    "# Data formatting\n",
    "X_train = df_train_preprocessed.drop(columns=IDENTIFIERS).values\n",
    "X_val = df_val_preprocessed.drop(columns=IDENTIFIERS).values\n",
    "# Create list with different label for each medical test\n",
    "print(\"Creating a list of labels for each medical test\")\n",
    "y_train_medical_tests = []\n",
    "for test in MEDICAL_TESTS:\n",
    "    y_train_medical_tests.append(df_train_label[test].astype(int).values)\n",
    "\n",
    "# Create list with different label for sepsis\n",
    "print(\"Creating a list of labels for each medical test\")\n",
    "y_train_sepsis = []\n",
    "for sepsis in SEPSIS:\n",
    "    y_train_sepsis.append(df_train_label[sepsis].astype(int).values)\n",
    "\n",
    "# Create list with different label for each vital sign\n",
    "print(\"Creating a list of labels for each vital sign\")\n",
    "y_train_vital_signs = []\n",
    "for sign in VITAL_SIGNS:\n",
    "    y_train_vital_signs.append(df_train_label[sign].astype(int).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data \n",
    "scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling medical tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Modelling of medical tests using logistic regression with cross validation\n",
    "# models = []\n",
    "# losses = []\n",
    "# columns_medical_tests = []\n",
    "# for i, test in enumerate(MEDICAL_TESTS):\n",
    "#     print(f\"Fitting model for {test}.\")\n",
    "\n",
    "#     print(\"Applying feature selection\")\n",
    "#     feature_selector = SelectKBest(score_func=f_classif, k=3)\n",
    "#     X_train = feature_selector.fit_transform(X_train, y_train_medical_tests[i])\n",
    "#     X_test = feature_selector.transform(X_test)\n",
    "#     columns = feature_selector.get_support(indices=True)\n",
    "#     columns_medical_tests.append(columns)\n",
    "\n",
    "#     print(\"Fitting model\")\n",
    "#     clf = LogisticRegressionCV(cv=5, random_state=42).fit(X_train, y_train_medical_tests[i])\n",
    "#     models.append(clf)\n",
    "#     print(roc_auc_score(y_test, clf.predict_proba(X_test)[:,1]))\n",
    "#     print(f\"Finished test for medical tests.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model for LABEL_BaseExcess.\n",
      "Resampling\n",
      "Applying feature selection\n",
      "Fitting model\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.2s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   20.4s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:   24.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2007269  0.15766926 0.7120504  ... 0.2723564  0.22081883 0.21603867]\n",
      "ROC score on test set 0.8637883581727395\n",
      "CV score 0.8614883692850748\n",
      "Fitting model for LABEL_Fibrinogen.\n",
      "Resampling\n",
      "Applying feature selection\n",
      "Fitting model\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 328 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done 477 out of 500 | elapsed:    5.9s remaining:    0.3s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:    6.1s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.355957   0.3287823  0.62840647 ... 0.6543695  0.343452   0.3434726 ]\n",
      "ROC score on test set 0.7571069414918199\n",
      "CV score 0.7337220367413428\n",
      "Fitting model for LABEL_AST.\n",
      "Resampling\n",
      "Applying feature selection\n",
      "Fitting model\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:    3.8s\n",
      "[Parallel(n_jobs=-1)]: Done 200 tasks      | elapsed:   10.7s\n",
      "[Parallel(n_jobs=-1)]: Done 450 tasks      | elapsed:   21.6s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:   24.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3520337  0.29511055 0.27799216 ... 0.6747026  0.3986621  0.34382242]\n",
      "ROC score on test set 0.7188894287127875\n",
      "CV score 0.69814238805551\n",
      "Fitting model for LABEL_Alkalinephos.\n",
      "Resampling\n",
      "Applying feature selection\n",
      "Fitting model\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.4s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    9.6s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   22.0s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:   25.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.34052482 0.35821488 0.3142905  ... 0.64606506 0.36751089 0.350552  ]\n",
      "ROC score on test set 0.7209169397186102\n",
      "CV score 0.70713486050038\n",
      "Fitting model for LABEL_Bilirubin_total.\n",
      "Resampling\n",
      "Applying feature selection\n",
      "Fitting model\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 224 tasks      | elapsed:   13.0s\n",
      "[Parallel(n_jobs=-1)]: Done 474 tasks      | elapsed:   25.7s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:   26.9s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.34983394 0.3609466  0.2783976  ... 0.64436424 0.38911775 0.34983394]\n",
      "ROC score on test set 0.7286266962138997\n",
      "CV score 0.7159922726347869\n",
      "Fitting model for LABEL_Lactate.\n",
      "Resampling\n",
      "Applying feature selection\n",
      "Fitting model\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.1s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:    7.9s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   17.5s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:   20.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6617697  0.2889779  0.6748714  ... 0.72084343 0.29953173 0.34955317]\n",
      "ROC score on test set 0.7643579273144993\n",
      "CV score 0.7541476305699097\n",
      "Fitting model for LABEL_TroponinI.\n",
      "Resampling\n",
      "Applying feature selection\n",
      "Fitting model\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  28 tasks      | elapsed:    0.8s\n",
      "[Parallel(n_jobs=-1)]: Done 328 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=-1)]: Done 477 out of 500 | elapsed:    8.3s remaining:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:    8.5s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.28923148 0.64543474 0.36900583 ... 0.25142214 0.60242796 0.22499003]\n",
      "ROC score on test set 0.7173066052971575\n",
      "CV score 0.7307102328512185\n",
      "Fitting model for LABEL_SaO2.\n",
      "Resampling\n",
      "Applying feature selection\n",
      "Fitting model\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.4s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   11.2s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   27.2s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:   30.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6241678  0.39949998 0.7719695  ... 0.3062304  0.38566342 0.17879733]\n",
      "ROC score on test set 0.7549642873545678\n",
      "CV score 0.7497046076580526\n",
      "Fitting model for LABEL_Bilirubin_direct.\n",
      "Resampling\n",
      "Applying feature selection\n",
      "Fitting model\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    0.4s\n",
      "[Parallel(n_jobs=-1)]: Done 328 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 477 out of 500 | elapsed:    3.3s remaining:    0.2s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:    3.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.41245383 0.27477345 0.37068772 ... 0.5520532  0.27477345 0.36429635]\n",
      "ROC score on test set 0.7674199843871976\n",
      "CV score 0.6987457964381653\n",
      "Fitting model for LABEL_EtCO2.\n",
      "Resampling\n",
      "Applying feature selection\n",
      "Fitting model\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  29 tasks      | elapsed:    0.6s\n",
      "[Parallel(n_jobs=-1)]: Done 328 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done 477 out of 500 | elapsed:    5.6s remaining:    0.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.33455676 0.2665775  0.11448496 ... 0.3534253  0.17914297 0.17474297]\n",
      "ROC score on test set 0.8407192524989135\n",
      "CV score 0.803455114638448\n",
      "Finished test for medical tests.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:    5.9s finished\n"
     ]
    }
   ],
   "source": [
    "# Modelling using extreme gradient boosting\n",
    "clf = xgb.XGBClassifier(objective=\"binary:logistic\", n_thread=-1)\n",
    "models = []\n",
    "losses = []\n",
    "feature_selector_medical_tests = []\n",
    "for i, test in enumerate(MEDICAL_TESTS):\n",
    "    print(f\"Fitting model for {test}.\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_train_scaled, y_train_medical_tests[i], test_size=0.10, random_state=42, shuffle=True\n",
    "    )\n",
    "    # Coarse parameter grid not optimized at all yet\n",
    "    param_grid = {\n",
    "        \"booster\": [\"dart\", \"gbtree\", \"gblinear\"],\n",
    "        \"eta\": np.arange(0.01, 0.4, 0.015),\n",
    "        \"min_child_weight\": range(1, 10, 1),\n",
    "        \"max_depth\": range(3, 8, 1),\n",
    "        \"gamma\": range(0, 100, 2),\n",
    "        \"max_delta_step\": range(1, 10, 1),\n",
    "        \"subsample\": np.arange(0.1, 1, 0.05),\n",
    "        \"colsample_bytree\": np.arange(0.3, 1, 0.05),\n",
    "        \"n_estimators\": range(50, 120, 2),\n",
    "        \"scale_pos_weight\": [1],\n",
    "        \"reg_lambda\": [0, 1], # Ridge regularization\n",
    "        \"reg_alpha\": [0, 1], # Lasso regularization\n",
    "        \"eval_metric\": [\"error\"],\n",
    "        \"verbosity\": [1]\n",
    "    }\n",
    "    \n",
    "    print(\"Resampling\")\n",
    "    sampler = RandomUnderSampler(random_state=42)\n",
    "    X_train_res, y_train_res = sampler.fit_resample(X_train, y_train)\n",
    "    \n",
    "    print(\"Applying feature selection\")\n",
    "    feature_selector = SelectKBest(score_func=f_classif, k=5)\n",
    "    X_train_selected = feature_selector.fit_transform(X_train_res, y_train_res)\n",
    "    X_test = feature_selector.transform(X_test)\n",
    "    feature_selector_medical_tests.append(feature_selector)\n",
    "\n",
    "    print(\"Fitting model\")\n",
    "    coarse_search = RandomizedSearchCV(estimator=clf,\n",
    "            param_distributions=param_grid, scoring=\"roc_auc\",\n",
    "            n_jobs=-1, cv=5, n_iter=100, verbose=1)\n",
    "    coarse_search.fit(X_train_selected, y_train_res)\n",
    "    \n",
    "    models.append(coarse_search.best_estimator_)\n",
    "    print(coarse_search.best_estimator_.predict_proba(X_test)[:,1])\n",
    "    print(f\"ROC score on test set {roc_auc_score(y_test, coarse_search.best_estimator_.predict_proba(X_test)[:,1])}\")\n",
    "    print(f\"CV score {coarse_search.best_score_}\")\n",
    "print(f\"Finished test for medical tests.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions for medical tests\n",
    "val_pids = np.unique(df_val[\"pid\"].values)\n",
    "df_pred_medical_test = pd.DataFrame(index=val_pids, columns=MEDICAL_TESTS)\n",
    "for i, test in enumerate(MEDICAL_TESTS):\n",
    "    col_for_medical_test = columns_medical_tests[i]\n",
    "    feature_selector = feature_selector_medical_tests[i]\n",
    "    X_val_vital_sign = feature_selector.transform(X_val_scaled)\n",
    "    model_for_test = models[i]\n",
    "#     print(model_for_test.predict_proba(X_val_vital_sign))\n",
    "    y_pred = model_for_test.predict_proba(X_val_vital_sign)[:, 1]\n",
    "    df_pred_medical_test[test] = y_pred\n",
    "\n",
    "df_pred_medical_test = df_pred_medical_test.reset_index().rename(columns={\"index\": \"pid\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling sepsis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling\n",
      "Applying feature selection\n",
      "Fitting model\n",
      "[0 0 0 ... 1 1 1]\n",
      "Fitting 5 folds for each of 200 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 tasks      | elapsed:    1.0s\n",
      "[Parallel(n_jobs=-1)]: Done 328 tasks      | elapsed:    8.5s\n",
      "[Parallel(n_jobs=-1)]: Done 606 tasks      | elapsed:   17.8s\n",
      "[Parallel(n_jobs=-1)]: Done 956 tasks      | elapsed:   27.6s\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed:   29.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC score on test set 0.7158712541620421\n",
      "CV score 0.7174778083868992\n",
      "Finished test for medical tests.\n"
     ]
    }
   ],
   "source": [
    "# Model and predict sepsis\n",
    "\n",
    "clf = xgb.XGBClassifier(objective=\"binary:logistic\", n_thread=-1)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_train_scaled, y_train_sepsis[0], test_size=0.10, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "        \"booster\": [\"dart\", \"gbtree\", \"gblinear\"],\n",
    "        \"eta\": np.arange(0.01, 0.4, 0.015),\n",
    "        \"min_child_weight\": range(1, 10, 1),\n",
    "        \"max_depth\": range(3, 8, 1),\n",
    "        \"gamma\": range(0, 100, 2),\n",
    "        \"max_delta_step\": range(1, 10, 1),\n",
    "        \"subsample\": np.arange(0.1, 1, 0.05),\n",
    "        \"colsample_bytree\": np.arange(0.3, 1, 0.05),\n",
    "        \"n_estimators\": range(50, 120, 2),\n",
    "        \"scale_pos_weight\": [1],\n",
    "        \"reg_lambda\": [0, 1], # Ridge regularization\n",
    "        \"reg_alpha\": [0, 1], # Lasso regularization\n",
    "        \"eval_metric\": [\"error\"],\n",
    "        \"verbosity\": [1]\n",
    "    }\n",
    "\n",
    "print(\"Resampling\")\n",
    "sampler = RandomUnderSampler()\n",
    "X_train_res, y_train_res = sampler.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"Applying feature selection\")\n",
    "feature_selector = SelectKBest(score_func=f_classif, k=30)\n",
    "X_train = feature_selector.fit_transform(X_train_res, y_train_res)\n",
    "X_test = feature_selector.transform(X_test)\n",
    "\n",
    "\n",
    "print(\"Fitting model\")\n",
    "coarse_search = RandomizedSearchCV(estimator=clf,\n",
    "        param_distributions=param_grid, scoring=\"roc_auc\",\n",
    "        n_jobs=-1, cv=5, n_iter=200, verbose=1)\n",
    "print(y_train_res)\n",
    "coarse_search.fit(X_train, y_train_res)\n",
    "\n",
    "sepsis_model = coarse_search.best_estimator_\n",
    "print(f\"ROC score on test set {roc_auc_score(y_test, coarse_search.best_estimator_.predict_proba(X_test)[:,1])}\")\n",
    "print(f\"CV score {coarse_search.best_score_}\")\n",
    "print(f\"Finished test for medical tests.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_sepsis = feature_selector.transform(X_val_scaled)\n",
    "y_pred = sepsis_model.predict_proba(X_val_sepsis)[:,1]\n",
    "# y_pred = model.predict_proba(X_test)[:,1]\n",
    "df_pred_sepsis = pd.DataFrame(y_pred, index=val_pids, columns=SEPSIS)\n",
    "df_pred_sepsis = df_pred_sepsis.reset_index().rename(columns={\"index\": \"pid\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12664, 30)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling vital signsy_train_sepsis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model for LABEL_RRate.\n",
      "Applying feature selection\n",
      "Fitting model\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   18.6s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   52.3s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:  1.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score 0.3785672394199969\n",
      "Test score is 0.3918968001089592\n",
      "Finished test for medical tests.\n",
      "Fitting model for LABEL_ABPm.\n",
      "Applying feature selection\n",
      "Fitting model\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.7s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   14.1s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   34.5s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:   40.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score 0.5795911299758122\n",
      "Test score is 0.5640360411805216\n",
      "Finished test for medical tests.\n",
      "Fitting model for LABEL_SpO2.\n",
      "Applying feature selection\n",
      "Fitting model\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.3s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   14.8s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   28.9s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:   38.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score 0.30082646302476773\n",
      "Test score is 0.229747787761021\n",
      "Finished test for medical tests.\n",
      "Fitting model for LABEL_Heartrate.\n",
      "Applying feature selection\n",
      "Fitting model\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    1.6s\n",
      "[Parallel(n_jobs=-1)]: Done 176 tasks      | elapsed:   12.6s\n",
      "[Parallel(n_jobs=-1)]: Done 426 tasks      | elapsed:   30.6s\n",
      "[Parallel(n_jobs=-1)]: Done 500 out of 500 | elapsed:   35.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score 0.5989895392555413\n",
      "Test score is 0.59719616504937\n",
      "Finished test for medical tests.\n"
     ]
    }
   ],
   "source": [
    "# Modelling of vital signs\n",
    "models = []\n",
    "losses = []\n",
    "feature_selectors_vital_signs = []\n",
    "clf = xgb.XGBRegressor(objective=\"reg:squarederror\", n_thread=-1)\n",
    "\n",
    "for i, sign in enumerate(VITAL_SIGNS):\n",
    "    print(f\"Fitting model for {sign}.\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_train_scaled, y_train_vital_signs[i], test_size=0.10, random_state=42, shuffle=True\n",
    "    )\n",
    "\n",
    "    print(\"Applying feature selection\")\n",
    "    feature_selector = SelectKBest(score_func=f_classif, k=5)\n",
    "    X_train_selected = feature_selector.fit_transform(X_train, y_train)\n",
    "    X_test_selected = feature_selector.transform(X_test)\n",
    "    feature_selectors_vital_signs.append(feature_selector)\n",
    "\n",
    "    print(\"Fitting model\")\n",
    "    \n",
    "    param_grid = {\n",
    "        \"booster\": [\"dart\", \"gbtree\", \"gblinear\"],\n",
    "        \"eta\": np.arange(0.01, 0.4, 0.015),\n",
    "        \"min_child_weight\": range(1, 10, 1),\n",
    "        \"max_depth\": range(3, 8, 1),\n",
    "        \"gamma\": range(0, 100, 2),\n",
    "        \"max_delta_step\": range(1, 10, 1),\n",
    "        \"subsample\": np.arange(0.1, 1, 0.05),\n",
    "        \"colsample_bytree\": np.arange(0.3, 1, 0.05),\n",
    "        \"n_estimators\": range(50, 120, 2),\n",
    "        \"scale_pos_weight\": [1],\n",
    "        \"reg_lambda\": [0], # Ridge regularization\n",
    "        \"reg_alpha\": [1], # Lasso regularization\n",
    "        \"eval_metric\": [\"error\"],\n",
    "        \"verbosity\": [1]\n",
    "    }\n",
    "    \n",
    "    coarse_search = RandomizedSearchCV(estimator=clf,\n",
    "            param_distributions=param_grid, scoring=\"r2\",\n",
    "            n_jobs=-1, cv=5, n_iter=100, verbose=1)\n",
    "    coarse_search.fit(X_train_selected, y_train)\n",
    "    models.append(coarse_search.best_estimator_)\n",
    "    print(f\"CV score {coarse_search.best_score_}\")\n",
    "    print(f\"Test score is {r2_score(y_test, coarse_search.best_estimator_.predict(X_test_selected))}\")\n",
    "    print(f\"Finished test for medical tests.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions for medical tests\n",
    "val_pids = np.unique(df_val[\"pid\"].values)\n",
    "df_pred_vital_signs = pd.DataFrame(index=val_pids, columns=VITAL_SIGNS)\n",
    "for i, test in enumerate(VITAL_SIGNS):\n",
    "    feature_selector = feature_selectors_vital_signs[i]\n",
    "    X_val_vital_sign = feature_selector.transform(X_val_scaled)\n",
    "    model_for_test = models[i]\n",
    "    y_pred = model_for_test.predict(X_val_vital_sign)\n",
    "    df_pred_vital_signs[test] = y_pred\n",
    "\n",
    "df_pred_vital_signs = df_pred_vital_signs.reset_index().rename(columns={\"index\": \"pid\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to ZIP file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Export predictions DataFrame to a zip file\n",
      "         pid  LABEL_BaseExcess  LABEL_Fibrinogen  LABEL_AST  \\\n",
      "0          0          0.861471          0.694429   0.895492   \n",
      "1          3          0.125926          0.304176   0.583918   \n",
      "2          5          0.032484          0.317638   0.416464   \n",
      "3          7          0.294058          0.415359   0.523530   \n",
      "4          9          0.212313          0.360426   0.474583   \n",
      "...      ...               ...               ...        ...   \n",
      "12659  31647          0.607426          0.388649   0.486032   \n",
      "12660  31649          0.637514          0.716042   0.302426   \n",
      "12661  31651          0.883313          0.335106   0.383662   \n",
      "12662  31652          0.951792          0.767715   0.657612   \n",
      "12663  31655          0.919913          0.361826   0.295301   \n",
      "\n",
      "       LABEL_Alkalinephos  LABEL_Bilirubin_total  LABEL_Lactate  \\\n",
      "0                0.875957               0.890575       0.804769   \n",
      "1                0.560731               0.551155       0.256450   \n",
      "2                0.433066               0.415411       0.731218   \n",
      "3                0.469061               0.534208       0.342860   \n",
      "4                0.516357               0.476860       0.336981   \n",
      "...                   ...                    ...            ...   \n",
      "12659            0.494959               0.516078       0.333121   \n",
      "12660            0.314739               0.299045       0.598231   \n",
      "12661            0.351995               0.403183       0.556240   \n",
      "12662            0.903211               0.913924       0.687185   \n",
      "12663            0.323510               0.296965       0.746017   \n",
      "\n",
      "       LABEL_TroponinI  LABEL_SaO2  LABEL_Bilirubin_direct  LABEL_EtCO2  \\\n",
      "0             0.046327    0.448208                0.909973     0.439596   \n",
      "1             0.498990    0.167900                0.412454     0.226304   \n",
      "2             0.475040    0.660048                0.412454     0.727123   \n",
      "3             0.527171    0.405571                0.343107     0.267637   \n",
      "4             0.200907    0.207823                0.309312     0.208664   \n",
      "...                ...         ...                     ...          ...   \n",
      "12659         0.249757    0.658068                0.370688     0.190349   \n",
      "12660         0.092631    0.337120                0.562520     0.557816   \n",
      "12661         0.265233    0.883597                0.412454     0.457173   \n",
      "12662         0.221201    0.712410                0.776826     0.114676   \n",
      "12663         0.159317    0.794631                0.274773     0.570501   \n",
      "\n",
      "       LABEL_Sepsis  LABEL_RRate  LABEL_ABPm  LABEL_SpO2  LABEL_Heartrate  \n",
      "0          0.721094    16.190342   85.152107   97.808853        86.461716  \n",
      "1          0.245261    17.456743   85.907463   95.073776       101.787201  \n",
      "2          0.506628    18.150208   80.798912   97.808853        87.549461  \n",
      "3          0.160874    16.592119   72.305679   95.494781        87.984741  \n",
      "4          0.544991    18.682375   73.864456   95.494781        60.573433  \n",
      "...             ...          ...         ...         ...              ...  \n",
      "12659      0.814105    19.063353   79.442314   95.073776       105.311226  \n",
      "12660      0.736357    17.688660   90.638412   97.495918        74.075935  \n",
      "12661      0.279343    17.894077   67.978676   97.157120        81.705086  \n",
      "12662      0.688640    14.505843   90.006226   97.499786        98.366699  \n",
      "12663      0.691883    17.385033   77.595459   97.768440        87.247124  \n",
      "\n",
      "[12664 rows x 16 columns]\n"
     ]
    }
   ],
   "source": [
    "df_predictions = pd.merge(df_pred_medical_test, df_pred_sepsis, on=\"pid\")\n",
    "df_predictions = pd.merge(df_predictions, df_pred_vital_signs, on=\"pid\")\n",
    "print(\"Export predictions DataFrame to a zip file\")\n",
    "print(df_predictions)\n",
    "df_predictions.to_csv(\n",
    "    \"predictions.csv\",\n",
    "    index=None,\n",
    "    sep=\",\",\n",
    "    header=True,\n",
    "    encoding=\"utf-8-sig\",\n",
    "    float_format=\"%.2f\",\n",
    ")\n",
    "\n",
    "with zipfile.ZipFile(\"predictions.zip\", \"w\", compression=zipfile.ZIP_DEFLATED) as zf:\n",
    "    zf.write(\"predictions.csv\")\n",
    "os.remove(\"predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
