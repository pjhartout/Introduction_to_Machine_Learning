{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of the solution to project 2 from scratch\n",
    "To note:\n",
    "- For clarity the df_test was renamed to df_val as the test word was used when splitting the labeled data into train and test. \n",
    "    - Val stands for validation\n",
    "\n",
    "To try out:\n",
    "- Preprocessing\n",
    "    - Tweak data imputer\n",
    "    - Tweak scaler (Robust scaler, minmax, etc..)\n",
    "    - Tweak feature selection parameter\n",
    "    - Tweak order of operations above to see the effect\n",
    "- Modelling\n",
    "    - XGBoost\n",
    "    - SVM\n",
    "    \n",
    "Following conversation with Gian:\n",
    "* Rewrite code such that XGBoost is used everywhere\n",
    "* RandomUnderSampler (without replacement, but should not be a problem)\n",
    "* Use one line per patient\n",
    "* Don't do imputation\n",
    "* Run 150 fits per label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "import zipfile\n",
    "import time\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "import xgboost as xgb\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import Counter\n",
    "from imblearn.over_sampling import ADASYN, SMOTE\n",
    "from imblearn.under_sampling import ClusterCentroids, RandomUnderSampler\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, chi2, f_classif\n",
    "from sklearn.metrics import f1_score, mean_squared_error, accuracy_score, r2_score, roc_auc_score, recall_score, precision_score\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.metrics import label_ranking_average_precision_score as LRAPS\n",
    "from sklearn.metrics import label_ranking_loss as LRL\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LinearRegression, BayesianRidge, LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer, SimpleImputer\n",
    "\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Global variables\n",
    "IDENTIFIERS = [\"pid\", \"Time\"]\n",
    "MEDICAL_TESTS = [\n",
    "    \"LABEL_BaseExcess\",\n",
    "    \"LABEL_Fibrinogen\",\n",
    "    \"LABEL_AST\",\n",
    "    \"LABEL_Alkalinephos\",\n",
    "    \"LABEL_Bilirubin_total\",\n",
    "    \"LABEL_Lactate\",\n",
    "    \"LABEL_TroponinI\",\n",
    "    \"LABEL_SaO2\",\n",
    "    \"LABEL_Bilirubin_direct\",\n",
    "    \"LABEL_EtCO2\",\n",
    "]\n",
    "VITAL_SIGNS = [\"LABEL_RRate\", \"LABEL_ABPm\", \"LABEL_SpO2\", \"LABEL_Heartrate\"]\n",
    "SEPSIS = [\"LABEL_Sepsis\"]\n",
    "ESTIMATOR = {\"bayesian\": BayesianRidge(), \"decisiontree\": DecisionTreeRegressor(max_features=\"sqrt\", random_state=0), \n",
    "                \"extratree\": ExtraTreesRegressor(n_estimators=10, random_state=0), \n",
    "                \"knn\": KNeighborsRegressor(n_neighbors=10, weights=\"distance\")}\n",
    "\n",
    "FEATURES_MNAR = [\"EtCO2\", \"PTT\", \"BUN\", \"Lactate\", \"Hgb\", \"HCO3\", \"BaseExcess\",\n",
    "                          \"Fibrinogen\", \"Phosphate\", \"WBC\", \"Creatinine\", \"PaCO2\", \"AST\",\n",
    "                          \"FiO2\", \"Platelets\", \"SaO2\", \"Glucose\", \"Magnesium\", \"Potassium\",\n",
    "                          \"Calcium\", \"Alkalinephos\", \"Bilirubin_direct\", \"Chloride\", \"Hct\",\n",
    "                          \"Bilirubin_total\", \"TroponinI\", \"pH\"]\n",
    "\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_f(x):\n",
    "    \"\"\"To get predictions as confidence level, the model predicts for all 12 sets of measures for\n",
    "    each patient a distance to the hyperplane ; it is then transformed into a confidence level using\n",
    "    the sigmoid function ; the confidence level reported is the mean of all confidence levels for a\n",
    "    single patient\n",
    "\n",
    "    Args:\n",
    "        x (float): input of the sigmoid function\n",
    "\n",
    "    Returns:\n",
    "       float: result of the sigmoid computation.\n",
    "\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(r\"data/train_features.csv\")\n",
    "df_train_label = pd.read_csv(r\"data/train_labels.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = pd.read_csv(r\"data/test_features.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data imputation methodology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8236bdff98fa496fa433ae4b42021d73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=18995.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done adding features about MNAR features\n"
     ]
    }
   ],
   "source": [
    "# Adding engineered features\n",
    "mnar_columns = [\n",
    "        sub + \"_presence\" for sub in FEATURES_MNAR\n",
    "    ]\n",
    "pid = df_train[\"pid\"].unique()\n",
    "for patient in tqdm(pid):\n",
    "    for column in FEATURES_MNAR:\n",
    "        presence = int(df_train.loc[\n",
    "            df_train[\"pid\"] == patient\n",
    "            ][column].any())\n",
    "        df_train.at[patient, column] = presence\n",
    "print(\"Done adding features about MNAR features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c3348567a18413797459f01f4567fb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12664.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Done adding features about MNAR features\n"
     ]
    }
   ],
   "source": [
    "# Adding engineered features\n",
    "pid = df_val[\"pid\"].unique()\n",
    "for patient in tqdm(pid):\n",
    "    for column in FEATURES_MNAR:\n",
    "        presence = int(df_val.loc[\n",
    "            df_val[\"pid\"] == patient\n",
    "            ][column].any())\n",
    "        df_val.at[patient, column] = presence\n",
    "print(\"Done adding features about MNAR features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c14857339fdc4138888e00d999f74a87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=18995.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "columns_for_regression = [\"Temp\", \"Hgb\", \"RRate\", \"BaseExcess\", \"WBC\", \"PaCO2\", \"FiO2\", \"Glucose\", \"ABPm\", \"ABPd\", \"SpO2\", \"Hct\", \"Heartrate\", \"ABPs\", \"pH\"]\n",
    "columns_for_regression_trend = [\n",
    "        sub + \"_trend\" for sub in columns_for_regression\n",
    "    ]\n",
    "columns_for_regression_std = [\n",
    "        sub + \"_std\" for sub in columns_for_regression\n",
    "    ]\n",
    "columns_for_regression_min = [\n",
    "        sub + \"_min\" for sub in columns_for_regression\n",
    "    ]\n",
    "columns_for_regression_max = [\n",
    "        sub + \"_max\" for sub in columns_for_regression\n",
    "    ]\n",
    "cols_to_add = columns_for_regression_trend + columns_for_regression_std + columns_for_regression_min + columns_for_regression_max\n",
    "\n",
    "df_train = df_train.reindex(\n",
    "        df_train.columns.tolist() + cols_to_add,\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "pid = df_train[\"pid\"].unique()\n",
    "\n",
    "for patient in tqdm(pid):\n",
    "    for column in columns_for_regression:\n",
    "        if df_train.loc[df_train[\"pid\"] == patient][column].isna().sum() <= 8:\n",
    "            series = df_train.loc[df_train[\"pid\"] == patient][column]\n",
    "            # Fill missing values between two non nans with their average\n",
    "            series = (series.ffill() + series.bfill()) / 2\n",
    "            # Drop the rest of the value\n",
    "            series = series.dropna()\n",
    "            standard_deviation = series.std()\n",
    "            minimum = series.min()\n",
    "            maximum = series.max()\n",
    "            X = [i for i in range(0, len(series))]\n",
    "            X = np.reshape(X, (len(X), 1))\n",
    "            y = series\n",
    "            model = LinearRegression()\n",
    "            try:\n",
    "                model.fit(X, y)\n",
    "                df_train.at[patient, column + \"_trend\"] = model.coef_\n",
    "            except ValueError:\n",
    "                df_train.at[patient, column + \"_trend\"] = 0\n",
    "            df_train.at[patient, column + \"_std\"] = standard_deviation\n",
    "            df_train.at[patient, column + \"_min\"] = minimum\n",
    "            df_train.at[patient, column + \"_max\"] = maximum\n",
    "\n",
    "    # fill rest of values with 0 for trends col umns\n",
    "    df_train[columns_for_regression_trend] = df_train[\n",
    "        columns_for_regression_trend\n",
    "    ].fillna(value=0)\n",
    "    df_train[columns_for_regression_std] = df_train[\n",
    "        columns_for_regression_std\n",
    "    ].fillna(value=0)\n",
    "    df_train[columns_for_regression_min] = df_train[\n",
    "        columns_for_regression_min\n",
    "    ].fillna(value=0)\n",
    "    df_train[columns_for_regression_max] = df_train[\n",
    "        columns_for_regression_max\n",
    "    ].fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "pid = df_val[\"pid\"].unique()\n",
    "\n",
    "df_val = df_val.reindex(\n",
    "        df_val.columns.tolist() + cols_to_add,\n",
    "        axis=1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "073c9680eccb44599b132a4216d4d4c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12664.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for patient in tqdm(pid):\n",
    "    for column in columns_for_regression:\n",
    "        if df_val.loc[df_val[\"pid\"] == patient][column].isna().sum() <= 8:\n",
    "            series = df_val.loc[df_val[\"pid\"] == patient][column]\n",
    "            # Fill missing values between two non nans with their average\n",
    "            series = (series.ffill() + series.bfill()) / 2\n",
    "            # Drop the rest of the value\n",
    "            series = series.dropna()\n",
    "            standard_deviation = series.std()\n",
    "            minimum = series.min()\n",
    "            maximum = series.max()\n",
    "            X = [i for i in range(0, len(series))]\n",
    "            X = np.reshape(X, (len(X), 1))\n",
    "            y = series\n",
    "            model = LinearRegression()\n",
    "            try:\n",
    "                model.fit(X, y)\n",
    "                df_val.at[patient, column + \"_trend\"] = model.coef_\n",
    "            except ValueError:\n",
    "                df_val.at[patient, column + \"_trend\"] = 0\n",
    "            df_val.at[patient, column + \"_std\"] = standard_deviation\n",
    "            df_val.at[patient, column + \"_min\"] = minimum\n",
    "            df_val.at[patient, column + \"_max\"] = maximum\n",
    "\n",
    "    # fill rest of values with 0 for trends col umns\n",
    "    df_val[columns_for_regression_trend] = df_val[\n",
    "        columns_for_regression_trend\n",
    "    ].fillna(value=0)\n",
    "    df_val[columns_for_regression_std] = df_val[\n",
    "        columns_for_regression_std\n",
    "    ].fillna(value=0)\n",
    "    df_val[columns_for_regression_min] = df_val[\n",
    "        columns_for_regression_min\n",
    "    ].fillna(value=0)\n",
    "    df_val[columns_for_regression_max] = df_val[\n",
    "        columns_for_regression_max\n",
    "    ].fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f6cb6108cf74d7abc9884744a135801",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=18995.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_train_grouped = pd.DataFrame(index=df_train[\"pid\"].unique(), columns=df_train.columns)\n",
    "\n",
    "for patient in tqdm(df_train[\"pid\"].unique()):\n",
    "    for column in df_train.columns:\n",
    "        patient_timeseries = df_train.loc[df_train[\"pid\"] == patient][column]\n",
    "        if patient_timeseries.isnull().all():\n",
    "            df_train_grouped.at[patient, column] = np.nan\n",
    "        elif column is not \"pid\":\n",
    "            df_train_grouped.at[patient, column] = patient_timeseries.mean()\n",
    "df_train = df_train_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c361598bb3e409b9d6a23c98143952e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=12664.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_val_grouped = pd.DataFrame(index=df_val[\"pid\"].unique(), columns=df_val.columns)\n",
    "\n",
    "for patient in tqdm(df_val[\"pid\"].unique()):\n",
    "    for column in df_val.columns:\n",
    "        patient_timeseries = df_val.loc[df_val[\"pid\"] == patient][column]\n",
    "        if patient_timeseries.isnull().all():\n",
    "            df_val_grouped.at[patient, column] = np.nan\n",
    "        elif column is not \"pid\":\n",
    "            df_val_grouped.at[patient, column] = patient_timeseries.mean()\n",
    "df_val = df_val_grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv(\"df_train_philip.csv\")\n",
    "df_val.to_csv(\"df_val_philip.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_preprocessed = pd.read_csv(\"df_train_philip.csv\")\n",
    "df_val_preprocessed = pd.read_csv(\"df_val_philip.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pids = np.unique(df_val_preprocessed[\"pid\"].values)\n",
    "val_pids = np.unique(df_val_preprocessed[\"pid\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_preprocessed = df_train_preprocessed.sort_values(by=[\"pid\"])\n",
    "df_train_preprocessed = df_train_preprocessed.drop(columns=IDENTIFIERS)\n",
    "df_val_preprocessed = df_val_preprocessed.sort_values(by=[\"pid\"])\n",
    "df_val_preprocessed = df_val_preprocessed.drop(columns=IDENTIFIERS)\n",
    "df_train_label = df_train_label.sort_values(by=[\"pid\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a list of labels for each medical test\n",
      "Creating a list of labels for sepsis\n",
      "Creating a list of labels for each vital sign\n"
     ]
    }
   ],
   "source": [
    "# Data formatting\n",
    "X_train = df_train_preprocessed.values\n",
    "X_val = df_val_preprocessed.values\n",
    "# Create list with different label for each medical test\n",
    "print(\"Creating a list of labels for each medical test\")\n",
    "y_train_medical_tests = []\n",
    "for test in MEDICAL_TESTS:\n",
    "    y_train_medical_tests.append(df_train_label[test].astype(int).values)\n",
    "\n",
    "# Create list with different label for sepsis\n",
    "print(\"Creating a list of labels for sepsis\")\n",
    "y_train_sepsis = []\n",
    "for sepsis in SEPSIS:\n",
    "    y_train_sepsis.append(df_train_label[sepsis].astype(int).values)\n",
    "\n",
    "# Create list with different label for each vital sign\n",
    "print(\"Creating a list of labels for each vital sign\")\n",
    "y_train_vital_signs = []\n",
    "for sign in VITAL_SIGNS:\n",
    "    y_train_vital_signs.append(df_train_label[sign].astype(int).values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data \n",
    "scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling medical tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model for LABEL_BaseExcess.\n",
      "Resampling\n",
      "Fitting coarse model\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   18.6s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   53.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9192943  0.03941115 0.0429096  ... 0.87684566 0.03840721 0.76820076]\n",
      "ROC score on test set 0.9212526847831162\n",
      "CV score 0.9142709197202634\n",
      "ROC score on test set 0.9212526847831162\n",
      "CV score 0.9142709197202634\n",
      "Fitting model for LABEL_Fibrinogen.\n",
      "Resampling\n",
      "Fitting coarse model\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    4.3s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   20.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.85556257 0.3864742  0.30642387 ... 0.8257802  0.30642387 0.33315018]\n",
      "ROC score on test set 0.7606602816901408\n",
      "CV score 0.7779127706692913\n",
      "ROC score on test set 0.7606602816901408\n",
      "CV score 0.7779127706692913\n",
      "Fitting model for LABEL_AST.\n",
      "Resampling\n",
      "Fitting coarse model\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   17.4s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   53.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.76991904 0.599469   0.32829252 ... 0.5248063  0.3760242  0.4299633 ]\n",
      "ROC score on test set 0.7509185296214378\n",
      "CV score 0.7110957763236169\n",
      "ROC score on test set 0.7509185296214378\n",
      "CV score 0.7110957763236169\n",
      "Fitting model for LABEL_Alkalinephos.\n",
      "Resampling\n",
      "Fitting coarse model\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   11.4s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   47.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.79145104 0.5689337  0.44030726 ... 0.5926671  0.42972842 0.35894385]\n",
      "ROC score on test set 0.7496564160271546\n",
      "CV score 0.7205849316152287\n",
      "ROC score on test set 0.7496564160271546\n",
      "CV score 0.7205849316152287\n",
      "Fitting model for LABEL_Bilirubin_total.\n",
      "Resampling\n",
      "Fitting coarse model\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   23.5s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   58.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8335465  0.71473825 0.3518789  ... 0.66789967 0.3129973  0.43256885]\n",
      "ROC score on test set 0.7332163345410627\n",
      "CV score 0.7041664446694017\n",
      "ROC score on test set 0.7332163345410627\n",
      "CV score 0.7041664446694017\n",
      "Fitting model for LABEL_Lactate.\n",
      "Resampling\n",
      "Fitting coarse model\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    7.0s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   45.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.77554786 0.15303849 0.18401696 ... 0.743133   0.15504944 0.78095853]\n",
      "ROC score on test set 0.7815666824205799\n",
      "CV score 0.7837864854008978\n",
      "ROC score on test set 0.7815666824205799\n",
      "CV score 0.7837864854008978\n",
      "Fitting model for LABEL_TroponinI.\n",
      "Resampling\n",
      "Fitting coarse model\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    7.8s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   21.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.13606526 0.9004724  0.82134575 ... 0.12675641 0.40537813 0.10361692]\n",
      "ROC score on test set 0.878312215320911\n",
      "CV score 0.8716603569497025\n",
      "ROC score on test set 0.878312215320911\n",
      "CV score 0.8716603569497025\n",
      "Fitting model for LABEL_SaO2.\n",
      "Resampling\n",
      "Fitting coarse model\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   15.3s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.5971507  0.242005   0.2411923  ... 0.80634934 0.2411923  0.6802159 ]\n",
      "ROC score on test set 0.8196282021782482\n",
      "CV score 0.8077480428282527\n",
      "ROC score on test set 0.8196282021782482\n",
      "CV score 0.8077480428282527\n",
      "Fitting model for LABEL_Bilirubin_direct.\n",
      "Resampling\n",
      "Fitting coarse model\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.1s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    9.7s finished\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9866333  0.6103902  0.6540704  ... 0.22768466 0.34102306 0.00376799]\n",
      "ROC score on test set 0.7038407494145199\n",
      "CV score 0.7144712962078519\n",
      "ROC score on test set 0.7038407494145199\n",
      "CV score 0.7144712962078519\n",
      "Fitting model for LABEL_EtCO2.\n",
      "Resampling\n",
      "Fitting coarse model\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    2.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:    8.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05827218 0.5136681  0.35009816 ... 0.23681766 0.19505642 0.03189045]\n",
      "ROC score on test set 0.9286404220779221\n",
      "CV score 0.9264675148121094\n",
      "ROC score on test set 0.9286404220779221\n",
      "CV score 0.9264675148121094\n",
      "Finished test for medical tests.\n"
     ]
    }
   ],
   "source": [
    "# Modelling using extreme gradient boosting\n",
    "clf = xgb.XGBClassifier(objective=\"binary:logistic\", n_thread=-1)\n",
    "models = []\n",
    "losses = []\n",
    "feature_selector_medical_tests = []\n",
    "for i, test in enumerate(MEDICAL_TESTS):\n",
    "    print(f\"Fitting model for {test}.\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_train_scaled, y_train_medical_tests[i], test_size=0.10, random_state=42, shuffle=True\n",
    "    )\n",
    "    \n",
    "    print(\"Resampling\")\n",
    "    sampler = RandomUnderSampler(random_state=42)\n",
    "    X_train_res, y_train_res = sampler.fit_resample(X_train, y_train)\n",
    "    \n",
    "    print(\"Fitting coarse model\")\n",
    "    # Coarse parameter grid not optimized at all yet\n",
    "    coarse_param_grid = {\n",
    "        \"booster\": [\"dart\"],\n",
    "        \"eta\": np.arange(0,1,0.1),\n",
    "        \"min_child_weight\": range(1, 10, 1),\n",
    "        \"max_depth\": range(4, 10, 1),\n",
    "        \"gamma\": range(0, 100, 1),\n",
    "        \"max_delta_step\": range(1, 10, 1),\n",
    "        \"subsample\": np.arange(0.1, 1, 0.05),\n",
    "        \"colsample_bytree\": np.arange(0.3, 1, 0.05),\n",
    "        \"n_estimators\": range(50, 150, 1),\n",
    "        \"scale_pos_weight\": [1],\n",
    "        \"reg_lambda\": [0, 1], # Ridge regularization\n",
    "        \"reg_alpha\": [0, 1], # Lasso regularization\n",
    "        \"eval_metric\": [\"error\"],\n",
    "        \"verbosity\": [1]\n",
    "    }\n",
    "    coarse_search = RandomizedSearchCV(estimator=clf,\n",
    "            param_distributions=coarse_param_grid, scoring=\"roc_auc\",\n",
    "            n_jobs=-1, cv=10, n_iter=10, verbose=1)\n",
    "    coarse_search.fit(X_train_res, y_train_res)\n",
    "    print(coarse_search.best_estimator_.predict_proba(X_test)[:,1])\n",
    "    print(f\"ROC score on test set {roc_auc_score(y_test, coarse_search.best_estimator_.predict_proba(X_test)[:,1])}\")\n",
    "    print(f\"CV score {coarse_search.best_score_}\")\n",
    "    best_params = coarse_search.best_params_\n",
    "    print(f\"ROC score on test set {roc_auc_score(y_test, coarse_search.best_estimator_.predict_proba(X_test)[:,1])}\")\n",
    "    print(f\"CV score {coarse_search.best_score_}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    models.append(coarse_search.best_estimator_)\n",
    "    \n",
    "print(f\"Finished test for medical tests.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "for i, model in enumerate(models):\n",
    "    joblib.dump(models[i], f\"xgboost_fine_{MEDICAL_TESTS[i]}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions for medical tests\n",
    "df_pred_medical_test = pd.DataFrame(index=val_pids, columns=MEDICAL_TESTS)\n",
    "for i, test in enumerate(MEDICAL_TESTS):\n",
    "    model_for_test = models[i]\n",
    "#     print(model_for_test.predict_proba(X_val_vital_sign))\n",
    "    y_pred = model_for_test.predict_proba(X_val_scaled)[:, 1]\n",
    "    df_pred_medical_test[test] = y_pred\n",
    "\n",
    "df_pred_medical_test = df_pred_medical_test.reset_index().rename(columns={\"index\": \"pid\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling sepsis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling\n",
      "Fitting model\n",
      "[0 0 0 ... 1 1 1]\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:    4.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC score on test set 0.7255442706556066\n",
      "CV score 0.6844090404040404\n",
      "Finished test for medical tests.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   12.2s finished\n"
     ]
    }
   ],
   "source": [
    "# Model and predict sepsis\n",
    "\n",
    "clf = xgb.XGBClassifier(objective=\"binary:logistic\", n_thread=-1)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_train_scaled, y_train_sepsis[0], test_size=0.10, random_state=42, shuffle=True\n",
    ")\n",
    "\n",
    "\n",
    "param_grid = {\n",
    "        \"booster\": [\"dart\"],\n",
    "        \"eta\": np.arange(0,1,0.1),\n",
    "        \"min_child_weight\": range(1, 10, 1),\n",
    "        \"max_depth\": range(4, 10, 1),\n",
    "        \"gamma\": range(0, 100, 1),\n",
    "        \"max_delta_step\": range(1, 10, 1),\n",
    "        \"subsample\": np.arange(0.1, 1, 0.05),\n",
    "        \"colsample_bytree\": np.arange(0.3, 1, 0.05),\n",
    "        \"n_estimators\": range(50, 150, 1),\n",
    "        \"scale_pos_weight\": [1],\n",
    "        \"reg_lambda\": [0, 1], # Ridge regularization\n",
    "        \"reg_alpha\": [0, 1], # Lasso regularization\n",
    "        \"eval_metric\": [\"error\"],\n",
    "        \"verbosity\": [1]\n",
    "    }\n",
    "\n",
    "print(\"Resampling\")\n",
    "sampler = RandomUnderSampler(random_state=42)\n",
    "X_train, y_train = sampler.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"Fitting model\")\n",
    "coarse_search = RandomizedSearchCV(estimator=clf,\n",
    "        param_distributions=param_grid, scoring=\"roc_auc\",\n",
    "        n_jobs=-1, cv=10, n_iter=10, verbose=1)\n",
    "print(y_train_res)\n",
    "coarse_search.fit(X_train, y_train)\n",
    "\n",
    "sepsis_model = coarse_search.best_estimator_\n",
    "print(f\"ROC score on test set {roc_auc_score(y_test, coarse_search.best_estimator_.predict_proba(X_test)[:,1])}\")\n",
    "print(f\"CV score {coarse_search.best_score_}\")\n",
    "print(f\"Finished test for medical tests.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = sepsis_model.predict_proba(X_val_scaled)[:,1]\n",
    "df_pred_sepsis = pd.DataFrame(y_pred, index=val_pids, columns=SEPSIS)\n",
    "df_pred_sepsis = df_pred_sepsis.reset_index().rename(columns={\"index\": \"pid\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xgboost_fine_sepsis.pkl']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(sepsis_model, f\"xgboost_fine_sepsis.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling vital signs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting model for LABEL_RRate.\n",
      "Fitting model\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   38.8s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  2.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score 0.4051125661920107\n",
      "Test score is 0.39979092274094374\n",
      "Finished test for medical tests.\n",
      "Fitting model for LABEL_ABPm.\n",
      "Fitting model\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   30.3s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  1.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score 0.5836022226887561\n",
      "Test score is 0.6043359316452224\n",
      "Finished test for medical tests.\n",
      "Fitting model for LABEL_SpO2.\n",
      "Fitting model\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   13.2s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:   31.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score 0.32253994174038814\n",
      "Test score is 0.34612475097599815\n",
      "Finished test for medical tests.\n",
      "Fitting model for LABEL_Heartrate.\n",
      "Fitting model\n",
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 12 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  26 tasks      | elapsed:   31.9s\n",
      "[Parallel(n_jobs=-1)]: Done 100 out of 100 | elapsed:  2.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score 0.6042153104770616\n",
      "Test score is 0.609124975655355\n",
      "Finished test for medical tests.\n"
     ]
    }
   ],
   "source": [
    "# Modelling of vital signs\n",
    "models = []\n",
    "losses = []\n",
    "feature_selectors_vital_signs = []\n",
    "clf = xgb.XGBRegressor(objective=\"reg:squarederror\", n_thread=-1)\n",
    "\n",
    "for i, sign in enumerate(VITAL_SIGNS):\n",
    "    print(f\"Fitting model for {sign}.\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_train_scaled, y_train_vital_signs[i], test_size=0.10, random_state=42, shuffle=True\n",
    "    )\n",
    "\n",
    "    print(\"Fitting model\")\n",
    "    \n",
    "    param_grid = {\n",
    "        \"booster\": [\"dart\"],\n",
    "        \"eta\": np.arange(0,1,0.1),\n",
    "        \"min_child_weight\": range(1, 10, 1),\n",
    "        \"max_depth\": range(4, 10, 1),\n",
    "        \"gamma\": range(0, 100, 1),\n",
    "        \"max_delta_step\": range(1, 10, 1),\n",
    "        \"subsample\": np.arange(0.1, 1, 0.05),\n",
    "        \"colsample_bytree\": np.arange(0.3, 1, 0.05),\n",
    "        \"n_estimators\": range(50, 150, 1),\n",
    "        \"scale_pos_weight\": [1],\n",
    "        \"reg_lambda\": [0, 1], # Ridge regularization\n",
    "        \"reg_alpha\": [0, 1], # Lasso regularization\n",
    "        \"eval_metric\": [\"error\"],\n",
    "        \"verbosity\": [1]\n",
    "    }\n",
    "\n",
    "\n",
    "    \n",
    "    coarse_search = RandomizedSearchCV(estimator=clf,\n",
    "            param_distributions=param_grid, scoring=\"r2\",\n",
    "            n_jobs=-1, cv=10, n_iter=10, verbose=1)\n",
    "    coarse_search.fit(X_train, y_train)\n",
    "    models.append(coarse_search.best_estimator_)\n",
    "    print(f\"CV score {coarse_search.best_score_}\")\n",
    "    print(f\"Test score is {r2_score(y_test, coarse_search.best_estimator_.predict(X_test))}\")\n",
    "    print(f\"Finished test for medical tests.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, model in enumerate(models):\n",
    "    joblib.dump(models[i], f\"xgboost_fine_{VITAL_SIGNS[i]}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions for vital signs using ANN\n",
    "df_pred_vital_signs = pd.DataFrame(index=val_pids, columns=VITAL_SIGNS)\n",
    "for model in models:\n",
    "    y_pred = model.predict(X_val_scaled)\n",
    "    df_pred_vital_signs[test] = y_pred\n",
    "\n",
    "df_pred_vital_signs = df_pred_vital_signs.reset_index().rename(columns={\"index\": \"pid\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to ZIP file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Export predictions DataFrame to a zip file\n",
      "           pid  LABEL_BaseExcess  LABEL_Fibrinogen  LABEL_AST  \\\n",
      "0          0.0          0.879785          0.802845   0.866690   \n",
      "1          3.0          0.097245          0.306424   0.580433   \n",
      "2          5.0          0.141181          0.306424   0.408596   \n",
      "3          7.0          0.943669          0.855563   0.921647   \n",
      "4          9.0          0.340743          0.489300   0.399829   \n",
      "...        ...               ...               ...        ...   \n",
      "12659  31647.0          0.111564          0.306424   0.408596   \n",
      "12660  31649.0          0.862636          0.381854   0.816294   \n",
      "12661  31651.0          0.881238          0.503553   0.326502   \n",
      "12662  31652.0          0.026464          0.306424   0.438133   \n",
      "12663  31655.0          0.180528          0.514729   0.503258   \n",
      "\n",
      "       LABEL_Alkalinephos  LABEL_Bilirubin_total  LABEL_Lactate  \\\n",
      "0                0.798704               0.747181       0.799121   \n",
      "1                0.522864               0.563465       0.188026   \n",
      "2                0.424896               0.407713       0.221539   \n",
      "3                0.909675               0.918851       0.750664   \n",
      "4                0.433631               0.455156       0.262222   \n",
      "...                   ...                    ...            ...   \n",
      "12659            0.407491               0.430230       0.163219   \n",
      "12660            0.726426               0.738276       0.711343   \n",
      "12661            0.365879               0.344495       0.708581   \n",
      "12662            0.474064               0.549088       0.115036   \n",
      "12663            0.527980               0.578556       0.289811   \n",
      "\n",
      "       LABEL_TroponinI  LABEL_SaO2  LABEL_Bilirubin_direct  LABEL_EtCO2_x  \\\n",
      "0             0.164469    0.489118                0.888155       0.191964   \n",
      "1             0.405378    0.226074                0.328030       0.121859   \n",
      "2             0.405378    0.241192                0.676315       0.044392   \n",
      "3             0.126756    0.849119                0.988090       0.093836   \n",
      "4             0.107688    0.349264                0.055274       0.008725   \n",
      "...                ...         ...                     ...            ...   \n",
      "12659         0.224700    0.207250                0.233645       0.007584   \n",
      "12660         0.126756    0.468405                0.172702       0.023754   \n",
      "12661         0.126756    0.540783                0.054751       0.015118   \n",
      "12662         0.608202    0.226074                0.144900       0.254369   \n",
      "12663         0.925166    0.411728                0.932527       0.145799   \n",
      "\n",
      "       LABEL_Sepsis LABEL_RRate LABEL_ABPm LABEL_SpO2 LABEL_Heartrate  \\\n",
      "0          0.513534         NaN        NaN        NaN             NaN   \n",
      "1          0.288685         NaN        NaN        NaN             NaN   \n",
      "2          0.288685         NaN        NaN        NaN             NaN   \n",
      "3          0.666998         NaN        NaN        NaN             NaN   \n",
      "4          0.452894         NaN        NaN        NaN             NaN   \n",
      "...             ...         ...        ...        ...             ...   \n",
      "12659      0.288685         NaN        NaN        NaN             NaN   \n",
      "12660      0.625120         NaN        NaN        NaN             NaN   \n",
      "12661      0.417238         NaN        NaN        NaN             NaN   \n",
      "12662      0.412294         NaN        NaN        NaN             NaN   \n",
      "12663      0.379934         NaN        NaN        NaN             NaN   \n",
      "\n",
      "       LABEL_EtCO2_y  \n",
      "0          82.933517  \n",
      "1          95.283882  \n",
      "2          67.782631  \n",
      "3          92.227463  \n",
      "4          88.607910  \n",
      "...              ...  \n",
      "12659      70.371735  \n",
      "12660      90.264626  \n",
      "12661      87.120674  \n",
      "12662     113.746826  \n",
      "12663     105.641800  \n",
      "\n",
      "[12664 rows x 17 columns]\n"
     ]
    }
   ],
   "source": [
    "df_predictions = pd.merge(df_pred_medical_test, df_pred_sepsis, on=\"pid\")\n",
    "df_predictions = pd.merge(df_predictions, df_pred_vital_signs, on=\"pid\")\n",
    "print(\"Export predictions DataFrame to a zip file\")\n",
    "print(df_predictions)\n",
    "df_predictions.to_csv(\n",
    "    \"predictions.csv\",\n",
    "    index=None,\n",
    "    sep=\",\",\n",
    "    header=True,\n",
    "    encoding=\"utf-8-sig\",\n",
    "    float_format=\"%.2f\",\n",
    ")\n",
    "\n",
    "with zipfile.ZipFile(\"predictions.zip\", \"w\", compression=zipfile.ZIP_DEFLATED) as zf:\n",
    "    zf.write(\"predictions.csv\")\n",
    "os.remove(\"predictions.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}