{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import impyute\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import ADASYN, SMOTE\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, chi2, f_classif\n",
    "from sklearn.metrics import f1_score, mean_squared_error, accuracy_score, r2_score, roc_auc_score, recall_score, precision_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.linear_model import LinearRegression, BayesianRidge, LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "IDENTIFIERS = [\"pid\", \"Time\", \"Age\"]\n",
    "MEDICAL_TESTS = [\n",
    "    \"LABEL_BaseExcess\",\n",
    "    \"LABEL_Fibrinogen\",\n",
    "    \"LABEL_AST\",\n",
    "    \"LABEL_Alkalinephos\",\n",
    "    \"LABEL_Bilirubin_total\",\n",
    "    \"LABEL_Lactate\",\n",
    "    \"LABEL_TroponinI\",\n",
    "    \"LABEL_SaO2\",\n",
    "    \"LABEL_Bilirubin_direct\",\n",
    "    \"LABEL_EtCO2\",\n",
    "]\n",
    "VITAL_SIGNS = [\"LABEL_RRate\", \"LABEL_ABPm\", \"LABEL_SpO2\", \"LABEL_Heartrate\"]\n",
    "SEPSIS = [\"LABEL_Sepsis\"]\n",
    "ESTIMATOR = {\"bayesian\": BayesianRidge(), \"decisiontree\": DecisionTreeRegressor(max_features=\"sqrt\", random_state=0), \n",
    "                \"extratree\": ExtraTreesRegressor(n_estimators=10, random_state=0), \n",
    "                \"knn\": KNeighborsRegressor(n_neighbors=10, weights=\"distance\")}\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_f(x):\n",
    "    \"\"\"To get predictions as confidence level, the model predicts for all 12 sets of measures for\n",
    "    each patient a distance to the hyperplane ; it is then transformed into a confidence level using\n",
    "    the sigmoid function ; the confidence level reported is the mean of all confidence levels for a\n",
    "    single patient\n",
    "\n",
    "    Args:\n",
    "        x (float): input of the sigmoid function\n",
    "\n",
    "    Returns:\n",
    "       float: result of the sigmoid computation.\n",
    "\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data \n",
    "df_train = pd.read_csv(r\"data/train_features.csv\")\n",
    "df_train_label = pd.read_csv(r\"data/train_labels.csv\")\n",
    "df_val = pd.read_csv(r\"data/test_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_mean = df_train.copy().fillna(df_train.mean())\n",
    "df_test_mean = df_val.copy().fillna(df_val.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRESENCE_IND = ['EtCO2','Lactate','Bilirubin_direct', 'Bilirubin_total', 'TroponinI',  'PaCO2', 'FiO2', 'AST', 'SaO2']\n",
    "MEAN_IND= ['BUN', 'PTT', 'Hgb', 'HCO3', 'Alkalinephos', 'Chloride', 'Hct', 'Fibrinogen', 'Phosphate', 'WBC', 'Creatinine', \n",
    "              'Platelets', 'Glucose', 'Magnesium', 'Potassium', 'Calcium', 'pH', 'BaseExcess']\n",
    "TIME_IND = ['Heartrate', 'Temp', 'SpO2', 'ABPs', 'RRate', 'ABPm', 'ABPd']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From visual analysis, it seems like we should treat the columns in the following way:\n",
    "* EtCO2, Lactate, Bilirubin_direct, Bilirubin_total, TroponinI, PaCO2, FiO2, AST, SaO2 : presence (etco2 for acute respiratory distress, lactate is indicator of sepsis shock, bilirubin for liver diseases, TroponinI if you've had heart issues, etc)\n",
    "* BUN, PTT, Hgb, HCO3, Alkalinephos, chloride, hct, fibrinogen, phosphate, WBC, creatinine, platelet, glucose, magnesium, potassium, calcium: set all missing values to mean of existing values (these are all blood test indicators)\n",
    "* pH, base excess : set all missing values to mean of existing values (these values should be fully correlated)\n",
    "* Heartrate, Temp, SpO2, ABPs, RRate, ABPm, ABPd : time series imputation, LCOF \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_copy = df_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_df(df, PRESENCE_IND, MEAN_IND, TIME_IND):\n",
    "    \"\"\"Performs data imputation and feature transformation in the following manner : for all data in PRESENCE_IND, \n",
    "    adds a column with the presence or absence for each patient of a test feature; for all data in PRESENCE_IND and MEAN_IND,\n",
    "    if there are any values for a patient, replaces the NaN by the mean of that patient; for data in TIME_IND, does linear \n",
    "    interpolation of values to fill the time series\n",
    "    \n",
    "    Args: df (pandas.core.DataFrame): dataframe to transform\n",
    "        PRESENCE_IND (list): features for presence transformation\n",
    "        MEAN_IND (list): features for mean transformation\n",
    "        TIME_IND (list): features for time series interpolation\n",
    "    \n",
    "    Returns: df (pandas.core.DataFrame): transformed dataframe\n",
    "    \"\"\"\n",
    "    for pid in tqdm(df[\"pid\"].unique()):\n",
    "        pdf = df.loc[df[\"pid\"]==pid]\n",
    "        for col in PRESENCE_IND:\n",
    "            if not(pd.isnull(pdf[col]).all()):\n",
    "                df.loc[df[\"pid\"]==pid, col+\"_presence\"]=1\n",
    "            else:\n",
    "                df.loc[df[\"pid\"]==pid, col+\"_presence\"]=0\n",
    "        for col in MEAN_IND+PRESENCE_IND:\n",
    "            if not(pd.isnull(pdf[col]).all()):\n",
    "                df.loc[df[\"pid\"]==pid, col]=df.loc[df[\"pid\"]==pid, col].fillna(df.loc[df[\"pid\"]==pid, col].mean())\n",
    "        for col in TIME_IND:\n",
    "            if not(pd.isnull(pdf[col]).all()):\n",
    "                df.loc[df[\"pid\"]==pid, col]=df.loc[df[\"pid\"]==pid, col].interpolate()\n",
    "                df.loc[df[\"pid\"]==pid, col]=df.loc[df[\"pid\"]==pid, col].fillna(method='ffill')\n",
    "                df.loc[df[\"pid\"]==pid, col]=df.loc[df[\"pid\"]==pid, col].fillna(method='bfill')\n",
    "    return df     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the training data\n",
    "df_train_copy = transform_df(df_train_copy, PRESENCE_IND, MEAN_IND, TIME_IND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_copy.to_csv(\"df_train_new_imputation.csv\", float_format=\"%.3f\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>Time</th>\n",
       "      <th>Age</th>\n",
       "      <th>EtCO2</th>\n",
       "      <th>PTT</th>\n",
       "      <th>BUN</th>\n",
       "      <th>Lactate</th>\n",
       "      <th>Temp</th>\n",
       "      <th>Hgb</th>\n",
       "      <th>HCO3</th>\n",
       "      <th>...</th>\n",
       "      <th>pH</th>\n",
       "      <th>EtCO2_presence</th>\n",
       "      <th>Lactate_presence</th>\n",
       "      <th>Bilirubin_direct_presence</th>\n",
       "      <th>Bilirubin_total_presence</th>\n",
       "      <th>TroponinI_presence</th>\n",
       "      <th>PaCO2_presence</th>\n",
       "      <th>FiO2_presence</th>\n",
       "      <th>AST_presence</th>\n",
       "      <th>SaO2_presence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "      <td>8.700</td>\n",
       "      <td>24.000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "      <td>8.567</td>\n",
       "      <td>25.333</td>\n",
       "      <td>...</td>\n",
       "      <td>7.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "      <td>8.567</td>\n",
       "      <td>25.333</td>\n",
       "      <td>...</td>\n",
       "      <td>7.37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.0</td>\n",
       "      <td>8.567</td>\n",
       "      <td>25.333</td>\n",
       "      <td>...</td>\n",
       "      <td>7.37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.0</td>\n",
       "      <td>8.567</td>\n",
       "      <td>25.333</td>\n",
       "      <td>...</td>\n",
       "      <td>7.41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227935</th>\n",
       "      <td>9999</td>\n",
       "      <td>8</td>\n",
       "      <td>85.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.4</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "      <td>9.450</td>\n",
       "      <td>25.000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227936</th>\n",
       "      <td>9999</td>\n",
       "      <td>9</td>\n",
       "      <td>85.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.4</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "      <td>9.450</td>\n",
       "      <td>25.000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227937</th>\n",
       "      <td>9999</td>\n",
       "      <td>10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.4</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "      <td>9.450</td>\n",
       "      <td>25.000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227938</th>\n",
       "      <td>9999</td>\n",
       "      <td>11</td>\n",
       "      <td>85.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.4</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "      <td>10.200</td>\n",
       "      <td>25.000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227939</th>\n",
       "      <td>9999</td>\n",
       "      <td>12</td>\n",
       "      <td>85.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.4</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "      <td>9.450</td>\n",
       "      <td>25.000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>227940 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         pid  Time   Age  EtCO2   PTT   BUN  Lactate  Temp     Hgb    HCO3  \\\n",
       "0          1     3  34.0    NaN   NaN  12.0      NaN  36.0   8.700  24.000   \n",
       "1          1     4  34.0    NaN   NaN  12.0      NaN  36.0   8.567  25.333   \n",
       "2          1     5  34.0    NaN   NaN  12.0      NaN  36.0   8.567  25.333   \n",
       "3          1     6  34.0    NaN   NaN  12.0      NaN  37.0   8.567  25.333   \n",
       "4          1     7  34.0    NaN   NaN  12.0      NaN  37.0   8.567  25.333   \n",
       "...      ...   ...   ...    ...   ...   ...      ...   ...     ...     ...   \n",
       "227935  9999     8  85.0    NaN  36.4  30.0      NaN  36.0   9.450  25.000   \n",
       "227936  9999     9  85.0    NaN  36.4  30.0      NaN  36.0   9.450  25.000   \n",
       "227937  9999    10  85.0    NaN  36.4  30.0      NaN  36.0   9.450  25.000   \n",
       "227938  9999    11  85.0    NaN  36.4  30.0      NaN  36.0  10.200  25.000   \n",
       "227939  9999    12  85.0    NaN  36.4  30.0      NaN  36.0   9.450  25.000   \n",
       "\n",
       "        ...    pH  EtCO2_presence  Lactate_presence  \\\n",
       "0       ...  7.33             0.0               0.0   \n",
       "1       ...  7.33             0.0               0.0   \n",
       "2       ...  7.37             0.0               0.0   \n",
       "3       ...  7.37             0.0               0.0   \n",
       "4       ...  7.41             0.0               0.0   \n",
       "...     ...   ...             ...               ...   \n",
       "227935  ...   NaN             0.0               0.0   \n",
       "227936  ...   NaN             0.0               0.0   \n",
       "227937  ...   NaN             0.0               0.0   \n",
       "227938  ...   NaN             0.0               0.0   \n",
       "227939  ...   NaN             0.0               0.0   \n",
       "\n",
       "        Bilirubin_direct_presence  Bilirubin_total_presence  \\\n",
       "0                             0.0                       0.0   \n",
       "1                             0.0                       0.0   \n",
       "2                             0.0                       0.0   \n",
       "3                             0.0                       0.0   \n",
       "4                             0.0                       0.0   \n",
       "...                           ...                       ...   \n",
       "227935                        0.0                       0.0   \n",
       "227936                        0.0                       0.0   \n",
       "227937                        0.0                       0.0   \n",
       "227938                        0.0                       0.0   \n",
       "227939                        0.0                       0.0   \n",
       "\n",
       "        TroponinI_presence  PaCO2_presence  FiO2_presence  AST_presence  \\\n",
       "0                      0.0             1.0            1.0           0.0   \n",
       "1                      0.0             1.0            1.0           0.0   \n",
       "2                      0.0             1.0            1.0           0.0   \n",
       "3                      0.0             1.0            1.0           0.0   \n",
       "4                      0.0             1.0            1.0           0.0   \n",
       "...                    ...             ...            ...           ...   \n",
       "227935                 0.0             0.0            0.0           0.0   \n",
       "227936                 0.0             0.0            0.0           0.0   \n",
       "227937                 0.0             0.0            0.0           0.0   \n",
       "227938                 0.0             0.0            0.0           0.0   \n",
       "227939                 0.0             0.0            0.0           0.0   \n",
       "\n",
       "        SaO2_presence  \n",
       "0                 0.0  \n",
       "1                 0.0  \n",
       "2                 0.0  \n",
       "3                 0.0  \n",
       "4                 0.0  \n",
       "...               ...  \n",
       "227935            1.0  \n",
       "227936            1.0  \n",
       "227937            1.0  \n",
       "227938            1.0  \n",
       "227939            1.0  \n",
       "\n",
       "[227940 rows x 46 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_copy = pd.read_csv(\"df_train_new_imputation.csv\")\n",
    "df_train_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>LABEL_BaseExcess</th>\n",
       "      <th>LABEL_Fibrinogen</th>\n",
       "      <th>LABEL_AST</th>\n",
       "      <th>LABEL_Alkalinephos</th>\n",
       "      <th>LABEL_Bilirubin_total</th>\n",
       "      <th>LABEL_Lactate</th>\n",
       "      <th>LABEL_TroponinI</th>\n",
       "      <th>LABEL_SaO2</th>\n",
       "      <th>LABEL_Bilirubin_direct</th>\n",
       "      <th>LABEL_EtCO2</th>\n",
       "      <th>LABEL_Sepsis</th>\n",
       "      <th>LABEL_RRate</th>\n",
       "      <th>LABEL_ABPm</th>\n",
       "      <th>LABEL_SpO2</th>\n",
       "      <th>LABEL_Heartrate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.1</td>\n",
       "      <td>85.4</td>\n",
       "      <td>100.0</td>\n",
       "      <td>59.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>100.6</td>\n",
       "      <td>95.5</td>\n",
       "      <td>85.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>88.3</td>\n",
       "      <td>96.5</td>\n",
       "      <td>108.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.4</td>\n",
       "      <td>77.2</td>\n",
       "      <td>98.3</td>\n",
       "      <td>80.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.6</td>\n",
       "      <td>76.8</td>\n",
       "      <td>97.7</td>\n",
       "      <td>95.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18990</th>\n",
       "      <td>9993</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.1</td>\n",
       "      <td>69.8</td>\n",
       "      <td>100.0</td>\n",
       "      <td>110.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18991</th>\n",
       "      <td>9995</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.6</td>\n",
       "      <td>97.3</td>\n",
       "      <td>97.8</td>\n",
       "      <td>59.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18992</th>\n",
       "      <td>9996</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.3</td>\n",
       "      <td>66.3</td>\n",
       "      <td>96.9</td>\n",
       "      <td>100.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18993</th>\n",
       "      <td>9998</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.8</td>\n",
       "      <td>81.5</td>\n",
       "      <td>96.9</td>\n",
       "      <td>99.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18994</th>\n",
       "      <td>9999</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>95.5</td>\n",
       "      <td>97.0</td>\n",
       "      <td>81.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>18995 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         pid  LABEL_BaseExcess  LABEL_Fibrinogen  LABEL_AST  \\\n",
       "0          1               1.0               0.0        0.0   \n",
       "1         10               0.0               0.0        0.0   \n",
       "2        100               1.0               0.0        0.0   \n",
       "3       1000               0.0               0.0        0.0   \n",
       "4      10000               0.0               0.0        0.0   \n",
       "...      ...               ...               ...        ...   \n",
       "18990   9993               0.0               0.0        0.0   \n",
       "18991   9995               0.0               0.0        0.0   \n",
       "18992   9996               1.0               0.0        0.0   \n",
       "18993   9998               0.0               0.0        0.0   \n",
       "18994   9999               0.0               0.0        1.0   \n",
       "\n",
       "       LABEL_Alkalinephos  LABEL_Bilirubin_total  LABEL_Lactate  \\\n",
       "0                     0.0                    0.0            1.0   \n",
       "1                     0.0                    0.0            0.0   \n",
       "2                     0.0                    0.0            1.0   \n",
       "3                     0.0                    0.0            1.0   \n",
       "4                     0.0                    0.0            0.0   \n",
       "...                   ...                    ...            ...   \n",
       "18990                 0.0                    0.0            0.0   \n",
       "18991                 0.0                    0.0            0.0   \n",
       "18992                 0.0                    0.0            0.0   \n",
       "18993                 0.0                    0.0            0.0   \n",
       "18994                 1.0                    1.0            0.0   \n",
       "\n",
       "       LABEL_TroponinI  LABEL_SaO2  LABEL_Bilirubin_direct  LABEL_EtCO2  \\\n",
       "0                  0.0         0.0                     0.0          0.0   \n",
       "1                  0.0         0.0                     0.0          0.0   \n",
       "2                  0.0         0.0                     0.0          0.0   \n",
       "3                  0.0         1.0                     0.0          1.0   \n",
       "4                  0.0         0.0                     0.0          0.0   \n",
       "...                ...         ...                     ...          ...   \n",
       "18990              1.0         0.0                     0.0          0.0   \n",
       "18991              0.0         0.0                     0.0          0.0   \n",
       "18992              0.0         1.0                     0.0          0.0   \n",
       "18993              1.0         0.0                     0.0          0.0   \n",
       "18994              0.0         1.0                     0.0          0.0   \n",
       "\n",
       "       LABEL_Sepsis  LABEL_RRate  LABEL_ABPm  LABEL_SpO2  LABEL_Heartrate  \n",
       "0               0.0         12.1        85.4       100.0             59.9  \n",
       "1               0.0         17.8       100.6        95.5             85.5  \n",
       "2               0.0         16.5        88.3        96.5            108.1  \n",
       "3               0.0         19.4        77.2        98.3             80.9  \n",
       "4               0.0         12.6        76.8        97.7             95.3  \n",
       "...             ...          ...         ...         ...              ...  \n",
       "18990           0.0         17.1        69.8       100.0            110.7  \n",
       "18991           0.0         17.6        97.3        97.8             59.2  \n",
       "18992           0.0         17.3        66.3        96.9            100.3  \n",
       "18993           0.0         18.8        81.5        96.9             99.4  \n",
       "18994           0.0         18.0        95.5        97.0             81.9  \n",
       "\n",
       "[18995 rows x 16 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# construct the training labels\n",
    "df_train_label_copy = df_train_label.set_index([\"pid\"])\n",
    "df_label = df_train_label_copy.loc[df_train_copy[\"pid\"].unique().astype(int)]\n",
    "df_label = df_label.reset_index()\n",
    "df_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_copy = df_val.copy().head(6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ce5db932f2544519d563db938893cfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=500.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "df_test_copy = transform_df(df_test_copy, PRESENCE_IND, MEAN_IND, TIME_IND)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we take the median of all these values for the 12h of the patient to get one line per patient for tasks 1 & 2, and keep all values for task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_1_2 = df_train_copy.groupby([\"pid\"], as_index=False).median()\n",
    "df_train_3 = df_train_copy[IDENTIFIERS + TIME_IND]\n",
    "df_test_1_2 = df_test_copy.groupby([\"pid\"], as_index=False).median()\n",
    "df_test_3 = df_test_copy[IDENTIFIERS + TIME_IND]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we use a data imputer to solve values that are still NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_imputation(df_train,df_test):\n",
    "    columns = df_train.columns\n",
    "    imputer = IterativeImputer(\n",
    "        estimator=KNeighborsRegressor(),\n",
    "        missing_values=np.nan,\n",
    "        sample_posterior=False,\n",
    "        max_iter=10,\n",
    "        tol=0.001,\n",
    "        n_nearest_features=None, # Meaning all features are used\n",
    "        initial_strategy='median',\n",
    "        imputation_order='descending',\n",
    "        skip_complete=False,\n",
    "        min_value=None,\n",
    "        max_value=None,\n",
    "        verbose=2,\n",
    "        random_state=42,\n",
    "        add_indicator=False\n",
    "    )\n",
    "\n",
    "    df_train = imputer.fit_transform(df_train.values)\n",
    "    df_train = pd.DataFrame(df_train, columns=columns)\n",
    "    df_train['pid'] = df_train['pid'].astype(int)\n",
    "    df_test = imputer.transform(df_test.values)\n",
    "    df_test = pd.DataFrame(df_test, columns=columns)\n",
    "    df_test['pid'] = df_test['pid'].astype(int)\n",
    "    return df_train,df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[IterativeImputer] Completing matrix with shape (18995, 46)\n",
      "[IterativeImputer] Ending imputation round 1/10, elapsed time 22.03\n",
      "[IterativeImputer] Change: 2341.6249, scaled tolerance: 31.658 \n",
      "[IterativeImputer] Ending imputation round 2/10, elapsed time 45.76\n",
      "[IterativeImputer] Change: 2009.5840999999998, scaled tolerance: 31.658 \n",
      "[IterativeImputer] Ending imputation round 3/10, elapsed time 69.45\n",
      "[IterativeImputer] Change: 1785.1525000000001, scaled tolerance: 31.658 \n",
      "[IterativeImputer] Ending imputation round 4/10, elapsed time 94.44\n",
      "[IterativeImputer] Change: 2038.6158, scaled tolerance: 31.658 \n",
      "[IterativeImputer] Ending imputation round 5/10, elapsed time 117.93\n",
      "[IterativeImputer] Change: 2002.0263, scaled tolerance: 31.658 \n",
      "[IterativeImputer] Ending imputation round 6/10, elapsed time 141.02\n",
      "[IterativeImputer] Change: 2007.9604999999997, scaled tolerance: 31.658 \n",
      "[IterativeImputer] Ending imputation round 7/10, elapsed time 165.02\n",
      "[IterativeImputer] Change: 1900.2678, scaled tolerance: 31.658 \n",
      "[IterativeImputer] Ending imputation round 8/10, elapsed time 188.38\n",
      "[IterativeImputer] Change: 2117.0777, scaled tolerance: 31.658 \n",
      "[IterativeImputer] Ending imputation round 9/10, elapsed time 213.30\n",
      "[IterativeImputer] Change: 2234.045, scaled tolerance: 31.658 \n",
      "[IterativeImputer] Ending imputation round 10/10, elapsed time 237.06\n",
      "[IterativeImputer] Change: 1997.5042999999998, scaled tolerance: 31.658 \n",
      "[IterativeImputer] Completing matrix with shape (500, 46)\n",
      "[IterativeImputer] Ending imputation round 1/10, elapsed time 0.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josep\\Anaconda3\\lib\\site-packages\\sklearn\\impute\\_iterative.py:638: ConvergenceWarning: [IterativeImputer] Early stopping criterion not reached.\n",
      "  \" reached.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[IterativeImputer] Ending imputation round 2/10, elapsed time 0.34\n",
      "[IterativeImputer] Ending imputation round 3/10, elapsed time 0.50\n",
      "[IterativeImputer] Ending imputation round 4/10, elapsed time 0.66\n",
      "[IterativeImputer] Ending imputation round 5/10, elapsed time 0.81\n",
      "[IterativeImputer] Ending imputation round 6/10, elapsed time 0.97\n",
      "[IterativeImputer] Ending imputation round 7/10, elapsed time 1.12\n",
      "[IterativeImputer] Ending imputation round 8/10, elapsed time 1.28\n",
      "[IterativeImputer] Ending imputation round 9/10, elapsed time 1.43\n",
      "[IterativeImputer] Ending imputation round 10/10, elapsed time 1.59\n"
     ]
    }
   ],
   "source": [
    "df_train_1_2, df_test_1_2 = perform_imputation(df_train_1_2, df_test_1_2)\n",
    "df_train_1_2.to_csv(\"df_train_1_2.csv\", float_format=\"%.3f\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_3, df_test_3 = perform_imputation(df_train_3, df_test_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_formatting(df_train, df_test, df_label):\n",
    "    # Data formatting\n",
    "    X_train= df_train.drop(columns=[\"pid\",\"Time\"]).values\n",
    "    X_test = df_test.drop(columns=[\"pid\",\"Time\"]).values\n",
    "    # Create list with different label for each medical test\n",
    "    print(\"Creating a list of labels for each medical test\")\n",
    "    y_train_medical_tests = []\n",
    "    for test in MEDICAL_TESTS:\n",
    "        y_train_medical_tests.append(df_label[test].astype(int).values)\n",
    "\n",
    "    # Create list with different label for sepsis\n",
    "    print(\"Creating a list of labels for sepsis\")\n",
    "    y_train_sepsis = []\n",
    "    for sepsis in SEPSIS:\n",
    "        y_train_sepsis.append(df_label[sepsis].astype(int).values)\n",
    "    return X_train,X_test,y_train_medical_tests,y_train_sepsis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a list of labels for each medical test\n",
      "Creating a list of labels for sepsis\n"
     ]
    }
   ],
   "source": [
    "X_train_1_2, X_test_1_2, y_train_medical_tests,y_train_sepsis = \\\n",
    "data_formatting(df_train_1_2,df_test_1_2,df_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mean, X_test_mean, y_train_medical_tests_mean, y_train_sepsis_mean = \\\n",
    "    data_formatting(df_train_mean,df_test_mean,df_train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(y_train_medical_tests_mean)):\n",
    "    newy = []\n",
    "    for j in range(len(y_train_medical_tests_mean[i])):\n",
    "        newy+=[y_train_medical_tests_mean[i][j] for k in range(12)]\n",
    "    y_train_medical_tests_mean[i]=np.array(newy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data \n",
    "scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "X_train_scaled = scaler.fit_transform(X_train_1_2)\n",
    "X_test_scaled = scaler.transform(X_test_1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data \n",
    "scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "X_train_scaled_mean = scaler.fit_transform(X_train_mean)\n",
    "X_test_scaled_mean = scaler.transform(X_test_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling data\n",
      "Fitting model for LABEL_BaseExcess.\n",
      "Resampling data\n",
      "Fitting model for LABEL_Fibrinogen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josep\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: RuntimeWarning: overflow encountered in exp\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling data\n",
      "Fitting model for LABEL_AST.\n",
      "Resampling data\n",
      "Fitting model for LABEL_Alkalinephos.\n",
      "Resampling data\n",
      "Fitting model for LABEL_Bilirubin_total.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josep\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: RuntimeWarning: overflow encountered in exp\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling data\n",
      "Fitting model for LABEL_Lactate.\n",
      "Resampling data\n",
      "Fitting model for LABEL_TroponinI.\n",
      "Resampling data\n",
      "Fitting model for LABEL_SaO2.\n",
      "Resampling data\n",
      "Fitting model for LABEL_Bilirubin_direct.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josep\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: RuntimeWarning: overflow encountered in exp\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling data\n",
      "Fitting model for LABEL_EtCO2.\n",
      "Scores [0.5159676021079085, 0.49051554228528216, 0.49590452377294636, 0.4904578391811426, 0.5057996351762872, 0.5110523259048464, 0.5112683811621429, 0.5104214473076322, 0.47246367696081515, 0.4959382493034378]\n",
      "Average score 0.49997892231624413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josep\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: RuntimeWarning: overflow encountered in exp\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Modelling of medical tests using SVC\n",
    "models = []\n",
    "scores = []\n",
    "columns_medical_tests = []\n",
    "for i, test in enumerate(MEDICAL_TESTS):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_train_scaled, y_train_medical_tests[i], test_size=0.20, random_state=42, shuffle=True\n",
    "    )\n",
    "    \n",
    "    print(\"Resampling data\")\n",
    "    sampler = ADASYN()\n",
    "    X_train, y_train = sampler.fit_sample(X_train, y_train)\n",
    "    print(f\"Fitting model for {test}.\")\n",
    "\n",
    "\n",
    "    feature_selector = SelectKBest(score_func=f_classif, k=3)\n",
    "    X_train = feature_selector.fit_transform(X_train, y_train)\n",
    "    X_test = feature_selector.transform(X_test)\n",
    "    columns = feature_selector.get_support(indices=True)\n",
    "    columns_medical_tests.append(columns)\n",
    "\n",
    "    clf = SVC(C=0.01, kernel=\"poly\", degree=4, class_weight=\"balanced\").fit(X_train, y_train)\n",
    "    models.append(clf)\n",
    "    y_pred = clf.decision_function(X_test)\n",
    "    y_pred = [sigmoid_f(y_pred[i]) for i in range(len(y_pred))]\n",
    "    scores.append(roc_auc_score(y_test, y_pred))\n",
    "print(f\"Scores {scores}\")\n",
    "print(f\"Average score {np.mean(scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling data\n",
      "Fitting model for LABEL_BaseExcess.\n",
      "Resampling data\n",
      "Fitting model for LABEL_Fibrinogen.\n",
      "Resampling data\n",
      "Fitting model for LABEL_AST.\n",
      "Resampling data\n",
      "Fitting model for LABEL_Alkalinephos.\n",
      "Resampling data\n",
      "Fitting model for LABEL_Bilirubin_total.\n",
      "Resampling data\n",
      "Fitting model for LABEL_Lactate.\n",
      "Resampling data\n",
      "Fitting model for LABEL_TroponinI.\n",
      "Resampling data\n"
     ]
    }
   ],
   "source": [
    "# Modelling of medical tests using logistic regression with cross validation\n",
    "models = []\n",
    "scores = []\n",
    "columns_medical_tests = []\n",
    "for i, test in enumerate(MEDICAL_TESTS):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_train_scaled, y_train_medical_tests[i], test_size=0.20, random_state=42, shuffle=True\n",
    "    )\n",
    "    \n",
    "    print(\"Resampling data\")\n",
    "    sampler = ADASYN()\n",
    "    X_train, y_train = sampler.fit_sample(X_train, y_train)\n",
    "    print(f\"Fitting model for {test}.\")\n",
    "\n",
    "    feature_selector = SelectKBest(score_func=f_classif, k=3)\n",
    "    X_train = feature_selector.fit_transform(X_train, y_train)\n",
    "    X_test = feature_selector.transform(X_test)\n",
    "    columns = feature_selector.get_support(indices=True)\n",
    "    columns_medical_tests.append(columns)\n",
    "    clf = LogisticRegressionCV(cv=5, random_state=42).fit(X_train, y_train)\n",
    "    models.append(clf)\n",
    "    scores.append(roc_auc_score(y_test, clf.predict_proba(X_test)[:,1]))\n",
    "print(f\"Scores {scores}\")\n",
    "print(f\"Average score {np.mean(scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using XGBoost\n",
    "clf = xgb.XGBClassifier(objective=\"binary:logistic\", n_thread=-1)\n",
    "\n",
    "scores = []\n",
    "for i, test in enumerate(MEDICAL_TESTS):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_train_scaled, y_train_medical_tests[i], test_size=0.20, random_state=42, shuffle=True\n",
    "    )\n",
    "    \n",
    "    print(\"Resampling data\")\n",
    "    sampler = ADASYN()\n",
    "    X_train, y_train = sampler.fit_sample(X_train, y_train)\n",
    "    print(f\"Fitting model for {test}.\")\n",
    "\n",
    "\n",
    "    label_counts = pd.Series(y_train).value_counts()\n",
    "    scale_pos_weight = label_counts[0] / label_counts[1]\n",
    "    if scale_pos_weight < 2: scale_pos_weight = 2\n",
    "    \n",
    "    # Coarse parameter grid not optimized at all yet\n",
    "    param_grid = {\n",
    "        \"booster\": [\"dart\"],\n",
    "        \"eta\": [0.1,0.01, 0.001],\n",
    "        \"min_child_weight\": range(1, 10, 1),\n",
    "        \"max_depth\": range(3, 8, 1),\n",
    "        \"gamma\": range(0, 100, 2),\n",
    "        \"max_delta_step\": range(3, 10, 1),\n",
    "        \"subsample\": np.arange(0.1, 1, 0.05),\n",
    "        \"colsample_bytree\": np.arange(0.3, 1, 0.05),\n",
    "        \"n_estimators\": range(50, 120, 2),\n",
    "        \"scale_pos_weight\": [int(scale_pos_weight)],\n",
    "        \"reg_lambda\": [100], # Ridge regularization\n",
    "        \"reg_alpha\": [0], # Lasso regularization\n",
    "        \"eval_metric\": [\"error\"]\n",
    "    }\n",
    "    \n",
    "    feature_selector = SelectKBest(score_func=f_classif, k=3)\n",
    "    X_train = feature_selector.fit_transform(X_train, y_train)\n",
    "    X_test = feature_selector.transform(X_test)\n",
    "    columns = feature_selector.get_support(indices=True)\n",
    "    columns_medical_tests.append(columns)\n",
    "\n",
    "    coarse_search = RandomizedSearchCV(estimator=clf,\n",
    "            param_distributions=param_grid, scoring=\"roc_auc\",\n",
    "            n_jobs=-1, cv=5, n_iter=10, verbose=1)\n",
    "    coarse_search.fit(X_train, y_train)\n",
    "    models.append(coarse_search.best_estimator_)\n",
    "    scores.append(roc_auc_score(y_test, coarse_search.best_estimator_.predict_proba(X_test)[:,1]))\n",
    "print(f\"Scores {scores}\")\n",
    "print(f\"Average score {np.mean(scores)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model and predict sepsis\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_train_scaled, y_train_sepsis[0], test_size=0.20, random_state=42, shuffle=True\n",
    ")\n",
    "print(\"Resampling data\")\n",
    "sampler = ADASYN()\n",
    "X_train, y_train = sampler.fit_sample(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"Applying feature selection\")\n",
    "feature_selector = SelectKBest(score_func=f_classif, k=3)\n",
    "X_train = feature_selector.fit_transform(X_train, y_train)\n",
    "X_test = feature_selector.transform(X_test)\n",
    "columns_sepsis = feature_selector.get_support(indices=True)\n",
    "\n",
    "models, scores = [], []\n",
    "for i, C in enumerate(np.linspace(0.0001, 0.01, num=5)):\n",
    "    print(\"Starting SVC for C={}\".format(C))\n",
    "    models.append(\n",
    "        SVC(C=C, kernel=\"poly\", class_weight=\"balanced\").fit(X_train, y_train)\n",
    "    )\n",
    "    y_pred = models[i].decision_function(X_test)\n",
    "    y_pred = [sigmoid_f(y_pred[i]) for i in range(len(y_pred))]\n",
    "    scores.append(roc_auc_score(y_test, y_pred))\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, np.around(y_pred)).ravel()\n",
    "    size = len(y_test)\n",
    "    print(\n",
    "        \"The ROC AUC score is {}, the TPrate is {}%, the FPrate is {}% \"\n",
    "        \"for iteration {}\".format(scores[i], tp/(tp+fn)*100, tn/(tn+fp)*100, i)\n",
    "    )\n",
    "    print(y_test[:30],np.around(y_pred[:30]))\n",
    "best = np.argmax(scores)\n",
    "model, score = models[best], scores[best]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TREND_LABEL = ['LABEL_RRate', 'LABEL_ABPm', 'LABEL_SpO2', 'LABEL_Heartrate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('precision', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lasso(df_train_3, df_train_label, test, label_test, alpha):\n",
    "    X_train, y_train = [],[]\n",
    "    for pid in df_train_3[\"pid\"].unique():\n",
    "        X_train.append(df_train_3.loc[df_train_3[\"pid\"]==pid, test].values)\n",
    "        y_train.append(df_train_label.loc[df_train_label[\"pid\"]==pid, label_test].values)\n",
    "    X_train, y_train = np.array(X_train),np.array(y_train)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_train, y_train, test_size=0.20, random_state=42, shuffle=True\n",
    "    )\n",
    "    lasso_model = Lasso(alpha=alpha)\n",
    "    lasso_model.fit(X_train, y_train)\n",
    "    print(\"R2 score for lasso model using innate scoring: \",lasso_model.score(X_train, y_train))\n",
    "    y_pred = lasso_model.predict(X_test)\n",
    "    print(\"R2 score on test set : \",r2_score(y_test, y_pred))\n",
    "    print(f\"Diff is {np.around(np.abs([(y_pred[i]-y_test[i])/y_test[i] for i in range(len(y_pred))][:10]),2)}\")\n",
    "    return lasso_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_lasso(lasso_model, df_test_3, test):\n",
    "    X_test = []\n",
    "    for pid in df_test_3[\"pid\"].unique():\n",
    "        X_test.append(df_test_3.loc[df_test_3[\"pid\"]==pid, test].values)\n",
    "    predictions = lasso_model.predict(X_test)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_subtask_3(df_train_3, df_train_label, TREND_LABEL):\n",
    "    lasso_models = []\n",
    "    for label_test in TREND_LABEL:\n",
    "        print('Testing model for {}'.format(label_test))\n",
    "        test = label_test.split(\"_\")[1]\n",
    "        lasso_models.append(train_lasso(df_train_3, df_train_label, test, label_test, 0.0001))\n",
    "    return lasso_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_models = lasso_subtask_3(df_train_3, df_label, TREND_LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions_3(df_test_3, lasso_models, TREND_LABEL):\n",
    "    predictions = []\n",
    "    for i in range(len(lasso_models)):\n",
    "        test = TREND_LABEL[i].split(\"_\")[1]\n",
    "        predictions.append(predict_lasso(lasso_models[i], df_test_3, test))\n",
    "    predictions = np.array(predictions).T\n",
    "    predictions = pd.DataFrame(data=predictions, columns=TREND_LABEL, index=(df_test_3[\"pid\"].unique()).astype(int))\n",
    "    return(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = get_predictions_3(df_test_3, lasso_models, TREND_LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discoveries: we already have the values of some we want to predict in the test set, so time series modelling? Prophet API possibly?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
