{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from imblearn.over_sampling import ADASYN, SMOTE\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, chi2, f_classif\n",
    "from sklearn.metrics import f1_score, mean_squared_error, accuracy_score, r2_score, roc_auc_score, recall_score, precision_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.linear_model import LinearRegression, BayesianRidge, LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.svm import SVC, LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "IDENTIFIERS = [\"pid\", \"Time\", \"Age\"]\n",
    "MEDICAL_TESTS = [\n",
    "    \"LABEL_BaseExcess\",\n",
    "    \"LABEL_Fibrinogen\",\n",
    "    \"LABEL_AST\",\n",
    "    \"LABEL_Alkalinephos\",\n",
    "    \"LABEL_Bilirubin_total\",\n",
    "    \"LABEL_Lactate\",\n",
    "    \"LABEL_TroponinI\",\n",
    "    \"LABEL_SaO2\",\n",
    "    \"LABEL_Bilirubin_direct\",\n",
    "    \"LABEL_EtCO2\",\n",
    "]\n",
    "VITAL_SIGNS = [\"LABEL_RRate\", \"LABEL_ABPm\", \"LABEL_SpO2\", \"LABEL_Heartrate\"]\n",
    "SEPSIS = [\"LABEL_Sepsis\"]\n",
    "ESTIMATOR = {\"bayesian\": BayesianRidge(), \"decisiontree\": DecisionTreeRegressor(max_features=\"sqrt\", random_state=0), \n",
    "                \"extratree\": ExtraTreesRegressor(n_estimators=10, random_state=0), \n",
    "                \"knn\": KNeighborsRegressor(n_neighbors=10, weights=\"distance\")}\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_f(x):\n",
    "    \"\"\"To get predictions as confidence level, the model predicts for all 12 sets of measures for\n",
    "    each patient a distance to the hyperplane ; it is then transformed into a confidence level using\n",
    "    the sigmoid function ; the confidence level reported is the mean of all confidence levels for a\n",
    "    single patient\n",
    "\n",
    "    Args:\n",
    "        x (float): input of the sigmoid function\n",
    "\n",
    "    Returns:\n",
    "       float: result of the sigmoid computation.\n",
    "\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data \n",
    "df_train = pd.read_csv(r\"data/train_features.csv\")\n",
    "df_train_label = pd.read_csv(r\"data/train_labels.csv\")\n",
    "df_val = pd.read_csv(r\"data/test_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_mean = df_train.copy().fillna(df_train.mean())\n",
    "df_test_mean = df_val.copy().fillna(df_val.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRESENCE_IND = ['EtCO2','Lactate','Bilirubin_direct', 'Bilirubin_total', 'TroponinI',  'PaCO2', 'FiO2', 'AST', 'SaO2']\n",
    "MEAN_IND= ['BUN', 'PTT', 'Hgb', 'HCO3', 'Alkalinephos', 'Chloride', 'Hct', 'Fibrinogen', 'Phosphate', 'WBC', 'Creatinine', \n",
    "              'Platelets', 'Glucose', 'Magnesium', 'Potassium', 'Calcium', 'pH', 'BaseExcess']\n",
    "TIME_IND = ['Heartrate', 'Temp', 'SpO2', 'ABPs', 'RRate', 'ABPm', 'ABPd']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From visual analysis, it seems like we should treat the columns in the following way:\n",
    "* EtCO2, Lactate, Bilirubin_direct, Bilirubin_total, TroponinI, PaCO2, FiO2, AST, SaO2 : presence (etco2 for acute respiratory distress, lactate is indicator of sepsis shock, bilirubin for liver diseases, TroponinI if you've had heart issues, etc)\n",
    "* BUN, PTT, Hgb, HCO3, Alkalinephos, chloride, hct, fibrinogen, phosphate, WBC, creatinine, platelet, glucose, magnesium, potassium, calcium: set all missing values to mean of existing values (these are all blood test indicators)\n",
    "* pH, base excess : set all missing values to mean of existing values (these values should be fully correlated)\n",
    "* Heartrate, Temp, SpO2, ABPs, RRate, ABPm, ABPd : time series imputation, LCOF \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_copy = df_train.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_df(df, PRESENCE_IND, MEAN_IND, TIME_IND):\n",
    "    \"\"\"Performs data imputation and feature transformation in the following manner : for all data in PRESENCE_IND, \n",
    "    adds a column with the presence or absence for each patient of a test feature; for all data in PRESENCE_IND and MEAN_IND,\n",
    "    if there are any values for a patient, replaces the NaN by the mean of that patient; for data in TIME_IND, does linear \n",
    "    interpolation of values to fill the time series\n",
    "    \n",
    "    Args: df (pandas.core.DataFrame): dataframe to transform\n",
    "        PRESENCE_IND (list): features for presence transformation\n",
    "        MEAN_IND (list): features for mean transformation\n",
    "        TIME_IND (list): features for time series interpolation\n",
    "    \n",
    "    Returns: df (pandas.core.DataFrame): transformed dataframe\n",
    "    \"\"\"\n",
    "    for pid in tqdm(df[\"pid\"].unique()):\n",
    "        pdf = df.loc[df[\"pid\"]==pid]\n",
    "        for col in PRESENCE_IND:\n",
    "            if not(pd.isnull(pdf[col]).all()):\n",
    "                df.loc[df[\"pid\"]==pid, col+\"_presence\"]=1\n",
    "            else:\n",
    "                df.loc[df[\"pid\"]==pid, col+\"_presence\"]=0\n",
    "        for col in MEAN_IND+PRESENCE_IND:\n",
    "            if not(pd.isnull(pdf[col]).all()):\n",
    "                df.loc[df[\"pid\"]==pid, col]=df.loc[df[\"pid\"]==pid, col].fillna(df.loc[df[\"pid\"]==pid, col].mean())\n",
    "        for col in TIME_IND:\n",
    "            if not(pd.isnull(pdf[col]).all()):\n",
    "                df.loc[df[\"pid\"]==pid, col]=df.loc[df[\"pid\"]==pid, col].interpolate()\n",
    "                df.loc[df[\"pid\"]==pid, col]=df.loc[df[\"pid\"]==pid, col].fillna(method='ffill')\n",
    "                df.loc[df[\"pid\"]==pid, col]=df.loc[df[\"pid\"]==pid, col].fillna(method='bfill')\n",
    "    return df     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the training data\n",
    "# df_train_copy = transform_df(df_train_copy, PRESENCE_IND, MEAN_IND, TIME_IND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train_copy.to_csv(\"df_train_new_imputation.csv\", float_format=\"%.3f\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>Time</th>\n",
       "      <th>Age</th>\n",
       "      <th>EtCO2</th>\n",
       "      <th>PTT</th>\n",
       "      <th>BUN</th>\n",
       "      <th>Lactate</th>\n",
       "      <th>Temp</th>\n",
       "      <th>Hgb</th>\n",
       "      <th>HCO3</th>\n",
       "      <th>...</th>\n",
       "      <th>pH</th>\n",
       "      <th>EtCO2_presence</th>\n",
       "      <th>Lactate_presence</th>\n",
       "      <th>Bilirubin_direct_presence</th>\n",
       "      <th>Bilirubin_total_presence</th>\n",
       "      <th>TroponinI_presence</th>\n",
       "      <th>PaCO2_presence</th>\n",
       "      <th>FiO2_presence</th>\n",
       "      <th>AST_presence</th>\n",
       "      <th>SaO2_presence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "      <td>8.700</td>\n",
       "      <td>24.000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "      <td>8.567</td>\n",
       "      <td>25.333</td>\n",
       "      <td>...</td>\n",
       "      <td>7.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "      <td>8.567</td>\n",
       "      <td>25.333</td>\n",
       "      <td>...</td>\n",
       "      <td>7.37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.0</td>\n",
       "      <td>8.567</td>\n",
       "      <td>25.333</td>\n",
       "      <td>...</td>\n",
       "      <td>7.37</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>34.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.0</td>\n",
       "      <td>8.567</td>\n",
       "      <td>25.333</td>\n",
       "      <td>...</td>\n",
       "      <td>7.41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227935</th>\n",
       "      <td>9999</td>\n",
       "      <td>8</td>\n",
       "      <td>85.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.4</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "      <td>9.450</td>\n",
       "      <td>25.000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227936</th>\n",
       "      <td>9999</td>\n",
       "      <td>9</td>\n",
       "      <td>85.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.4</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "      <td>9.450</td>\n",
       "      <td>25.000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227937</th>\n",
       "      <td>9999</td>\n",
       "      <td>10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.4</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "      <td>9.450</td>\n",
       "      <td>25.000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227938</th>\n",
       "      <td>9999</td>\n",
       "      <td>11</td>\n",
       "      <td>85.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.4</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "      <td>10.200</td>\n",
       "      <td>25.000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227939</th>\n",
       "      <td>9999</td>\n",
       "      <td>12</td>\n",
       "      <td>85.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.4</td>\n",
       "      <td>30.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "      <td>9.450</td>\n",
       "      <td>25.000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>227940 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         pid  Time   Age  EtCO2   PTT   BUN  Lactate  Temp     Hgb    HCO3  \\\n",
       "0          1     3  34.0    NaN   NaN  12.0      NaN  36.0   8.700  24.000   \n",
       "1          1     4  34.0    NaN   NaN  12.0      NaN  36.0   8.567  25.333   \n",
       "2          1     5  34.0    NaN   NaN  12.0      NaN  36.0   8.567  25.333   \n",
       "3          1     6  34.0    NaN   NaN  12.0      NaN  37.0   8.567  25.333   \n",
       "4          1     7  34.0    NaN   NaN  12.0      NaN  37.0   8.567  25.333   \n",
       "...      ...   ...   ...    ...   ...   ...      ...   ...     ...     ...   \n",
       "227935  9999     8  85.0    NaN  36.4  30.0      NaN  36.0   9.450  25.000   \n",
       "227936  9999     9  85.0    NaN  36.4  30.0      NaN  36.0   9.450  25.000   \n",
       "227937  9999    10  85.0    NaN  36.4  30.0      NaN  36.0   9.450  25.000   \n",
       "227938  9999    11  85.0    NaN  36.4  30.0      NaN  36.0  10.200  25.000   \n",
       "227939  9999    12  85.0    NaN  36.4  30.0      NaN  36.0   9.450  25.000   \n",
       "\n",
       "        ...    pH  EtCO2_presence  Lactate_presence  \\\n",
       "0       ...  7.33             0.0               0.0   \n",
       "1       ...  7.33             0.0               0.0   \n",
       "2       ...  7.37             0.0               0.0   \n",
       "3       ...  7.37             0.0               0.0   \n",
       "4       ...  7.41             0.0               0.0   \n",
       "...     ...   ...             ...               ...   \n",
       "227935  ...   NaN             0.0               0.0   \n",
       "227936  ...   NaN             0.0               0.0   \n",
       "227937  ...   NaN             0.0               0.0   \n",
       "227938  ...   NaN             0.0               0.0   \n",
       "227939  ...   NaN             0.0               0.0   \n",
       "\n",
       "        Bilirubin_direct_presence  Bilirubin_total_presence  \\\n",
       "0                             0.0                       0.0   \n",
       "1                             0.0                       0.0   \n",
       "2                             0.0                       0.0   \n",
       "3                             0.0                       0.0   \n",
       "4                             0.0                       0.0   \n",
       "...                           ...                       ...   \n",
       "227935                        0.0                       0.0   \n",
       "227936                        0.0                       0.0   \n",
       "227937                        0.0                       0.0   \n",
       "227938                        0.0                       0.0   \n",
       "227939                        0.0                       0.0   \n",
       "\n",
       "        TroponinI_presence  PaCO2_presence  FiO2_presence  AST_presence  \\\n",
       "0                      0.0             1.0            1.0           0.0   \n",
       "1                      0.0             1.0            1.0           0.0   \n",
       "2                      0.0             1.0            1.0           0.0   \n",
       "3                      0.0             1.0            1.0           0.0   \n",
       "4                      0.0             1.0            1.0           0.0   \n",
       "...                    ...             ...            ...           ...   \n",
       "227935                 0.0             0.0            0.0           0.0   \n",
       "227936                 0.0             0.0            0.0           0.0   \n",
       "227937                 0.0             0.0            0.0           0.0   \n",
       "227938                 0.0             0.0            0.0           0.0   \n",
       "227939                 0.0             0.0            0.0           0.0   \n",
       "\n",
       "        SaO2_presence  \n",
       "0                 0.0  \n",
       "1                 0.0  \n",
       "2                 0.0  \n",
       "3                 0.0  \n",
       "4                 0.0  \n",
       "...               ...  \n",
       "227935            1.0  \n",
       "227936            1.0  \n",
       "227937            1.0  \n",
       "227938            1.0  \n",
       "227939            1.0  \n",
       "\n",
       "[227940 rows x 46 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_copy = pd.read_csv(\"df_train_new_imputation.csv\")\n",
    "df_train_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the training labels\n",
    "df_train_label_copy = df_train_label.set_index([\"pid\"])\n",
    "df_label = df_train_label_copy.loc[df_train_copy[\"pid\"].unique().astype(int)]\n",
    "df_label = df_label.reset_index()\n",
    "df_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_copy = df_val.copy().head(6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_test_copy = transform_df(df_test_copy, PRESENCE_IND, MEAN_IND, TIME_IND)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we take the median of all these values for the 12h of the patient to get one line per patient for tasks 1 & 2, and keep all values for task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_1_2 = df_train_copy.groupby([\"pid\"], as_index=False).median()\n",
    "df_train_3 = df_train_copy[IDENTIFIERS + TIME_IND]\n",
    "df_test_1_2 = df_test_copy.groupby([\"pid\"], as_index=False).median()\n",
    "df_test_3 = df_test_copy[IDENTIFIERS + TIME_IND]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we use a data imputer to solve values that are still NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_imputation(df_train,df_test):\n",
    "    columns = df_train.columns\n",
    "    imputer = IterativeImputer(\n",
    "        estimator=KNeighborsRegressor(),\n",
    "        missing_values=np.nan,\n",
    "        sample_posterior=False,\n",
    "        max_iter=10,\n",
    "        tol=0.001,\n",
    "        n_nearest_features=None, # Meaning all features are used\n",
    "        initial_strategy='median',\n",
    "        imputation_order='descending',\n",
    "        skip_complete=False,\n",
    "        min_value=None,\n",
    "        max_value=None,\n",
    "        verbose=2,\n",
    "        random_state=42,\n",
    "        add_indicator=False\n",
    "    )\n",
    "\n",
    "    df_train = imputer.fit_transform(df_train.values)\n",
    "    df_train = pd.DataFrame(df_train, columns=columns)\n",
    "    df_train['pid'] = df_train['pid'].astype(int)\n",
    "    df_test = imputer.transform(df_test.values)\n",
    "    df_test = pd.DataFrame(df_test, columns=columns)\n",
    "    df_test['pid'] = df_test['pid'].astype(int)\n",
    "    return df_train,df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_1_2, df_test_1_2 = perform_imputation(df_train_1_2, df_test_1_2)\n",
    "df_train_1_2.to_csv(\"df_train_1_2.csv\", float_format=\"%.3f\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_3, df_test_3 = perform_imputation(df_train_3, df_test_3)\n",
    "df_train_1_2.to_csv(\"df_train_3.csv\", float_format=\"%.3f\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_1_2 = pd.read_csv(\"df_train_1_2.csv\")\n",
    "df_train_3 = pd.read_csv(\"df_train_3.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>Time</th>\n",
       "      <th>Age</th>\n",
       "      <th>Heartrate</th>\n",
       "      <th>Temp</th>\n",
       "      <th>SpO2</th>\n",
       "      <th>ABPs</th>\n",
       "      <th>RRate</th>\n",
       "      <th>ABPm</th>\n",
       "      <th>ABPd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>34.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>100.000</td>\n",
       "      <td>142.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>61.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>34.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>100.000</td>\n",
       "      <td>125.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>62.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>34.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>100.000</td>\n",
       "      <td>110.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>34.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>100.000</td>\n",
       "      <td>104.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>49.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>34.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>100.000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227935</th>\n",
       "      <td>9999</td>\n",
       "      <td>8</td>\n",
       "      <td>85.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>96.667</td>\n",
       "      <td>110.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>89.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227936</th>\n",
       "      <td>9999</td>\n",
       "      <td>9</td>\n",
       "      <td>85.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>97.333</td>\n",
       "      <td>123.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>89.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227937</th>\n",
       "      <td>9999</td>\n",
       "      <td>10</td>\n",
       "      <td>85.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>98.000</td>\n",
       "      <td>138.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>89.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227938</th>\n",
       "      <td>9999</td>\n",
       "      <td>11</td>\n",
       "      <td>85.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>98.000</td>\n",
       "      <td>125.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>89.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>227939</th>\n",
       "      <td>9999</td>\n",
       "      <td>12</td>\n",
       "      <td>85.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>98.000</td>\n",
       "      <td>128.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>89.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>227940 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         pid  Time   Age  Heartrate  Temp     SpO2   ABPs  RRate  ABPm  ABPd\n",
       "0          1     3  34.0       94.0  36.0  100.000  142.0   16.0  84.0  61.0\n",
       "1          1     4  34.0       99.0  36.0  100.000  125.0   16.0  81.0  62.5\n",
       "2          1     5  34.0       92.0  36.0  100.000  110.0   18.0  74.0  59.0\n",
       "3          1     6  34.0       88.0  37.0  100.000  104.0   18.0  66.0  49.5\n",
       "4          1     7  34.0       81.0  37.0  100.000  100.0   18.0  63.0  48.0\n",
       "...      ...   ...   ...        ...   ...      ...    ...    ...   ...   ...\n",
       "227935  9999     8  85.0       80.0  36.0   96.667  110.0   17.0  78.0  89.0\n",
       "227936  9999     9  85.0       83.0  36.0   97.333  123.0   15.0  88.0  89.0\n",
       "227937  9999    10  85.0       80.0  36.0   98.000  138.0   22.0  97.0  89.0\n",
       "227938  9999    11  85.0       75.0  36.0   98.000  125.0   22.0  84.0  89.0\n",
       "227939  9999    12  85.0       79.0  36.0   98.000  128.0   24.0  85.0  89.0\n",
       "\n",
       "[227940 rows x 10 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_1_2\n",
    "df_train_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_formatting(df_train, df_test, df_label):\n",
    "    # Data formatting\n",
    "    X_train= df_train.drop(columns=[\"pid\",\"Time\"]).values\n",
    "    X_test = df_test.drop(columns=[\"pid\",\"Time\"]).values\n",
    "    # Create list with different label for each medical test\n",
    "    print(\"Creating a list of labels for each medical test\")\n",
    "    y_train_medical_tests = []\n",
    "    for test in MEDICAL_TESTS:\n",
    "        y_train_medical_tests.append(df_label[test].astype(int).values)\n",
    "\n",
    "    # Create list with different label for sepsis\n",
    "    print(\"Creating a list of labels for sepsis\")\n",
    "    y_train_sepsis = []\n",
    "    for sepsis in SEPSIS:\n",
    "        y_train_sepsis.append(df_label[sepsis].astype(int).values)\n",
    "    return X_train,X_test,y_train_medical_tests,y_train_sepsis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1_2, X_test_1_2, y_train_medical_tests,y_train_sepsis = \\\n",
    "data_formatting(df_train_1_2,df_test_1_2,df_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mean, X_test_mean, y_train_medical_tests_mean, y_train_sepsis_mean = \\\n",
    "    data_formatting(df_train_mean,df_test_mean,df_train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(y_train_medical_tests_mean)):\n",
    "    newy = []\n",
    "    for j in range(len(y_train_medical_tests_mean[i])):\n",
    "        newy+=[y_train_medical_tests_mean[i][j] for k in range(12)]\n",
    "    y_train_medical_tests_mean[i]=np.array(newy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data \n",
    "scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "X_train_scaled = scaler.fit_transform(X_train_1_2)\n",
    "X_test_scaled = scaler.transform(X_test_1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data \n",
    "scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "X_train_scaled_mean = scaler.fit_transform(X_train_mean)\n",
    "X_test_scaled_mean = scaler.transform(X_test_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling data\n",
      "Fitting model for LABEL_BaseExcess.\n",
      "Resampling data\n",
      "Fitting model for LABEL_Fibrinogen.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josep\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: RuntimeWarning: overflow encountered in exp\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling data\n",
      "Fitting model for LABEL_AST.\n",
      "Resampling data\n",
      "Fitting model for LABEL_Alkalinephos.\n",
      "Resampling data\n",
      "Fitting model for LABEL_Bilirubin_total.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josep\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: RuntimeWarning: overflow encountered in exp\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling data\n",
      "Fitting model for LABEL_Lactate.\n",
      "Resampling data\n",
      "Fitting model for LABEL_TroponinI.\n",
      "Resampling data\n",
      "Fitting model for LABEL_SaO2.\n",
      "Resampling data\n",
      "Fitting model for LABEL_Bilirubin_direct.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josep\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: RuntimeWarning: overflow encountered in exp\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling data\n",
      "Fitting model for LABEL_EtCO2.\n",
      "Scores [0.5159676021079085, 0.49051554228528216, 0.49590452377294636, 0.4904578391811426, 0.5057996351762872, 0.5110523259048464, 0.5112683811621429, 0.5104214473076322, 0.47246367696081515, 0.4959382493034378]\n",
      "Average score 0.49997892231624413\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\josep\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:14: RuntimeWarning: overflow encountered in exp\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Modelling of medical tests using SVC\n",
    "models = []\n",
    "scores = []\n",
    "columns_medical_tests = []\n",
    "for i, test in enumerate(MEDICAL_TESTS):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_train_scaled, y_train_medical_tests[i], test_size=0.20, random_state=42, shuffle=True\n",
    "    )\n",
    "    \n",
    "    print(\"Resampling data\")\n",
    "    sampler = ADASYN()\n",
    "    X_train, y_train = sampler.fit_sample(X_train, y_train)\n",
    "    print(f\"Fitting model for {test}.\")\n",
    "\n",
    "\n",
    "    feature_selector = SelectKBest(score_func=f_classif, k=3)\n",
    "    X_train = feature_selector.fit_transform(X_train, y_train)\n",
    "    X_test = feature_selector.transform(X_test)\n",
    "    columns = feature_selector.get_support(indices=True)\n",
    "    columns_medical_tests.append(columns)\n",
    "\n",
    "    clf = SVC(C=0.01, kernel=\"rbf\", degree=4, class_weight=\"balanced\").fit(X_train, y_train)\n",
    "    models.append(clf)\n",
    "    y_pred = clf.decision_function(X_test)\n",
    "    y_pred = [sigmoid_f(y_pred[i]) for i in range(len(y_pred))]\n",
    "    scores.append(roc_auc_score(y_test, y_pred))\n",
    "print(f\"Scores {scores}\")\n",
    "print(f\"Average score {np.mean(scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resampling data\n",
      "Fitting model for LABEL_BaseExcess.\n",
      "Resampling data\n",
      "Fitting model for LABEL_Fibrinogen.\n",
      "Resampling data\n",
      "Fitting model for LABEL_AST.\n",
      "Resampling data\n",
      "Fitting model for LABEL_Alkalinephos.\n",
      "Resampling data\n",
      "Fitting model for LABEL_Bilirubin_total.\n",
      "Resampling data\n",
      "Fitting model for LABEL_Lactate.\n",
      "Resampling data\n",
      "Fitting model for LABEL_TroponinI.\n",
      "Resampling data\n"
     ]
    }
   ],
   "source": [
    "# Modelling of medical tests using logistic regression with cross validation\n",
    "models = []\n",
    "scores = []\n",
    "columns_medical_tests = []\n",
    "for i, test in enumerate(MEDICAL_TESTS):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_train_scaled, y_train_medical_tests[i], test_size=0.20, random_state=42, shuffle=True\n",
    "    )\n",
    "    \n",
    "    print(\"Resampling data\")\n",
    "    sampler = ADASYN()\n",
    "    X_train, y_train = sampler.fit_sample(X_train, y_train)\n",
    "    print(f\"Fitting model for {test}.\")\n",
    "\n",
    "    feature_selector = SelectKBest(score_func=f_classif, k=3)\n",
    "    X_train = feature_selector.fit_transform(X_train, y_train)\n",
    "    X_test = feature_selector.transform(X_test)\n",
    "    columns = feature_selector.get_support(indices=True)\n",
    "    columns_medical_tests.append(columns)\n",
    "    clf = LogisticRegressionCV(cv=5, random_state=42).fit(X_train, y_train)\n",
    "    models.append(clf)\n",
    "    scores.append(roc_auc_score(y_test, clf.predict_proba(X_test)[:,1]))\n",
    "print(f\"Scores {scores}\")\n",
    "print(f\"Average score {np.mean(scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using XGBoost\n",
    "clf = xgb.XGBClassifier(objective=\"binary:logistic\", n_thread=-1)\n",
    "\n",
    "scores = []\n",
    "for i, test in enumerate(MEDICAL_TESTS):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_train_scaled, y_train_medical_tests[i], test_size=0.20, random_state=42, shuffle=True\n",
    "    )\n",
    "    \n",
    "    print(\"Resampling data\")\n",
    "    sampler = ADASYN()\n",
    "    X_train, y_train = sampler.fit_sample(X_train, y_train)\n",
    "    print(f\"Fitting model for {test}.\")\n",
    "\n",
    "\n",
    "    label_counts = pd.Series(y_train).value_counts()\n",
    "    scale_pos_weight = label_counts[0] / label_counts[1]\n",
    "    if scale_pos_weight < 2: scale_pos_weight = 2\n",
    "    \n",
    "    # Coarse parameter grid not optimized at all yet\n",
    "    param_grid = {\n",
    "        \"booster\": [\"dart\"],\n",
    "        \"eta\": [0.1,0.01, 0.001],\n",
    "        \"min_child_weight\": range(1, 10, 1),\n",
    "        \"max_depth\": range(3, 8, 1),\n",
    "        \"gamma\": range(0, 100, 2),\n",
    "        \"max_delta_step\": range(3, 10, 1),\n",
    "        \"subsample\": np.arange(0.1, 1, 0.05),\n",
    "        \"colsample_bytree\": np.arange(0.3, 1, 0.05),\n",
    "        \"n_estimators\": range(50, 120, 2),\n",
    "        \"scale_pos_weight\": [int(scale_pos_weight)],\n",
    "        \"reg_lambda\": [100], # Ridge regularization\n",
    "        \"reg_alpha\": [0], # Lasso regularization\n",
    "        \"eval_metric\": [\"error\"]\n",
    "    }\n",
    "    \n",
    "    feature_selector = SelectKBest(score_func=f_classif, k=3)\n",
    "    X_train = feature_selector.fit_transform(X_train, y_train)\n",
    "    X_test = feature_selector.transform(X_test)\n",
    "    columns = feature_selector.get_support(indices=True)\n",
    "    columns_medical_tests.append(columns)\n",
    "\n",
    "    coarse_search = RandomizedSearchCV(estimator=clf,\n",
    "            param_distributions=param_grid, scoring=\"roc_auc\",\n",
    "            n_jobs=-1, cv=5, n_iter=10, verbose=1)\n",
    "    coarse_search.fit(X_train, y_train)\n",
    "    models.append(coarse_search.best_estimator_)\n",
    "    scores.append(roc_auc_score(y_test, coarse_search.best_estimator_.predict_proba(X_test)[:,1]))\n",
    "print(f\"Scores {scores}\")\n",
    "print(f\"Average score {np.mean(scores)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model and predict sepsis\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_train_scaled, y_train_sepsis[0], test_size=0.20, random_state=42, shuffle=True\n",
    ")\n",
    "print(\"Resampling data\")\n",
    "sampler = ADASYN()\n",
    "X_train, y_train = sampler.fit_sample(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"Applying feature selection\")\n",
    "feature_selector = SelectKBest(score_func=f_classif, k=3)\n",
    "X_train = feature_selector.fit_transform(X_train, y_train)\n",
    "X_test = feature_selector.transform(X_test)\n",
    "columns_sepsis = feature_selector.get_support(indices=True)\n",
    "\n",
    "models, scores = [], []\n",
    "for i, C in enumerate(np.linspace(0.0001, 0.01, num=5)):\n",
    "    print(\"Starting SVC for C={}\".format(C))\n",
    "    models.append(\n",
    "        SVC(C=C, kernel=\"poly\", class_weight=\"balanced\").fit(X_train, y_train)\n",
    "    )\n",
    "    y_pred = models[i].decision_function(X_test)\n",
    "    y_pred = [sigmoid_f(y_pred[i]) for i in range(len(y_pred))]\n",
    "    scores.append(roc_auc_score(y_test, y_pred))\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, np.around(y_pred)).ravel()\n",
    "    size = len(y_test)\n",
    "    print(\n",
    "        \"The ROC AUC score is {}, the TPrate is {}%, the FPrate is {}% \"\n",
    "        \"for iteration {}\".format(scores[i], tp/(tp+fn)*100, tn/(tn+fp)*100, i)\n",
    "    )\n",
    "    print(y_test[:30],np.around(y_pred[:30]))\n",
    "best = np.argmax(scores)\n",
    "model, score = models[best], scores[best]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TREND_LABEL = ['LABEL_RRate', 'LABEL_ABPm', 'LABEL_SpO2', 'LABEL_Heartrate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('precision', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lasso(df_train_3, df_train_label, test, label_test, alpha):\n",
    "    X_train, y_train = [],[]\n",
    "    for pid in df_train_3[\"pid\"].unique():\n",
    "        X_train.append(df_train_3.loc[df_train_3[\"pid\"]==pid, test].values)\n",
    "        y_train.append(df_train_label.loc[df_train_label[\"pid\"]==pid, label_test].values)\n",
    "    X_train, y_train = np.array(X_train),np.array(y_train)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_train, y_train, test_size=0.20, random_state=42, shuffle=True\n",
    "    )\n",
    "    lasso_model = Lasso(alpha=alpha)\n",
    "    lasso_model.fit(X_train, y_train)\n",
    "    print(\"R2 score for lasso model using innate scoring: \",lasso_model.score(X_train, y_train))\n",
    "    y_pred = lasso_model.predict(X_test)\n",
    "    print(\"R2 score on test set : \",r2_score(y_test, y_pred))\n",
    "    print(f\"Diff is {np.around(np.abs([(y_pred[i]-y_test[i])/y_test[i] for i in range(len(y_pred))][:10]),2)}\")\n",
    "    return lasso_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_lasso(lasso_model, df_test_3, test):\n",
    "    X_test = []\n",
    "    for pid in df_test_3[\"pid\"].unique():\n",
    "        X_test.append(df_test_3.loc[df_test_3[\"pid\"]==pid, test].values)\n",
    "    predictions = lasso_model.predict(X_test)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_subtask_3(df_train_3, df_train_label, TREND_LABEL):\n",
    "    lasso_models = []\n",
    "    for label_test in TREND_LABEL:\n",
    "        print('Testing model for {}'.format(label_test))\n",
    "        test = label_test.split(\"_\")[1]\n",
    "        lasso_models.append(train_lasso(df_train_3, df_train_label, test, label_test, 0.0001))\n",
    "    return lasso_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_models = lasso_subtask_3(df_train_3, df_label, TREND_LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions_3(df_test_3, lasso_models, TREND_LABEL):\n",
    "    predictions = []\n",
    "    for i in range(len(lasso_models)):\n",
    "        test = TREND_LABEL[i].split(\"_\")[1]\n",
    "        predictions.append(predict_lasso(lasso_models[i], df_test_3, test))\n",
    "    predictions = np.array(predictions).T\n",
    "    predictions = pd.DataFrame(data=predictions, columns=TREND_LABEL, index=(df_test_3[\"pid\"].unique()).astype(int))\n",
    "    return(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = get_predictions_3(df_test_3, lasso_models, TREND_LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discoveries: we already have the values of some we want to predict in the test set, so time series modelling? Prophet API possibly?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
