{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import impyute\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import ADASYN, SMOTE\n",
    "from sklearn.feature_selection import SelectKBest, f_regression, chi2, f_classif\n",
    "from sklearn.metrics import f1_score, mean_squared_error, accuracy_score, r2_score, roc_auc_score, recall_score, precision_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
    "from sklearn.linear_model import LinearRegression, BayesianRidge, LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDENTIFIERS = [\"pid\", \"Time\", \"Age\"]\n",
    "MEDICAL_TESTS = [\n",
    "    \"LABEL_BaseExcess\",\n",
    "    \"LABEL_Fibrinogen\",\n",
    "    \"LABEL_AST\",\n",
    "    \"LABEL_Alkalinephos\",\n",
    "    \"LABEL_Bilirubin_total\",\n",
    "    \"LABEL_Lactate\",\n",
    "    \"LABEL_TroponinI\",\n",
    "    \"LABEL_SaO2\",\n",
    "    \"LABEL_Bilirubin_direct\",\n",
    "    \"LABEL_EtCO2\",\n",
    "]\n",
    "VITAL_SIGNS = [\"LABEL_RRate\", \"LABEL_ABPm\", \"LABEL_SpO2\", \"LABEL_Heartrate\"]\n",
    "SEPSIS = [\"LABEL_Sepsis\"]\n",
    "ESTIMATOR = {\"bayesian\": BayesianRidge(), \"decisiontree\": DecisionTreeRegressor(max_features=\"sqrt\", random_state=0), \n",
    "                \"extratree\": ExtraTreesRegressor(n_estimators=10, random_state=0), \n",
    "                \"knn\": KNeighborsRegressor(n_neighbors=10, weights=\"distance\")}\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid_f(x):\n",
    "    \"\"\"To get predictions as confidence level, the model predicts for all 12 sets of measures for\n",
    "    each patient a distance to the hyperplane ; it is then transformed into a confidence level using\n",
    "    the sigmoid function ; the confidence level reported is the mean of all confidence levels for a\n",
    "    single patient\n",
    "\n",
    "    Args:\n",
    "        x (float): input of the sigmoid function\n",
    "\n",
    "    Returns:\n",
    "       float: result of the sigmoid computation.\n",
    "\n",
    "    \"\"\"\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data \n",
    "df_train = pd.read_csv(r\"data/train_features.csv\")\n",
    "df_train_label = pd.read_csv(r\"data/train_labels.csv\")\n",
    "df_val = pd.read_csv(r\"data/test_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_mean = df_train.copy().fillna(df_train.mean())\n",
    "df_test_mean = df_val.copy().fillna(df_val.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRESENCE_IND = ['EtCO2','Lactate','Bilirubin_direct', 'Bilirubin_total', 'TroponinI',  'PaCO2', 'FiO2', 'AST', 'SaO2']\n",
    "MEAN_IND= ['BUN', 'PTT', 'Hgb', 'HCO3', 'Alkalinephos', 'Chloride', 'Hct', 'Fibrinogen', 'Phosphate', 'WBC', 'Creatinine', \n",
    "              'Platelets', 'Glucose', 'Magnesium', 'Potassium', 'Calcium', 'pH', 'BaseExcess']\n",
    "TIME_IND = ['Heartrate', 'Temp', 'SpO2', 'ABPs', 'RRate', 'ABPm', 'ABPd']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From visual analysis, it seems like we should treat the columns in the following way:\n",
    "* EtCO2, Lactate, Bilirubin_direct, Bilirubin_total, TroponinI, PaCO2, FiO2, AST, SaO2 : presence (etco2 for acute respiratory distress, lactate is indicator of sepsis shock, bilirubin for liver diseases, TroponinI if you've had heart issues, etc)\n",
    "* BUN, PTT, Hgb, HCO3, Alkalinephos, chloride, hct, fibrinogen, phosphate, WBC, creatinine, platelet, glucose, magnesium, potassium, calcium: set all missing values to mean of existing values (these are all blood test indicators)\n",
    "* pH, base excess : set all missing values to mean of existing values (these values should be fully correlated)\n",
    "* Heartrate, Temp, SpO2, ABPs, RRate, ABPm, ABPd : time series imputation, LCOF \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_copy = df_train.copy().head(36000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_df(df, PRESENCE_IND, MEAN_IND, TIME_IND):\n",
    "    \"\"\"Performs data imputation and feature transformation in the following manner : for all data in PRESENCE_IND, \n",
    "    adds a column with the presence or absence for each patient of a test feature; for all data in PRESENCE_IND and MEAN_IND,\n",
    "    if there are any values for a patient, replaces the NaN by the mean of that patient; for data in TIME_IND, does linear \n",
    "    interpolation of values to fill the time series\n",
    "    \n",
    "    Args: df (pandas.core.DataFrame): dataframe to transform\n",
    "        PRESENCE_IND (list): features for presence transformation\n",
    "        MEAN_IND (list): features for mean transformation\n",
    "        TIME_IND (list): features for time series interpolation\n",
    "    \n",
    "    Returns: df (pandas.core.DataFrame): transformed dataframe\n",
    "    \"\"\"\n",
    "    for pid in tqdm(df[\"pid\"].unique()):\n",
    "        pdf = df.loc[df[\"pid\"]==pid]\n",
    "        for col in PRESENCE_IND:\n",
    "            if not(pd.isnull(pdf[col]).all()):\n",
    "                df.loc[df[\"pid\"]==pid, col+\"_presence\"]=1\n",
    "            else:\n",
    "                df.loc[df[\"pid\"]==pid, col+\"_presence\"]=0\n",
    "        for col in MEAN_IND+PRESENCE_IND:\n",
    "            if not(pd.isnull(pdf[col]).all()):\n",
    "                df.loc[df[\"pid\"]==pid, col]=df.loc[df[\"pid\"]==pid, col].fillna(df.loc[df[\"pid\"]==pid, col].mean())\n",
    "        for col in TIME_IND:\n",
    "            if not(pd.isnull(pdf[col]).all()):\n",
    "                df.loc[df[\"pid\"]==pid, col]=df.loc[df[\"pid\"]==pid, col].interpolate()\n",
    "                df.loc[df[\"pid\"]==pid, col]=df.loc[df[\"pid\"]==pid, col].fillna(method='ffill')\n",
    "                df.loc[df[\"pid\"]==pid, col]=df.loc[df[\"pid\"]==pid, col].fillna(method='bfill')\n",
    "    return df     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the training data\n",
    "df_train_copy = transform_df(df_train_copy, PRESENCE_IND, MEAN_IND, TIME_IND)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct the training labels\n",
    "df_train_label_copy = df_train_label.set_index([\"pid\"])\n",
    "df_label = df_train_label_copy.loc[df_train_copy[\"pid\"].unique().astype(int)]\n",
    "df_label = df_label.reset_index()\n",
    "df_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_copy = df_val.copy().head(6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_copy = transform_df(df_test_copy, PRESENCE_IND, MEAN_IND, TIME_IND)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we take the median of all these values for the 12h of the patient to get one line per patient for tasks 1 & 2, and keep all values for task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_1_2 = df_train_copy.groupby([\"pid\"], as_index=False).median()\n",
    "df_train_3 = df_train_copy[IDENTIFIERS + TIME_IND]\n",
    "df_test_1_2 = df_test_copy.groupby([\"pid\"], as_index=False).median()\n",
    "df_test_3 = df_test_copy[IDENTIFIERS + TIME_IND]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we use a data imputer to solve values that are still NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_imputation(df_train,df_test):\n",
    "    columns = df_train.columns\n",
    "    imputer = IterativeImputer(\n",
    "        estimator=KNeighborsRegressor(),\n",
    "        missing_values=np.nan,\n",
    "        sample_posterior=False,\n",
    "        max_iter=10,\n",
    "        tol=0.001,\n",
    "        n_nearest_features=None, # Meaning all features are used\n",
    "        initial_strategy='median',\n",
    "        imputation_order='descending',\n",
    "        skip_complete=False,\n",
    "        min_value=None,\n",
    "        max_value=None,\n",
    "        verbose=2,\n",
    "        random_state=42,\n",
    "        add_indicator=False\n",
    "    )\n",
    "\n",
    "    df_train = imputer.fit_transform(df_train.values)\n",
    "    df_train = pd.DataFrame(df_train, columns=columns)\n",
    "    df_train['pid'] = df_train['pid'].astype(int)\n",
    "    df_test = imputer.transform(df_test.values)\n",
    "    df_test = pd.DataFrame(df_test, columns=columns)\n",
    "    df_test['pid'] = df_test['pid'].astype(int)\n",
    "    return df_train,df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_1_2, df_test_1_2 = perform_imputation(df_train_1_2, df_test_1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_3, df_test_3 = perform_imputation(df_train_3, df_test_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_formatting(df_train, df_test, df_label):\n",
    "    # Data formatting\n",
    "    X_train= df_train.drop(columns=[\"pid\",\"Time\"]).values\n",
    "    X_test = df_test.drop(columns=[\"pid\",\"Time\"]).values\n",
    "    # Create list with different label for each medical test\n",
    "    print(\"Creating a list of labels for each medical test\")\n",
    "    y_train_medical_tests = []\n",
    "    for test in MEDICAL_TESTS:\n",
    "        y_train_medical_tests.append(df_label[test].astype(int).values)\n",
    "\n",
    "    # Create list with different label for sepsis\n",
    "    print(\"Creating a list of labels for sepsis\")\n",
    "    y_train_sepsis = []\n",
    "    for sepsis in SEPSIS:\n",
    "        y_train_sepsis.append(df_label[sepsis].astype(int).values)\n",
    "    return X_train,X_test,y_train_medical_tests,y_train_sepsis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_1_2, X_test_1_2, y_train_medical_tests,y_train_sepsis = \\\n",
    "data_formatting(df_train_1_2,df_test_1_2,df_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_mean, X_test_mean, y_train_medical_tests_mean, y_train_sepsis_mean = \\\n",
    "    data_formatting(df_train_mean,df_test_mean,df_train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(y_train_medical_tests_mean)):\n",
    "    newy = []\n",
    "    for j in range(len(y_train_medical_tests_mean[i])):\n",
    "        newy+=[y_train_medical_tests_mean[i][j] for k in range(12)]\n",
    "    y_train_medical_tests_mean[i]=np.array(newy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data \n",
    "scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "X_train_scaled = scaler.fit_transform(X_train_1_2)\n",
    "X_test_scaled = scaler.transform(X_test_1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale data \n",
    "scaler = StandardScaler(with_mean=True, with_std=True)\n",
    "X_train_scaled_mean = scaler.fit_transform(X_train_mean)\n",
    "X_test_scaled_mean = scaler.transform(X_test_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelling of medical tests using SVC\n",
    "models = []\n",
    "scores = []\n",
    "columns_medical_tests = []\n",
    "for i, test in enumerate(MEDICAL_TESTS):\n",
    "    print(\"Resampling data\")\n",
    "    sampler = ADASYN()\n",
    "    X_train, y_train = sampler.fit_sample(X_train_scaled_mean, y_train_medical_tests_mean[i])\n",
    "    print(f\"Fitting model for {test}.\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_train, y_train, test_size=0.20, random_state=42, shuffle=True\n",
    "    )\n",
    "\n",
    "    feature_selector = SelectKBest(score_func=f_classif, k=3)\n",
    "    X_train = feature_selector.fit_transform(X_train, y_train)\n",
    "    X_test = feature_selector.transform(X_test)\n",
    "    columns = feature_selector.get_support(indices=True)\n",
    "    columns_medical_tests.append(columns)\n",
    "\n",
    "    clf = SVC(C=0.01, kernel=\"poly\", degree=4, class_weight=\"balanced\").fit(X_train, y_train)\n",
    "    models.append(clf)\n",
    "    y_pred = clf.decision_function(X_test)\n",
    "    y_pred = [sigmoid_f(y_pred[i]) for i in range(len(y_pred))]\n",
    "    scores.append(roc_auc_score(y_test, y_pred))\n",
    "print(f\"Scores {scores}\")\n",
    "print(f\"Average score {np.mean(scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelling of medical tests using logistic regression with cross validation\n",
    "models = []\n",
    "scores = []\n",
    "columns_medical_tests = []\n",
    "for i, test in enumerate(MEDICAL_TESTS):\n",
    "    print(\"Resampling data\")\n",
    "    sampler = ADASYN()\n",
    "    X_train, y_train = sampler.fit_sample(X_train_scaled, y_train_medical_tests[i])\n",
    "    print(f\"Fitting model for {test}.\")\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_train, y_train, test_size=0.20, random_state=42, shuffle=True\n",
    "    )\n",
    "\n",
    "    feature_selector = SelectKBest(score_func=f_classif, k=3)\n",
    "    X_train = feature_selector.fit_transform(X_train, y_train)\n",
    "    X_test = feature_selector.transform(X_test)\n",
    "    columns = feature_selector.get_support(indices=True)\n",
    "    columns_medical_tests.append(columns)\n",
    "    clf = LogisticRegressionCV(cv=5, random_state=42).fit(X_train, y_train)\n",
    "    models.append(clf)\n",
    "    scores.append(roc_auc_score(y_test, clf.predict_proba(X_test)[:,1]))\n",
    "print(f\"Scores {scores}\")\n",
    "print(f\"Average score {np.mean(scores)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using XGBoost\n",
    "clf = xgb.XGBClassifier(objective=\"binary:logistic\", n_thread=-1)\n",
    "\n",
    "scores = []\n",
    "for i, test in enumerate(MEDICAL_TESTS):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_train_scaled, y_train_medical_tests[i], test_size=0.20, random_state=42, shuffle=True\n",
    "    )\n",
    "    \n",
    "    print(\"Resampling data\")\n",
    "    sampler = ADASYN()\n",
    "    X_train, y_train = sampler.fit_sample(X_train, y_train)\n",
    "    print(f\"Fitting model for {test}.\")\n",
    "\n",
    "\n",
    "    label_counts = pd.Series(y_train).value_counts()\n",
    "    scale_pos_weight = label_counts[0] / label_counts[1]\n",
    "    if scale_pos_weight < 2: scale_pos_weight = 2\n",
    "    \n",
    "    # Coarse parameter grid not optimized at all yet\n",
    "    param_grid = {\n",
    "        \"booster\": [\"dart\"],\n",
    "        \"eta\": [0.1,0.01, 0.001],\n",
    "        \"min_child_weight\": range(1, 10, 1),\n",
    "        \"max_depth\": range(3, 8, 1),\n",
    "        \"gamma\": range(0, 100, 2),\n",
    "        \"max_delta_step\": range(3, 10, 1),\n",
    "        \"subsample\": np.arange(0.1, 1, 0.05),\n",
    "        \"colsample_bytree\": np.arange(0.3, 1, 0.05),\n",
    "        \"n_estimators\": range(50, 120, 2),\n",
    "        \"scale_pos_weight\": [int(scale_pos_weight)],\n",
    "        \"reg_lambda\": [100], # Ridge regularization\n",
    "        \"reg_alpha\": [0], # Lasso regularization\n",
    "        \"eval_metric\": [\"error\"]\n",
    "    }\n",
    "    \n",
    "    feature_selector = SelectKBest(score_func=f_classif, k=3)\n",
    "    X_train = feature_selector.fit_transform(X_train, y_train)\n",
    "    X_test = feature_selector.transform(X_test)\n",
    "    columns = feature_selector.get_support(indices=True)\n",
    "    columns_medical_tests.append(columns)\n",
    "\n",
    "    coarse_search = RandomizedSearchCV(estimator=clf,\n",
    "            param_distributions=param_grid, scoring=\"roc_auc\",\n",
    "            n_jobs=-1, cv=5, n_iter=10, verbose=1)\n",
    "    coarse_search.fit(X_train, y_train)\n",
    "    models.append(coarse_search.best_estimator_)\n",
    "    scores.append(roc_auc_score(y_test, coarse_search.best_estimator_.predict_proba(X_test)[:,1]))\n",
    "print(f\"Scores {scores}\")\n",
    "print(f\"Average score {np.mean(scores)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model and predict sepsis\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_train_scaled, y_train_sepsis[0], test_size=0.20, random_state=42, shuffle=True\n",
    ")\n",
    "print(\"Resampling data\")\n",
    "sampler = ADASYN()\n",
    "X_train, y_train = sampler.fit_sample(X_train, y_train)\n",
    "\n",
    "\n",
    "print(\"Applying feature selection\")\n",
    "feature_selector = SelectKBest(score_func=f_classif, k=3)\n",
    "X_train = feature_selector.fit_transform(X_train, y_train)\n",
    "X_test = feature_selector.transform(X_test)\n",
    "columns_sepsis = feature_selector.get_support(indices=True)\n",
    "\n",
    "models, scores = [], []\n",
    "for i, C in enumerate(np.linspace(0.0001, 0.01, num=5)):\n",
    "    print(\"Starting SVC for C={}\".format(C))\n",
    "    models.append(\n",
    "        SVC(C=C, kernel=\"poly\", class_weight=\"balanced\").fit(X_train, y_train)\n",
    "    )\n",
    "    y_pred = models[i].decision_function(X_test)\n",
    "    y_pred = [sigmoid_f(y_pred[i]) for i in range(len(y_pred))]\n",
    "    scores.append(roc_auc_score(y_test, y_pred))\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test, np.around(y_pred)).ravel()\n",
    "    size = len(y_test)\n",
    "    print(\n",
    "        \"The ROC AUC score is {}, the TPrate is {}%, the FPrate is {}% \"\n",
    "        \"for iteration {}\".format(scores[i], tp/(tp+fn)*100, tn/(tn+fp)*100, i)\n",
    "    )\n",
    "    print(y_test[:30],np.around(y_pred[:30]))\n",
    "best = np.argmax(scores)\n",
    "model, score = models[best], scores[best]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TREND_LABEL = ['LABEL_RRate', 'LABEL_ABPm', 'LABEL_SpO2', 'LABEL_Heartrate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('precision', 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_lasso(df_train_3, df_train_label, test, label_test, alpha):\n",
    "    X_train, y_train = [],[]\n",
    "    for pid in df_train_3[\"pid\"].unique():\n",
    "        X_train.append(df_train_3.loc[df_train_3[\"pid\"]==pid, test].values)\n",
    "        y_train.append(df_train_label.loc[df_train_label[\"pid\"]==pid, label_test].values)\n",
    "    X_train, y_train = np.array(X_train),np.array(y_train)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_train, y_train, test_size=0.20, random_state=42, shuffle=True\n",
    "    )\n",
    "    lasso_model = Lasso(alpha=alpha)\n",
    "    lasso_model.fit(X_train, y_train)\n",
    "    print(\"R2 score for lasso model using innate scoring: \",lasso_model.score(X_train, y_train))\n",
    "    y_pred = lasso_model.predict(X_test)\n",
    "    print(\"R2 score on test set : \",r2_score(y_test, y_pred))\n",
    "    print(f\"Diff is {np.around(np.abs([(y_pred[i]-y_test[i])/y_test[i] for i in range(len(y_pred))][:10]),2)}\")\n",
    "    return lasso_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_lasso(lasso_model, df_test_3, test):\n",
    "    X_test = []\n",
    "    for pid in df_test_3[\"pid\"].unique():\n",
    "        X_test.append(df_test_3.loc[df_test_3[\"pid\"]==pid, test].values)\n",
    "    predictions = lasso_model.predict(X_test)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lasso_subtask_3(df_train_3, df_train_label, TREND_LABEL):\n",
    "    lasso_models = []\n",
    "    for label_test in TREND_LABEL:\n",
    "        print('Testing model for {}'.format(label_test))\n",
    "        test = label_test.split(\"_\")[1]\n",
    "        lasso_models.append(train_lasso(df_train_3, df_train_label, test, label_test, 0.0001))\n",
    "    return lasso_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_models = lasso_subtask_3(df_train_3, df_label, TREND_LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions_3(df_test_3, lasso_models, TREND_LABEL):\n",
    "    predictions = []\n",
    "    for i in range(len(lasso_models)):\n",
    "        test = TREND_LABEL[i].split(\"_\")[1]\n",
    "        predictions.append(predict_lasso(lasso_models[i], df_test_3, test))\n",
    "    predictions = np.array(predictions).T\n",
    "    predictions = pd.DataFrame(data=predictions, columns=TREND_LABEL, index=(df_test_3[\"pid\"].unique()).astype(int))\n",
    "    return(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = get_predictions_3(df_test_3, lasso_models, TREND_LABEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discoveries: we already have the values of some we want to predict in the test set, so time series modelling? Prophet API possibly?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
